"""
TryAngle v1.5 - Unified Feedback System
í†µí•© í”¼ë“œë°± ì‹œìŠ¤í…œ: ë ˆí¼ëŸ°ìŠ¤ ë¹„êµ + íŒ¨í„´ ê¸°ë°˜ í”¼ë“œë°±
"""

import os
import sys
import json
import time
import numpy as np
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict

# ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent.parent / "v1.5_learning"))

from reference_comparison import ReferenceComparison, ComparisonResult
from test_feedback_system import FeedbackSystemTester


@dataclass
class UnifiedFeedback:
    """í†µí•© í”¼ë“œë°± ê²°ê³¼"""
    # ê¸°ë³¸ ì •ë³´
    image_path: str
    theme: str

    # ë‘ ê°€ì§€ í”¼ë“œë°± ëª¨ë“œ
    pattern_feedback: Optional[Dict] = None
    reference_feedback: Optional[ComparisonResult] = None

    # í†µí•© ì ìˆ˜ ë° ì•¡ì…˜
    unified_score: float = 0.0
    primary_actions: List[Dict] = None
    confidence: float = 0.0

    # ì‹œê°ì  ê°€ì´ë“œ
    visual_overlay: Dict = None

    # íƒ€ì´ë°
    total_time: float = 0.0


class UnifiedFeedbackSystem:
    """í†µí•© í”¼ë“œë°± ì‹œìŠ¤í…œ"""

    def __init__(self, pattern_file: str = None):
        """
        ì´ˆê¸°í™”

        Args:
            pattern_file: íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ
        """
        print("[UnifiedSystem] Initializing...")

        # íŒ¨í„´ ê¸°ë°˜ í”¼ë“œë°± ì‹œìŠ¤í…œ
        self.pattern_system = FeedbackSystemTester()

        # ë ˆí¼ëŸ°ìŠ¤ ë¹„êµ ì‹œìŠ¤í…œ
        self.reference_system = ReferenceComparison()

        # ìºì‹œ
        self.feedback_cache = {}

        print("[UnifiedSystem] Ready!")

    def analyze_with_reference(self,
                              current_path: str,
                              reference_path: str,
                              theme: str = "auto",
                              weight: float = 0.7) -> UnifiedFeedback:
        """
        ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ì™€ ë¹„êµí•˜ì—¬ í”¼ë“œë°± ìƒì„±

        Args:
            current_path: í‰ê°€í•  ì´ë¯¸ì§€
            reference_path: ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€
            theme: í…Œë§ˆ (autoë©´ ìë™ ê°ì§€)
            weight: ë ˆí¼ëŸ°ìŠ¤ ë¹„êµ ê°€ì¤‘ì¹˜ (0.0-1.0)
        """
        print("\n" + "="*60)
        print("Unified Feedback Analysis (with Reference)")
        print("="*60)

        start_time = time.time()

        # 1. ë ˆí¼ëŸ°ìŠ¤ ë¹„êµ
        print("\n[Phase 1] Reference Comparison")
        try:
            reference_result = self.reference_system.compare(
                current_path, reference_path, mode='detailed'
            )
            print(f"  - Similarity: {reference_result.similarity_score:.1f}/100")
        except Exception as e:
            print(f"  - Error: {e}")
            reference_result = None
            weight = 0.0  # ì‹¤íŒ¨ì‹œ íŒ¨í„´ë§Œ ì‚¬ìš©

        # 2. íŒ¨í„´ ê¸°ë°˜ í”¼ë“œë°±
        print("\n[Phase 2] Pattern-based Analysis")
        try:
            pattern_result = self.pattern_system.analyze_image(current_path, theme)
            if pattern_result["status"] == "success":
                print(f"  - Score: {pattern_result['feedback']['overall_score']:.1f}/100")
                print(f"  - Matched: {pattern_result['feedback']['matched_pattern']}")
            else:
                print(f"  - Error: {pattern_result.get('message', 'Unknown')}")
                pattern_result = None
        except Exception as e:
            print(f"  - Error: {e}")
            pattern_result = None

        # 3. í†µí•© ì ìˆ˜ ê³„ì‚°
        unified_score = self._calculate_unified_score(
            reference_result, pattern_result, weight
        )

        # 4. ìš°ì„ ìˆœìœ„ ì•¡ì…˜ ìƒì„±
        primary_actions = self._merge_actions(
            reference_result, pattern_result, weight
        )

        # 5. ì‹œê°ì  ì˜¤ë²„ë ˆì´ ìƒì„±
        visual_overlay = self._create_visual_overlay(
            current_path, reference_result, pattern_result
        )

        # 6. ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_confidence(
            reference_result, pattern_result, weight
        )

        # ê²°ê³¼ ìƒì„±
        return UnifiedFeedback(
            image_path=current_path,
            theme=theme if theme != "auto" else self._detect_theme(current_path),
            pattern_feedback=pattern_result if pattern_result and pattern_result["status"] == "success" else None,
            reference_feedback=reference_result,
            unified_score=unified_score,
            primary_actions=primary_actions,
            confidence=confidence,
            visual_overlay=visual_overlay,
            total_time=time.time() - start_time
        )

    def analyze_with_pattern(self,
                            image_path: str,
                            theme: str = "auto") -> UnifiedFeedback:
        """
        íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤ë§Œ ì‚¬ìš©í•˜ì—¬ í”¼ë“œë°± ìƒì„±

        Args:
            image_path: í‰ê°€í•  ì´ë¯¸ì§€
            theme: í…Œë§ˆ
        """
        print("\n" + "="*60)
        print("Unified Feedback Analysis (Pattern-only)")
        print("="*60)

        start_time = time.time()

        # íŒ¨í„´ ê¸°ë°˜ í”¼ë“œë°±
        print("\n[Analysis] Pattern-based feedback")
        try:
            pattern_result = self.pattern_system.analyze_image(image_path, theme)

            if pattern_result["status"] == "success":
                # íŒ¨í„´ í”¼ë“œë°±ì„ ì•¡ì…˜ìœ¼ë¡œ ë³€í™˜
                actions = self._convert_pattern_to_actions(pattern_result)

                # ì‹œê°ì  ì˜¤ë²„ë ˆì´
                visual_overlay = self._create_pattern_overlay(
                    image_path, pattern_result
                )

                return UnifiedFeedback(
                    image_path=image_path,
                    theme=theme if theme != "auto" else pattern_result.get("theme", "unknown"),
                    pattern_feedback=pattern_result,
                    reference_feedback=None,
                    unified_score=pattern_result['feedback']['overall_score'],
                    primary_actions=actions,
                    confidence=pattern_result['feedback']['confidence'],
                    visual_overlay=visual_overlay,
                    total_time=time.time() - start_time
                )
            else:
                raise ValueError(pattern_result.get('message', 'Analysis failed'))

        except Exception as e:
            print(f"  - Error: {e}")
            return UnifiedFeedback(
                image_path=image_path,
                theme=theme,
                pattern_feedback=None,
                reference_feedback=None,
                unified_score=0.0,
                primary_actions=[],
                confidence=0.0,
                visual_overlay=None,
                total_time=time.time() - start_time
            )

    def _calculate_unified_score(self,
                                reference_result: Optional[ComparisonResult],
                                pattern_result: Optional[Dict],
                                weight: float) -> float:
        """í†µí•© ì ìˆ˜ ê³„ì‚°"""

        scores = []
        weights = []

        if reference_result:
            scores.append(reference_result.similarity_score)
            weights.append(weight)

        if pattern_result and pattern_result.get("status") == "success":
            scores.append(pattern_result['feedback']['overall_score'])
            weights.append(1.0 - weight if reference_result else 1.0)

        if not scores:
            return 0.0

        # ê°€ì¤‘ í‰ê· 
        return sum(s * w for s, w in zip(scores, weights)) / sum(weights)

    def _merge_actions(self,
                      reference_result: Optional[ComparisonResult],
                      pattern_result: Optional[Dict],
                      weight: float) -> List[Dict]:
        """ì•¡ì…˜ ë³‘í•© ë° ìš°ì„ ìˆœìœ„ ê²°ì •"""

        actions = []

        # ë ˆí¼ëŸ°ìŠ¤ ê¸°ë°˜ ì•¡ì…˜
        if reference_result and reference_result.priority_actions:
            for action in reference_result.priority_actions:
                action_copy = action.copy()
                action_copy['source'] = 'reference'
                action_copy['weight'] = weight
                actions.append(action_copy)

        # íŒ¨í„´ ê¸°ë°˜ ì•¡ì…˜
        if pattern_result and pattern_result.get("status") == "success":
            pattern_actions = self._convert_pattern_to_actions(pattern_result)
            for action in pattern_actions:
                action['source'] = 'pattern'
                action['weight'] = 1.0 - weight if reference_result else 1.0
                actions.append(action)

        # ì¤‘ë³µ ì œê±° ë° ìš°ì„ ìˆœìœ„ ì •ë ¬
        unique_actions = self._deduplicate_actions(actions)

        # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì •ë ¬
        unique_actions.sort(key=lambda x: x.get('weight', 0), reverse=True)

        # ìƒìœ„ 3ê°œ ë°˜í™˜
        return unique_actions[:3]

    def _convert_pattern_to_actions(self, pattern_result: Dict) -> List[Dict]:
        """íŒ¨í„´ í”¼ë“œë°±ì„ ì•¡ì…˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""

        actions = []
        feedback = pattern_result.get('feedback', {})
        analysis = pattern_result.get('analysis', {})

        # ì—¬ë°± í”¼ë“œë°±ì„ ì•¡ì…˜ìœ¼ë¡œ
        margin_feedback = feedback.get('margin_feedback', '')
        if 'ë„ˆë¬´ ì¢' in margin_feedback or 'too tight' in margin_feedback.lower():
            actions.append({
                'type': 'margin',
                'action': 'Zoom out',
                'direction': 'âŸµâŸ¶',
                'amount': '10-15%',
                'impact': '+10 points'
            })
        elif 'ë„ˆë¬´ ë„“' in margin_feedback or 'too loose' in margin_feedback.lower():
            actions.append({
                'type': 'margin',
                'action': 'Zoom in',
                'direction': 'âŸ¶âŸµ',
                'amount': '10-15%',
                'impact': '+10 points'
            })

        # ìœ„ì¹˜ í”¼ë“œë°±ì„ ì•¡ì…˜ìœ¼ë¡œ
        position_feedback = feedback.get('position_feedback', '')
        if 'ìœ„ë¡œ' in position_feedback or 'move up' in position_feedback.lower():
            actions.append({
                'type': 'position',
                'action': 'Move up',
                'direction': 'â†‘',
                'amount': '5-10%',
                'impact': '+5 points'
            })
        elif 'ì•„ë˜ë¡œ' in position_feedback or 'move down' in position_feedback.lower():
            actions.append({
                'type': 'position',
                'action': 'Move down',
                'direction': 'â†“',
                'amount': '5-10%',
                'impact': '+5 points'
            })

        # ì••ì¶•ê° í”¼ë“œë°±ì„ ì•¡ì…˜ìœ¼ë¡œ
        compression_feedback = feedback.get('compression_feedback', '')
        if 'ë§ì›' in compression_feedback or 'telephoto' in compression_feedback.lower():
            actions.append({
                'type': 'compression',
                'action': 'Use telephoto lens',
                'direction': 'ğŸ”­',
                'amount': '85mm+',
                'impact': '+15 points'
            })
        elif 'ê´‘ê°' in compression_feedback or 'wide' in compression_feedback.lower():
            actions.append({
                'type': 'compression',
                'action': 'Use wider lens',
                'direction': 'ğŸ“',
                'amount': '24-35mm',
                'impact': '+15 points'
            })

        return actions

    def _deduplicate_actions(self, actions: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ì•¡ì…˜ ì œê±°"""

        unique = {}
        for action in actions:
            key = f"{action['type']}_{action.get('direction', '')}"
            if key not in unique:
                unique[key] = action
            else:
                # ë” ë†’ì€ ê°€ì¤‘ì¹˜ ìœ ì§€
                if action.get('weight', 0) > unique[key].get('weight', 0):
                    unique[key] = action

        return list(unique.values())

    def _calculate_confidence(self,
                            reference_result: Optional[ComparisonResult],
                            pattern_result: Optional[Dict],
                            weight: float) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""

        confidences = []
        weights = []

        if reference_result:
            # ë ˆí¼ëŸ°ìŠ¤ ë¹„êµëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë†’ì€ ì‹ ë¢°ë„
            confidences.append(0.95)
            weights.append(weight)

        if pattern_result and pattern_result.get("status") == "success":
            confidences.append(pattern_result['feedback'].get('confidence', 0.8))
            weights.append(1.0 - weight if reference_result else 1.0)

        if not confidences:
            return 0.0

        return sum(c * w for c, w in zip(confidences, weights)) / sum(weights)

    def _create_visual_overlay(self,
                              image_path: str,
                              reference_result: Optional[ComparisonResult],
                              pattern_result: Optional[Dict]) -> Dict:
        """ì‹œê°ì  ì˜¤ë²„ë ˆì´ ì •ë³´ ìƒì„±"""

        overlay = {
            'current_bbox': None,
            'target_bbox': None,
            'movement_arrows': [],
            'grid_lines': {
                'rule_of_thirds': True,
                'golden_ratio': False
            },
            'margin_guides': None,
            'focus_point': None
        }

        # ë ˆí¼ëŸ°ìŠ¤ ê²°ê³¼ì—ì„œ ì˜¤ë²„ë ˆì´ ì •ë³´
        if reference_result and reference_result.visual_guides:
            guides = reference_result.visual_guides
            overlay['current_bbox'] = guides.get('current_bbox')
            overlay['target_bbox'] = guides.get('target_area')

            if guides.get('movement_arrow'):
                arrow = guides['movement_arrow']
                overlay['movement_arrows'].append({
                    'from': arrow['start'],
                    'to': arrow['end'],
                    'strength': min(1.0, arrow['distance'] * 2),
                    'color': 'green'
                })

        # íŒ¨í„´ ê²°ê³¼ì—ì„œ ì¶”ê°€ ì •ë³´
        if pattern_result and pattern_result.get("status") == "success":
            detection = pattern_result.get('detection', {})
            if detection.get('person_bbox'):
                overlay['current_bbox'] = detection['person_bbox']

            analysis = pattern_result.get('analysis', {})
            if analysis.get('center'):
                overlay['focus_point'] = analysis['center']

            # ì—¬ë°± ê°€ì´ë“œ
            if analysis.get('margins'):
                margins = analysis['margins']
                overlay['margin_guides'] = {
                    'top': margins[0],
                    'right': margins[1],
                    'bottom': margins[2],
                    'left': margins[3],
                    'optimal': self._get_optimal_margins(pattern_result)
                }

        return overlay

    def _create_pattern_overlay(self,
                               image_path: str,
                               pattern_result: Dict) -> Dict:
        """íŒ¨í„´ ì „ìš© ì˜¤ë²„ë ˆì´"""

        overlay = {
            'current_bbox': pattern_result.get('detection', {}).get('person_bbox'),
            'grid_lines': {'rule_of_thirds': True},
            'margin_guides': None,
            'focus_point': pattern_result.get('analysis', {}).get('center')
        }

        # ì—¬ë°± ê°€ì´ë“œ
        margins = pattern_result.get('analysis', {}).get('margins')
        if margins:
            overlay['margin_guides'] = {
                'top': margins[0],
                'right': margins[1],
                'bottom': margins[2],
                'left': margins[3],
                'optimal': self._get_optimal_margins(pattern_result)
            }

        return overlay

    def _get_optimal_margins(self, pattern_result: Dict) -> Dict:
        """ìµœì  ì—¬ë°± ê³„ì‚°"""

        # í¬ì¦ˆ íƒ€ì…ë³„ ê¶Œì¥ ì—¬ë°±
        pose_type = pattern_result.get('analysis', {}).get('pose_type', 'medium_shot')

        optimal = {
            'closeup': {'top': 0.05, 'sides': 0.05, 'bottom': 0.05},
            'medium_shot': {'top': 0.15, 'sides': 0.15, 'bottom': 0.20},
            'knee_shot': {'top': 0.20, 'sides': 0.15, 'bottom': 0.15},
            'full_shot': {'top': 0.15, 'sides': 0.20, 'bottom': 0.15}
        }

        return optimal.get(pose_type, optimal['medium_shot'])

    def _detect_theme(self, image_path: str) -> str:
        """ì´ë¯¸ì§€ì—ì„œ í…Œë§ˆ ìë™ ê°ì§€"""
        # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ê°ì§€
        # ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¶„ë¥˜ê¸° ì‚¬ìš© ê°€ëŠ¥

        path_lower = image_path.lower()

        if 'cafe' in path_lower or 'coffee' in path_lower:
            return 'cafe_indoor'
        elif 'park' in path_lower or 'nature' in path_lower:
            return 'park_nature'
        elif 'street' in path_lower or 'urban' in path_lower:
            return 'street_urban'
        elif 'winter' in path_lower or 'snow' in path_lower:
            return 'winter'
        else:
            return 'indoor_home'

    def create_visualization(self,
                            feedback: UnifiedFeedback,
                            output_path: str = None) -> Optional[str]:
        """
        í”¼ë“œë°± ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±

        Args:
            feedback: í†µí•© í”¼ë“œë°± ê²°ê³¼
            output_path: ì €ì¥ ê²½ë¡œ

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        try:
            # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
            image = Image.open(feedback.image_path)
            if image.mode != 'RGB':
                image = image.convert('RGB')

            # ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸°
            draw = ImageDraw.Draw(image, 'RGBA')
            width, height = image.size

            overlay = feedback.visual_overlay
            if not overlay:
                return None

            # 1. Rule of thirds ê·¸ë¦¬ë“œ
            if overlay.get('grid_lines', {}).get('rule_of_thirds'):
                for x in [width/3, 2*width/3]:
                    draw.line([(x, 0), (x, height)], fill=(255, 255, 255, 50), width=1)
                for y in [height/3, 2*height/3]:
                    draw.line([(0, y), (width, y)], fill=(255, 255, 255, 50), width=1)

            # 2. í˜„ì¬ ë°”ìš´ë”© ë°•ìŠ¤
            if overlay.get('current_bbox'):
                x1, y1, x2, y2 = overlay['current_bbox']
                x1, y1, x2, y2 = x1*width, y1*height, x2*width, y2*height
                draw.rectangle([x1, y1, x2, y2], outline=(255, 0, 0, 200), width=3)

            # 3. ëª©í‘œ ë°”ìš´ë”© ë°•ìŠ¤
            if overlay.get('target_bbox'):
                x1, y1, x2, y2 = overlay['target_bbox']
                x1, y1, x2, y2 = x1*width, y1*height, x2*width, y2*height
                draw.rectangle([x1, y1, x2, y2], outline=(0, 255, 0, 150), width=2)

            # 4. ì´ë™ í™”ì‚´í‘œ
            for arrow in overlay.get('movement_arrows', []):
                start = (arrow['from'][0]*width, arrow['from'][1]*height)
                end = (arrow['to'][0]*width, arrow['to'][1]*height)
                draw.line([start, end], fill=(0, 255, 0, 200), width=3)

                # í™”ì‚´í‘œ ë¨¸ë¦¬
                angle = np.arctan2(end[1]-start[1], end[0]-start[0])
                arrow_len = 20
                draw.line([end, (end[0]-arrow_len*np.cos(angle-0.5),
                                end[1]-arrow_len*np.sin(angle-0.5))],
                         fill=(0, 255, 0, 200), width=3)
                draw.line([end, (end[0]-arrow_len*np.cos(angle+0.5),
                                end[1]-arrow_len*np.sin(angle+0.5))],
                         fill=(0, 255, 0, 200), width=3)

            # 5. ì•¡ì…˜ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´
            y_offset = 20
            for i, action in enumerate(feedback.primary_actions[:3]):
                text = f"{i+1}. {action['action']} {action['direction']} ({action['amount']})"
                draw.text((20, y_offset), text,
                         fill=(255, 255, 0, 255),
                         font=None)
                y_offset += 30

            # 6. ì ìˆ˜ í‘œì‹œ
            score_text = f"Score: {feedback.unified_score:.1f}/100"
            draw.text((width-150, 20), score_text,
                     fill=(255, 255, 255, 255),
                     font=None)

            # ì €ì¥
            if not output_path:
                output_path = feedback.image_path.replace('.', '_feedback.')

            image.save(output_path, quality=95)
            print(f"\n[Visualization] Saved to: {output_path}")
            return output_path

        except Exception as e:
            print(f"\n[Visualization Error] {e}")
            return None


def print_unified_feedback(feedback: UnifiedFeedback):
    """í†µí•© í”¼ë“œë°± ê²°ê³¼ ì¶œë ¥"""

    print("\n" + "="*60)
    print("UNIFIED FEEDBACK RESULTS")
    print("="*60)

    # ê¸°ë³¸ ì •ë³´
    print(f"\nImage: {Path(feedback.image_path).name}")
    print(f"Theme: {feedback.theme}")
    print(f"Analysis Time: {feedback.total_time:.2f}s")
    print(f"Confidence: {feedback.confidence:.1%}")

    # í†µí•© ì ìˆ˜
    score_emoji = "ğŸŸ¢" if feedback.unified_score >= 80 else "ğŸŸ¡" if feedback.unified_score >= 60 else "ğŸ”´"
    print(f"\n{score_emoji} Unified Score: {feedback.unified_score:.1f}/100")

    # ìš°ì„ ìˆœìœ„ ì•¡ì…˜
    if feedback.primary_actions:
        print("\nğŸ“‹ Recommended Actions:")
        for i, action in enumerate(feedback.primary_actions):
            print(f"\n  {i+1}. {action['action']} {action.get('direction', '')}")
            print(f"     Amount: {action.get('amount', 'N/A')}")
            print(f"     Expected Impact: {action.get('impact', 'N/A')}")
            print(f"     Source: {action.get('source', 'unified')}")

    # ìƒì„¸ í”¼ë“œë°± (ìˆëŠ” ê²½ìš°)
    if feedback.reference_feedback:
        print("\nğŸ“Š Reference Comparison:")
        print(f"   Similarity: {feedback.reference_feedback.similarity_score:.1f}/100")
        print(f"   Position Difference: {feedback.reference_feedback.position_difference}")
        print(f"   Margin Differences: {feedback.reference_feedback.margin_differences}")

    if feedback.pattern_feedback:
        pf = feedback.pattern_feedback.get('feedback', {})
        print("\nğŸ“Š Pattern Analysis:")
        print(f"   Pattern Score: {pf.get('overall_score', 0):.1f}/100")
        print(f"   Matched Pattern: {pf.get('matched_pattern', 'N/A')}")
        print(f"   Margin Feedback: {pf.get('margin_feedback', 'N/A')}")

    # ì‹œê°ì  ê°€ì´ë“œ ì •ë³´
    if feedback.visual_overlay:
        print("\nğŸ¯ Visual Guides Available:")
        if feedback.visual_overlay.get('target_bbox'):
            print("   - Target area overlay")
        if feedback.visual_overlay.get('movement_arrows'):
            print("   - Movement direction arrows")
        if feedback.visual_overlay.get('margin_guides'):
            print("   - Margin adjustment guides")
        if feedback.visual_overlay.get('grid_lines'):
            print("   - Composition grid lines")

    print("\n" + "="*60)


# ============================================================
# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
# ============================================================

def test_unified_system():
    """í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""

    print("\n" + "="*60)
    print("TryAngle v1.5 - Unified Feedback System Test")
    print("="*60)

    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = UnifiedFeedbackSystem()

    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases = [
        # 1. ë ˆí¼ëŸ°ìŠ¤ ë¹„êµ í…ŒìŠ¤íŠ¸
        {
            'mode': 'reference',
            'current': 'C:/try_angle/data/sample_images/cafe2.jpg',
            'reference': 'C:/try_angle/data/sample_images/cafe1.jpg',
            'theme': 'cafe_indoor'
        },
        # 2. íŒ¨í„´ë§Œ ì‚¬ìš© í…ŒìŠ¤íŠ¸
        {
            'mode': 'pattern',
            'current': 'C:/try_angle/data/sample_images/cafe1.jpg',
            'theme': 'cafe_indoor'
        }
    ]

    results = []

    for i, test in enumerate(test_cases):
        print(f"\n[Test {i+1}] Mode: {test['mode']}")
        print("-" * 40)

        try:
            if test['mode'] == 'reference':
                # ë ˆí¼ëŸ°ìŠ¤ ë¹„êµ ëª¨ë“œ
                feedback = system.analyze_with_reference(
                    test['current'],
                    test['reference'],
                    test['theme'],
                    weight=0.7
                )
            else:
                # íŒ¨í„´ ì „ìš© ëª¨ë“œ
                feedback = system.analyze_with_pattern(
                    test['current'],
                    test['theme']
                )

            # ê²°ê³¼ ì¶œë ¥
            print_unified_feedback(feedback)

            # ì‹œê°í™” ìƒì„±
            viz_path = system.create_visualization(
                feedback,
                f"test_feedback_{i+1}.jpg"
            )

            results.append({
                'test': test,
                'feedback': asdict(feedback),
                'visualization': viz_path
            })

        except Exception as e:
            print(f"\n[Error] {e}")
            import traceback
            traceback.print_exc()

    # ê²°ê³¼ ì €ì¥
    with open('unified_test_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=str)

    print("\n[Complete] Test results saved to unified_test_results.json")


if __name__ == "__main__":
    test_unified_system()