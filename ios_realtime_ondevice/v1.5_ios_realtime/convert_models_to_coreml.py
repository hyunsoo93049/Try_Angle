"""
ëª¨ë¸ì„ CoreML/ONNXë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
ì‘ì„±ì¼: 2025-12-05
"""

import os
import sys
import torch
import coremltools as ct
import numpy as np
from pathlib import Path

print("="*60)
print("TryAngle ëª¨ë¸ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸")
print("="*60)

# ============================================================
# 1. Depth Anything â†’ CoreML ë³€í™˜
# ============================================================

def convert_depth_anything_to_coreml():
    """Depth Anythingì„ CoreMLë¡œ ë³€í™˜"""

    print("\n[1] Depth Anything â†’ CoreML ë³€í™˜")
    print("-"*40)

    try:
        # Depth Anything ëª¨ë¸ ë¡œë“œ
        from transformers import pipeline

        print("1. Hugging Faceì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        depth_estimator = pipeline('depth-estimation', model='LiheYoung/depth-anything-small-hf')

        # PyTorch ëª¨ë¸ ì¶”ì¶œ
        model = depth_estimator.model
        model.eval()

        print("2. ëª¨ë¸ íŠ¸ë ˆì´ì‹±...")
        # ë”ë¯¸ ì…ë ¥ (518x518 - Depth Anything ê¸°ë³¸ í¬ê¸°)
        dummy_input = torch.randn(1, 3, 518, 518)

        # ëª¨ë¸ íŠ¸ë ˆì´ì‹±
        traced_model = torch.jit.trace(model, dummy_input)

        print("3. CoreML ë³€í™˜ ì¤‘...")

        # ë°©ë²• 1: neuralnetwork ë°±ì—”ë“œ (iOS í˜¸í™˜ì„± ì¢‹ìŒ)
        mlmodel = ct.convert(
            traced_model,
            inputs=[ct.ImageType(
                name="image",
                shape=dummy_input.shape,
                bias=[-0.485/0.229, -0.456/0.224, -0.406/0.225],
                scale=1.0/255.0/0.226
            )],
            convert_to='neuralnetwork'  # iOS í˜¸í™˜ì„±
        )

        # ëª¨ë¸ ì €ì¥
        output_path = "depth_anything_small.mlmodel"
        mlmodel.save(output_path)

        print(f"âœ… CoreML ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {output_path}")
        print(f"   íŒŒì¼ í¬ê¸°: {os.path.getsize(output_path) / 1024 / 1024:.1f}MB")

        # ë°©ë²• 2: mlprogram ë°±ì—”ë“œ (ìµœì‹ , ë” íš¨ìœ¨ì )
        print("\n4. mlprogram ë²„ì „ë„ ë³€í™˜ ì¤‘...")
        mlmodel_program = ct.convert(
            traced_model,
            inputs=[ct.TensorType(
                name="input",
                shape=dummy_input.shape
            )],
            convert_to='mlprogram',
            minimum_deployment_target=ct.target.iOS16
        )

        output_path2 = "depth_anything_small.mlpackage"
        mlmodel_program.save(output_path2)
        print(f"âœ… mlpackage ì €ì¥ ì™„ë£Œ: {output_path2}")

        return True

    except Exception as e:
        print(f"âŒ Depth Anything ë³€í™˜ ì‹¤íŒ¨: {e}")
        print("\nëŒ€ì•ˆ: Apple ê³µì‹ CoreML ëª¨ë¸ ì‚¬ìš©")
        print("ë‹¤ìš´ë¡œë“œ: https://huggingface.co/apple/coreml-depth-anything-v2-small")
        return False


# ============================================================
# 2. RTMPose â†’ ONNX ë³€í™˜ (ì´ë¯¸ êµ¬í˜„ë¨)
# ============================================================

def check_rtmpose_onnx():
    """RTMPose ONNX íŒŒì¼ í™•ì¸"""

    print("\n[2] RTMPose ONNX í™•ì¸")
    print("-"*40)

    onnx_files = {
        "yolox_int8.onnx": "YOLOX ê²€ì¶œê¸° (24MB)",
        "rtmpose_int8.onnx": "RTMPose 133 í‚¤í¬ì¸íŠ¸ (55MB)"
    }

    ios_model_dir = Path("../../ios/TryAngleApp/Models")

    for filename, description in onnx_files.items():
        file_path = ios_model_dir / filename
        if file_path.exists():
            size_mb = file_path.stat().st_size / 1024 / 1024
            print(f"âœ… {filename}: {description}")
            print(f"   ê²½ë¡œ: {file_path}")
            print(f"   í¬ê¸°: {size_mb:.1f}MB")
        else:
            print(f"âŒ {filename} ì—†ìŒ")
            print(f"   ì˜ˆìƒ ê²½ë¡œ: {file_path}")

    print("\nì°¸ê³ : RTMPose ONNX ë³€í™˜ì€ ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
    print("ê´€ë ¨ ì½”ë“œ: ios/TryAngleApp/Services/Analysis/RTMPoseRunner.swift")


# ============================================================
# 3. YOLO â†’ CoreML ë³€í™˜ (ë³´ë„ˆìŠ¤)
# ============================================================

def convert_yolo_to_coreml():
    """YOLO v8ì„ CoreMLë¡œ ë³€í™˜"""

    print("\n[3] YOLO v8 â†’ CoreML ë³€í™˜")
    print("-"*40)

    try:
        from ultralytics import YOLO

        print("1. YOLOv8n ëª¨ë¸ ë¡œë“œ ì¤‘...")
        model = YOLO('yolov8n.pt')

        print("2. CoreML ë³€í™˜ ì¤‘...")
        # CoreMLë¡œ export
        model.export(format='coreml', imgsz=640, nms=True)

        print("âœ… YOLO CoreML ë³€í™˜ ì™„ë£Œ")
        print("   ì¶œë ¥: yolov8n.mlpackage")
        print("   iOSì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥!")

        return True

    except Exception as e:
        print(f"âŒ YOLO ë³€í™˜ ì‹¤íŒ¨: {e}")
        print("   pip install ultralytics í•„ìš”")
        return False


# ============================================================
# 4. ëª¨ë¸ í¬ê¸° ìµœì í™”
# ============================================================

def optimize_model_size():
    """ëª¨ë¸ í¬ê¸° ìµœì í™” íŒ"""

    print("\n[4] ëª¨ë¸ í¬ê¸° ìµœì í™” ë°©ë²•")
    print("-"*40)

    print("""
1. ì–‘ìí™” (Quantization)
   - INT8 ì–‘ìí™”: í¬ê¸° 75% ê°ì†Œ, ì†ë„ 3ë°° í–¥ìƒ
   - Float16: í¬ê¸° 50% ê°ì†Œ

2. í”„ë£¨ë‹ (Pruning)
   - ë¶ˆí•„ìš”í•œ ê°€ì¤‘ì¹˜ ì œê±°
   - 20-30% í¬ê¸° ê°ì†Œ ê°€ëŠ¥

3. ì§€ì‹ ì¦ë¥˜ (Knowledge Distillation)
   - í° ëª¨ë¸ â†’ ì‘ì€ ëª¨ë¸ë¡œ í•™ìŠµ
   - Depth Anything Large â†’ Small

4. ëª¨ë¸ ì„ íƒ
   - Depth Anything: Small (24MB) vs Base (97MB)
   - RTMPose: Tiny vs Small vs Medium
   - YOLO: v8n (6MB) vs v8s (25MB)
""")


# ============================================================
# 5. í†µí•© iOS í”„ë¡œì íŠ¸ êµ¬ì¡°
# ============================================================

def create_ios_project_structure():
    """iOS í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±"""

    print("\n[5] iOS í”„ë¡œì íŠ¸ êµ¬ì¡°")
    print("-"*40)

    structure = """
ios/
â”œâ”€â”€ TryAngleApp/
â”‚   â”œâ”€â”€ Models/                    # ëª¨ë¸ íŒŒì¼
â”‚   â”‚   â”œâ”€â”€ depth_anything_small.mlmodelc
â”‚   â”‚   â”œâ”€â”€ yolox_int8.onnx
â”‚   â”‚   â””â”€â”€ rtmpose_int8.onnx
â”‚   â”‚
â”‚   â”œâ”€â”€ Services/
â”‚   â”‚   â”œâ”€â”€ Analysis/
â”‚   â”‚   â”‚   â”œâ”€â”€ RTMPoseRunner.swift      # ONNX Runtime
â”‚   â”‚   â”‚   â”œâ”€â”€ DepthAnythingCoreML.swift # CoreML
â”‚   â”‚   â”‚   â””â”€â”€ PoseMLAnalyzer.swift     # í†µí•©
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ Camera/
â”‚   â”‚       â””â”€â”€ CameraService.swift
â”‚   â”‚
â”‚   â””â”€â”€ TryAngleApp-Bridging-Header.h    # ONNX Runtime C API
â”‚
â”œâ”€â”€ Podfile                         # onnxruntime-mobile-c
â””â”€â”€ Info.plist                      # ì¹´ë©”ë¼ ê¶Œí•œ
"""

    print(structure)
    print("\nëª¨ë“  ëª¨ë¸ì„ ì˜¨ë””ë°”ì´ìŠ¤ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥!")


# ============================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""

    # 1. Depth Anything ë³€í™˜
    success = convert_depth_anything_to_coreml()

    # 2. RTMPose í™•ì¸
    check_rtmpose_onnx()

    # 3. YOLO ë³€í™˜ (ì˜µì…˜)
    # convert_yolo_to_coreml()

    # 4. ìµœì í™” íŒ
    optimize_model_size()

    # 5. í”„ë¡œì íŠ¸ êµ¬ì¡°
    create_ios_project_structure()

    print("\n" + "="*60)
    print("ë³€í™˜ ì™„ë£Œ!")
    print("="*60)

    if success:
        print("\nâœ… ì˜¨ë””ë°”ì´ìŠ¤ ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ:")
        print("   - RTMPose: ONNX Runtime (ì´ë¯¸ êµ¬í˜„)")
        print("   - Depth Anything: CoreML (ë³€í™˜ ì™„ë£Œ)")
        print("   - YOLO: ë”ë¯¸ ëª¨ë“œ ë˜ëŠ” CoreML")
        print("\nğŸš€ API ì„œë²„ ì—†ì´ iOSì—ì„œ ì§ì ‘ ì‹¤í–‰ ê°€ëŠ¥!")
    else:
        print("\nâš ï¸ ì¼ë¶€ ë³€í™˜ ì‹¤íŒ¨")
        print("   Apple ê³µì‹ ëª¨ë¸ ì‚¬ìš© ê¶Œì¥")


if __name__ == "__main__":
    # í•„ìš” íŒ¨í‚¤ì§€ í™•ì¸
    required = ["torch", "coremltools", "transformers"]
    missing = []

    for package in required:
        try:
            __import__(package)
        except ImportError:
            missing.append(package)

    if missing:
        print(f"âŒ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜:")
        print(f"   pip install {' '.join(missing)}")
        print("\níŠ¹íˆ coremltools ì„¤ì¹˜:")
        print("   pip install coremltools")
        sys.exit(1)

    main()