#!/usr/bin/env python3
"""
TryAngle v7.0 - iOS Realtime Smart Feedback
ê¸°ë°˜: v6 + ì‹¤ì‹œê°„ ìµœì í™”
ê°œì„  ì‚¬í•­:
1. ì´ì¤‘ ëª¨ë“œ (ë ˆí¼ëŸ°ìŠ¤/ì‹¤ì‹œê°„)
2. ìºì‹± ì‹œìŠ¤í…œ
3. iOS ìµœì í™”
4. v6ì˜ ëª¨ë“  ê¸°ëŠ¥ í¬í•¨
"""

import sys
import os
import time
import traceback
import math
import numpy as np
from pathlib import Path
from typing import Optional, Tuple, Dict, List, Any
import json

# UTF-8 ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'

# ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent.parent))
sys.path.append(str(Path(__file__).parent.parent / "models"))

# Analyzers ì„í¬íŠ¸
from analyzers.pose_analyzer import RTMPoseWholebodyAnalyzer
from analyzers.framing_analyzer import FramingAnalyzer
from analyzers.margin_analyzer import ImprovedMarginAnalyzer, convert_to_legacy_format

# Core ì„í¬íŠ¸
from feedback_config import FeedbackConfig, get_config, set_language

# Legacy ì‹œìŠ¤í…œ ì„í¬íŠ¸ (ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„ìš©)
from models.legacy.reference_comparison import (
    ReferenceComparison,
    ComparisonResult,
    ImageAnalysis
)

# ì´ë¯¸ì§€ ì²˜ë¦¬
try:
    from PIL import Image
except ImportError:
    import cv2


class SmartFeedbackV7:
    """
    iOS Realtime Smart Feedback System
    - v6 ê¸°ë°˜ + ì‹¤ì‹œê°„ ìµœì í™”
    - ì´ì¤‘ ëª¨ë“œ: ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„ / ì‹¤ì‹œê°„ ì²˜ë¦¬
    - ìºì‹± ì‹œìŠ¤í…œ í†µí•©
    """

    def __init__(self, mode='ios', language='ko', debug_mode=True):
        """
        ì´ˆê¸°í™”
        Args:
            mode: 'ios' (ì‹¤ì‹œê°„), 'reference' (ì •ë°€ ë¶„ì„), 'full' (ë‘˜ ë‹¤)
            language: ì–¸ì–´ ì„¤ì •
            debug_mode: ë””ë²„ê·¸ ì¶œë ¥
        """
        self.mode = mode
        self.debug_mode = debug_mode

        if debug_mode:
            print(f"[SmartFeedbackV7] ì´ˆê¸°í™” ì¤‘... (ëª¨ë“œ: {mode}, ì–¸ì–´: {language})")
            print(f"[ê°œì„ ì‚¬í•­] iOS ì‹¤ì‹œê°„ ìµœì í™”, ìºì‹±, ì´ì¤‘ ëª¨ë“œ")

        # 133ê°œ í‚¤í¬ì¸íŠ¸ ë¶„ì„ê¸°
        self.wholebody = RTMPoseWholebodyAnalyzer(mode='balanced')

        # ëª¨ë“œë³„ ì´ˆê¸°í™”
        if mode in ['reference', 'full']:
            # Legacy ì‹œìŠ¤í…œ (ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„ìš©)
            self.legacy_comparator = ReferenceComparison()
        else:
            # ì‹¤ì‹œê°„ ëª¨ë“œì—ì„œëŠ” Legacy ì‚¬ìš© ì•ˆ í•¨
            self.legacy_comparator = None

        # í”„ë ˆì´ë° ë¶„ì„ê¸° (í•­ìƒ ì‚¬ìš©)
        self.framing_analyzer = FramingAnalyzer()

        # ê°œì„ ëœ ì—¬ë°± ë¶„ì„ê¸° (í•­ìƒ ì‚¬ìš©)
        self.margin_analyzer = ImprovedMarginAnalyzer()

        # ìºì‹œ ê´€ë¦¬ì (ë‚˜ì¤‘ì— ì¶”ê°€)
        self.cache_manager = None

        # ì–¸ì–´ ì„¤ì •
        self.config = get_config(language)
        self.language = language

        # Gate í†µê³¼ ê¸°ì¤€ (v5ì™€ ë™ì¼)
        self.gate_thresholds = {
            'aspect_ratio': 90,
            'framing': 70,
            'composition': 75,
            'compression': 80
        }

        # ë””ë°”ì´ìŠ¤ë³„ ì¤Œ ì‹œìŠ¤í…œ (v5ì™€ ë™ì¼)
        self.device_zoom_systems = {
            "iPhone": [0.5, 1.0, 2.0, 3.0, 5.0],
            "Galaxy": [0.6, 1.0, 3.0, 10.0],
            "generic": [0.5, 1.0, 2.0, 3.0, 5.0]
        }

        if debug_mode:
            print("[SmartFeedbackV7] ì´ˆê¸°í™” ì™„ë£Œ")

    def analyze_reference(self, reference_path: str) -> Dict[str, Any]:
        """
        ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ì •ë°€ ë¶„ì„ (1íšŒë§Œ ì‹¤í–‰)
        Legacy ì‹œìŠ¤í…œ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ë¶„ì„
        """
        if self.debug_mode:
            print("\n" + "="*70)
            print("[ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„] ì •ë°€ ë¶„ì„ ì‹œì‘...")
            print("="*70)

        if self.mode == 'ios' and self.legacy_comparator is None:
            # iOS ëª¨ë“œì—ì„œëŠ” ê°„ì†Œí™”ëœ ë¶„ì„
            return self._analyze_reference_fast(reference_path)
        else:
            # Full ëª¨ë“œì—ì„œëŠ” Legacy ì‚¬ìš©
            return self._analyze_reference_full(reference_path)

    def process_frame(self, frame: np.ndarray, reference_cache: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ì‹¤ì‹œê°„ í”„ë ˆì„ ì²˜ë¦¬ (30fps)
        ìºì‹œëœ ë ˆí¼ëŸ°ìŠ¤ì™€ ë¹„êµ
        """
        if self.mode not in ['ios', 'full']:
            raise ValueError(f"ì‹¤ì‹œê°„ ì²˜ë¦¬ëŠ” 'ios' ë˜ëŠ” 'full' ëª¨ë“œì—ì„œë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤. í˜„ì¬: {self.mode}")

        # RTMPoseë¡œ ë¹ ë¥¸ ë¶„ì„
        keypoints = self.wholebody.extract_wholebody_keypoints(frame)

        # ìºì‹œëœ ë ˆí¼ëŸ°ìŠ¤ì™€ ë¹„êµ
        if reference_cache:
            return self._compare_realtime(keypoints, reference_cache, frame.shape)
        else:
            return {'error': 'ë ˆí¼ëŸ°ìŠ¤ ìºì‹œê°€ í•„ìš”í•©ë‹ˆë‹¤'}

    def analyze_with_gates(self, current_path: str, reference_path: str,
                          device_type: str = "generic",
                          test_mode: bool = True) -> Dict[str, Any]:
        """
        Gate System ê¸°ë°˜ ë¶„ì„ (v6 í˜¸í™˜ ë©”ì„œë“œ)
        """
        if self.debug_mode:
            print("\n" + "="*70)
            print("[V6] Gate System ë¶„ì„ ì‹œì‘ (ê°œì„ ëœ ì—¬ë°± ë¶„ì„)")
            print("="*70)

            print(f"\n[ì…ë ¥ íŒŒì¼ ì •ë³´]")
            print(f"  Current: {Path(current_path).name}")
            print(f"  Reference: {Path(reference_path).name}")

        # ì´ë¯¸ì§€ ë¡œë“œ
        curr_img = self._load_image(current_path)
        ref_img = self._load_image(reference_path)

        if curr_img is None or ref_img is None:
            return {'error': 'ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨'}

        if self.debug_mode:
            print(f"\n[ì´ë¯¸ì§€ í¬ê¸°]")
            print(f"  Current: {curr_img.shape[1]}x{curr_img.shape[0]} (WxH)")
            print(f"  Reference: {ref_img.shape[1]}x{ref_img.shape[0]} (WxH)")

        # 133ê°œ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
        if self.debug_mode:
            print("\n[133ê°œ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ]")
            print("-" * 60)

        curr_kpts = self._extract_keypoints_debug(curr_img, "Current") if self.debug_mode else \
                   self.wholebody.extract_wholebody_keypoints(curr_img)
        ref_kpts = self._extract_keypoints_debug(ref_img, "Reference") if self.debug_mode else \
                  self.wholebody.extract_wholebody_keypoints(ref_img)

        # Legacy ë¶„ì„
        if self.debug_mode:
            print("\n[Legacy ì‹œìŠ¤í…œ ë¶„ì„]")
            print("-" * 60)

        legacy_result = self.legacy_comparator.compare(
            current_path=current_path,
            reference_path=reference_path,
            mode='detailed'
        )

        # Gate System ì ìš© (v6 Full Analysis)
        return self._full_analysis_v6(
            curr_kpts, ref_kpts,
            curr_img.shape, ref_img.shape,
            legacy_result, device_type
        )

    def _full_analysis_v6(self, curr_kpts: Dict, ref_kpts: Dict,
                         curr_shape: Tuple, ref_shape: Tuple,
                         legacy_result: Any, device_type: str) -> Dict[str, Any]:
        """
        v6 Full Analysis: ê°œì„ ëœ ì—¬ë°± ë¶„ì„ í¬í•¨
        """
        if self.debug_mode:
            print("\n" + "="*70)
            print("[V6] Full Analysis - ê°œì„ ëœ Gate ì ê²€")
            print("="*70)

        all_gates = {}

        # ============ GATE 0: ì¢…íš¡ë¹„ ì²´í¬ (v5ì™€ ë™ì¼) ============
        if self.debug_mode:
            print("\n[GATE 0] ì¢…íš¡ë¹„ ì²´í¬...")
        aspect_score, aspect_feedback = self._check_aspect_ratio_debug(curr_shape, ref_shape)
        all_gates['aspect_ratio'] = {
            'score': aspect_score,
            'passed': aspect_score >= self.gate_thresholds['aspect_ratio'],
            'feedback': aspect_feedback
        }

        # ============ GATE 1: ê°œì„ ëœ í”„ë ˆì´ë° (v6) ============
        if self.debug_mode:
            print("\n[GATE 1] í”„ë ˆì´ë° ì²´í¬ (ê°œì„ ëœ ì—¬ë°± ë¶„ì„)...")
        framing_score, framing_result = self._check_framing_v6(
            curr_kpts, ref_kpts, curr_shape, ref_shape
        )
        all_gates['framing'] = {
            'score': framing_score,
            'passed': framing_score >= self.gate_thresholds['framing'],
            'feedback': framing_result.get('feedback', {}).get('summary', ''),
            'details': framing_result
        }

        # ============ GATE 2: êµ¬ë„ (v5ì™€ ë™ì¼) ============
        if self.debug_mode:
            print("\n[GATE 2] êµ¬ë„ ì²´í¬...")
        composition_score, composition_feedback = self._check_composition_debug(
            curr_kpts, ref_kpts, curr_shape, ref_shape
        )
        all_gates['composition'] = {
            'score': composition_score,
            'passed': composition_score >= self.gate_thresholds['composition'],
            'feedback': composition_feedback
        }

        # ============ GATE 3: ì••ì¶•ê° (v5ì™€ ë™ì¼) ============
        if self.debug_mode:
            print("\n[GATE 3] ì••ì¶•ê° ì²´í¬...")
        compression_score, compression_feedback = self._check_compression_debug(
            legacy_result, device_type
        )
        all_gates['compression'] = {
            'score': compression_score,
            'passed': compression_score >= self.gate_thresholds['compression'],
            'feedback': compression_feedback
        }

        # ============ GATE 4: í¬ì¦ˆ ì„¸ë¶€ (v5ì™€ ë™ì¼) ============
        if self.debug_mode:
            print("\n[GATE 4] í¬ì¦ˆ ì„¸ë¶€ ì²´í¬...")
        pose_feedback = self._check_pose_details_debug(curr_kpts, ref_kpts)
        all_gates['pose'] = {
            'feedback': pose_feedback
        }

        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        scores = [g['score'] for g in all_gates.values() if 'score' in g]
        overall_score = sum(scores) / len(scores) if scores else 0

        if self.debug_mode:
            print(f"\n[ìµœì¢… ì ìˆ˜] {overall_score:.1f}/100")

        # ì¹œì ˆí•œ ìš”ì•½ ì½”ë©˜íŠ¸ ìƒì„± (v6 ê°œì„ )
        friendly_summary = self._generate_friendly_summary_v6(all_gates, overall_score)

        return {
            'mode': 'V6_ANALYSIS',
            'overall_score': overall_score,
            'all_gates': all_gates,
            'summary': self._generate_summary(all_gates),
            'friendly_summary': friendly_summary
        }

    def _check_framing_v6(self, curr_kpts: Dict, ref_kpts: Dict,
                         curr_shape: Tuple, ref_shape: Tuple) -> Tuple[float, Dict]:
        """
        v6 í”„ë ˆì´ë° ì²´í¬ - ê°œì„ ëœ ì—¬ë°± ë¶„ì„ í†µí•©
        """
        if self.debug_mode:
            print("\n  [í”„ë ˆì´ë° ì¢…í•© ë¶„ì„ V6]")
            print("  " + "-"*50)

        # ê¸°ì¡´ í”„ë ˆì´ë° ë¶„ì„ (ìƒ· íƒ€ì…, ì¸ë¬¼ ë¹„ì¤‘)
        framing_result = self.framing_analyzer.analyze_framing_comprehensive(
            curr_kpts, ref_kpts, curr_shape, ref_shape
        )

        # v6: ê°œì„ ëœ ì—¬ë°± ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´
        margin_analysis = self.margin_analyzer.analyze_margins_unified(
            curr_kpts, ref_kpts, curr_shape, ref_shape
        )

        # ê¸°ì¡´ í˜•ì‹ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ ë³€í™˜
        framing_result['all_margins'] = convert_to_legacy_format(margin_analysis)
        framing_result['improved_margin_analysis'] = margin_analysis

        # ë””ë²„ê·¸ ì¶œë ¥
        if self.debug_mode:
            self._print_framing_analysis_v6(framing_result, margin_analysis)

        # ì ìˆ˜ ê³„ì‚° (ê°œì„ ëœ ê°€ì¤‘ì¹˜)
        shot_score = framing_result['shot_type']['score']
        subject_score = framing_result['subject_ratio']['score']
        margin_score = margin_analysis['overall_score']

        # v6 ê°€ì¤‘ì¹˜: ì—¬ë°± ë¶„ì„ì˜ ì¤‘ìš”ë„ ì¦ê°€
        weights = {
            'shot_type': 0.25,      # 25% (ê°ì†Œ)
            'subject_ratio': 0.35,   # 35%
            'margins': 0.40         # 40% (ì¦ê°€)
        }

        overall_score = (
            shot_score * weights['shot_type'] +
            subject_score * weights['subject_ratio'] +
            margin_score * weights['margins']
        )

        framing_result['overall_score'] = overall_score

        # v6 í†µí•© í”¼ë“œë°±
        framing_result['feedback'] = self._generate_framing_feedback_v6(
            framing_result, margin_analysis
        )

        return overall_score, framing_result

    def _print_framing_analysis_v6(self, framing_result: Dict, margin_analysis: Dict):
        """v6 í”„ë ˆì´ë° ë¶„ì„ ë””ë²„ê·¸ ì¶œë ¥"""

        # 1. ìƒ· íƒ€ì… (ê¸°ì¡´ê³¼ ë™ì¼)
        shot_data = framing_result['shot_type']
        print(f"\n  [1] ìƒ· íƒ€ì… ë¶„ì„")
        curr_name = shot_data['current'].get('name_kr', shot_data['current'].get('type', 'unknown'))
        ref_name = shot_data['reference'].get('name_kr', shot_data['reference'].get('type', 'unknown'))
        print(f"     Current: {curr_name}")
        print(f"     Reference: {ref_name}")
        print(f"     ì ìˆ˜: {shot_data['score']:.0f}")

        # 2. ì¸ë¬¼ ë¹„ì¤‘ (v6 ê°œì„ : ê±°ë¦¬ ìš°ì„  í”¼ë“œë°±)
        subject_data = framing_result['subject_ratio']
        print(f"\n  [2] ì¸ë¬¼ ë¹„ì¤‘")
        print(f"     Current: í™”ë©´ì˜ {subject_data['current_ratio']*100:.1f}%")
        print(f"     Reference: í™”ë©´ì˜ {subject_data['reference_ratio']*100:.1f}%")
        print(f"     ì ìˆ˜: {subject_data['score']:.0f}")

        # êµ¬ì²´ì  ì¡°ì • ë°©ë²• (ê±°ë¦¬ ìš°ì„ )
        if subject_data.get('detailed_action'):
            detail = subject_data['detailed_action']
            print(f"\n     [ì¡°ì • ë°©ë²•]")
            print(f"       1ìˆœìœ„: {detail['primary']}")
            print(f"       2ìˆœìœ„: {detail['secondary']}")
            print(f"       (ì¸ë¬¼ ë¹„ì¤‘ ì°¨ì´: {detail['ratio_diff']:.1f}%)")

        # 3. v6 í†µí•© ì—¬ë°± ë¶„ì„
        print(f"\n  [3] í†µí•© ì—¬ë°± ë¶„ì„ (V6 ê°œì„ )")

        # ì¢Œìš° ê· í˜•
        h_analysis = margin_analysis['horizontal']
        print(f"\n     [ì¢Œìš° ê· í˜•]")
        curr_m = margin_analysis['current_margins']
        ref_m = margin_analysis['reference_margins']
        print(f"       Current: ì¢Œ {curr_m['left']*100:+.0f}% | ìš° {curr_m['right']*100:+.0f}%")
        print(f"       Reference: ì¢Œ {ref_m['left']*100:+.0f}% | ìš° {ref_m['right']*100:+.0f}%")
        print(f"       ìƒíƒœ: {h_analysis['status']} (ì ìˆ˜: {h_analysis['score']:.0f})")
        if h_analysis.get('out_of_frame_warning'):
            print(f"       âš ï¸ {h_analysis['out_of_frame_warning']}")

        # ìƒí•˜ ê· í˜•
        v_analysis = margin_analysis['vertical']
        print(f"\n     [ìƒí•˜ ê· í˜•]")
        print(f"       Current: ìƒ {curr_m['top']*100:+.0f}% | í•˜ {curr_m['bottom']*100:+.0f}%")
        print(f"       Reference: ìƒ {ref_m['top']*100:+.0f}% | í•˜ {ref_m['bottom']*100:+.0f}%")

        # ì¸ë¬¼ ìœ„ì¹˜ ì •ë³´
        curr_pos = v_analysis.get('current_position', 0.5)
        ref_pos = v_analysis.get('reference_position', 0.5)
        print(f"       ì¸ë¬¼ ìœ„ì¹˜: Current {curr_pos:.2f} vs Reference {ref_pos:.2f} (0=ìƒë‹¨, 1=í•˜ë‹¨)")

        # í•˜ì´ì•µê¸€ ê°ì§€
        v_details = v_analysis.get('details', {})
        if v_details.get('current_is_high_angle'):
            print(f"       âš¡ í•˜ì´ì•µê¸€ ê°ì§€ (ìœ„ì—ì„œ ë‚´ë ¤ë‹¤ë´„)")

        print(f"       ìƒíƒœ: {v_analysis['status']} (ì ìˆ˜: {v_analysis['score']:.0f})")
        if v_analysis.get('out_of_frame_warning'):
            print(f"       âš ï¸ {v_analysis['out_of_frame_warning']}")

        # ì¡°ì • ë°©ë²• (ê°œì„ ë¨)
        if v_analysis.get('adjustment'):
            adj = v_analysis['adjustment']
            if adj['direction'] == 'lower_camera':
                print(f"       ğŸ’¡ {adj['camera_action']}")
            elif adj['direction'] == 'tilt_down':
                print(f"       ğŸ’¡ {adj['camera_action']}")
            elif adj['direction'] == 'tilt_up':
                print(f"       ğŸ’¡ {adj['camera_action']}")

        # í•˜ë‹¨ íŠ¹ë³„ ë¶„ì„
        bottom_special = margin_analysis['bottom_special']
        if bottom_special.get('special_message'):
            print(f"\n     [í•˜ë‹¨ íŠ¹ë³„ ìƒí™©]")
            print(f"       {bottom_special['special_message']}")

        # í†µí•© ì—¬ë°± ì ìˆ˜
        print(f"\n     [ì—¬ë°± ì¢…í•© ì ìˆ˜] {margin_analysis['overall_score']:.0f}/100")

        # 4. í”„ë ˆì´ë° ì¢…í•© ì¡°ì • ë°©ë²•
        self._print_framing_adjustments(framing_result, margin_analysis)

    def _print_framing_adjustments(self, framing_result: Dict, margin_analysis: Dict):
        """í”„ë ˆì´ë° ì¢…í•© ì¡°ì • ë°©ë²• ì¶œë ¥"""

        adjustments = []

        # ìƒ· íƒ€ì… ë¶ˆì¼ì¹˜
        shot_data = framing_result.get('shot_type', {})
        if not shot_data.get('same_category'):
            curr = shot_data.get('current', {}).get('name_kr', '')
            ref = shot_data.get('reference', {}).get('name_kr', '')
            adjustments.append({
                'priority': 1,
                'type': 'shot_type',
                'message': f"ìƒ· íƒ€ì… ë³€ê²½: {curr} â†’ {ref}"
            })

        # ì¸ë¬¼ ë¹„ì¤‘ ì¡°ì •
        subject_data = framing_result.get('subject_ratio', {})
        if subject_data.get('detailed_action'):
            detail = subject_data['detailed_action']
            adjustments.append({
                'priority': 2 if len(adjustments) > 0 else 1,
                'type': 'subject_size',
                'message': detail['primary']
            })

        # ì—¬ë°± ì¡°ì •
        actionable = margin_analysis.get('actionable_feedback', {})
        if actionable.get('primary_action'):
            action = actionable['primary_action']
            priority = len(adjustments) + 1

            if action['type'] == 'horizontal_move':
                message = action['camera']
            elif action['type'] == 'vertical_tilt':
                message = action['camera']
            elif action['type'] == 'bottom_adjustment':
                message = action['message']
            else:
                message = "ì—¬ë°± ì¡°ì • í•„ìš”"

            adjustments.append({
                'priority': priority,
                'type': 'margin',
                'message': message
            })

        # ì¶œë ¥
        if adjustments:
            print(f"\n  [í”„ë ˆì´ë° ì¡°ì • ë°©ë²•]")
            print("  " + "-"*50)

            # ìš°ì„ ìˆœìœ„ ì •ë ¬
            adjustments.sort(key=lambda x: x['priority'])

            for adj in adjustments[:3]:  # ìµœëŒ€ 3ê°œ
                print(f"     {adj['priority']}ìˆœìœ„: {adj['message']}")

            # ì¶”ê°€ íŒ
            if len(adjustments) > 1:
                print(f"\n     ğŸ’¡ íŒ: 1ìˆœìœ„ë¶€í„° ìˆœì„œëŒ€ë¡œ ì¡°ì •í•˜ë©´ì„œ í™•ì¸í•˜ì„¸ìš”")

    def _generate_framing_feedback_v6(self, framing_result: Dict,
                                      margin_analysis: Dict) -> Dict:
        """v6 í†µí•© í”„ë ˆì´ë° í”¼ë“œë°± ìƒì„±"""

        actions = []
        issues = []
        severity = 'minor'

        # 1. ìƒ· íƒ€ì… ì´ìŠˆ
        shot_data = framing_result['shot_type']
        if not shot_data['same_category']:
            issues.append('shot_type_mismatch')
            severity = 'major'
            curr_type = shot_data['current'].get('name_kr', '')
            ref_type = shot_data['reference'].get('name_kr', '')
            actions.append(f"ìƒ· íƒ€ì… ë³€ê²½: {curr_type} â†’ {ref_type}")

        # 2. ì¸ë¬¼ ë¹„ì¤‘ ì´ìŠˆ
        subject_data = framing_result['subject_ratio']
        if subject_data['action']:
            issues.append('subject_ratio')
            actions.append(subject_data['action'])

        # 3. v6 ì—¬ë°± ì´ìŠˆ
        margin_feedback = margin_analysis['actionable_feedback']
        if margin_feedback.get('has_issues'):
            issues.append('margin_imbalance')
            # ì£¼ìš” ì¡°ì •ë§Œ ì¶”ê°€
            if margin_feedback.get('primary_action'):
                action = margin_feedback['primary_action']
                if action['type'] == 'horizontal_move':
                    actions.append(action['camera'])
                elif action['type'] == 'vertical_tilt':
                    actions.append(action['camera'])
                elif action['type'] == 'bottom_adjustment':
                    actions.append(action['message'])

        # ì¢…í•© í‰ê°€
        if not issues:
            summary = "í”„ë ˆì´ë°ì´ ë ˆí¼ëŸ°ìŠ¤ì™€ ê±°ì˜ ë™ì¼í•©ë‹ˆë‹¤!"
            severity = 'excellent'
        elif len(issues) == 1:
            summary = "í”„ë ˆì´ë° ë¯¸ì„¸ ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤"
            severity = 'minor'
        elif len(issues) == 2:
            summary = "í”„ë ˆì´ë° ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤"
            severity = 'moderate'
        else:
            summary = "í”„ë ˆì´ë°ì´ ë ˆí¼ëŸ°ìŠ¤ì™€ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤"
            severity = 'major'

        # ì¹œì ˆí•œ ë©”ì‹œì§€
        friendly_message = self._create_friendly_framing_message_v6(
            shot_data, subject_data, margin_analysis
        )

        return {
            'issues': issues,
            'actions': actions[:3],  # ìµœëŒ€ 3ê°œ
            'summary': summary,
            'severity': severity,
            'friendly_message': friendly_message
        }

    def _create_friendly_framing_message_v6(self, shot: Dict, subject: Dict,
                                           margin_analysis: Dict) -> str:
        """v6 ì¹œì ˆí•œ í”„ë ˆì´ë° ë©”ì‹œì§€"""

        messages = []

        # ìƒ· íƒ€ì…
        if shot['same_category']:
            if shot['score'] >= 90:
                messages.append("ìƒ· íƒ€ì…ì´ ì¼ì¹˜í•©ë‹ˆë‹¤")
        else:
            curr = shot['current'].get('name_kr', '')
            ref = shot['reference'].get('name_kr', '')
            messages.append(f"ìƒ· íƒ€ì… ì¡°ì • í•„ìš” ({curr} â†’ {ref})")

        # ì¸ë¬¼ í¬ê¸° (v6 ê°œì„ : êµ¬ì²´ì  ê±°ë¦¬)
        if subject['direction'] == 'smaller':
            if subject.get('detailed_action'):
                detail = subject['detailed_action']
                messages.append(detail['primary'])
            else:
                messages.append("ì¸ë¬¼ì„ ë” í¬ê²Œ ë‹´ì•„ì£¼ì„¸ìš”")
        elif subject['direction'] == 'larger':
            if subject.get('detailed_action'):
                detail = subject['detailed_action']
                messages.append(detail['primary'])
            else:
                messages.append("ì¸ë¬¼ì„ ë” ì‘ê²Œ ë‹´ì•„ì£¼ì„¸ìš”")

        # ì—¬ë°± ë¬¸ì œ (v6)
        actionable = margin_analysis['actionable_feedback']
        if actionable.get('has_issues') and actionable.get('message'):
            # ì²« ë²ˆì§¸ ì¤„ë§Œ ì¶”ê°€ (ê°„ê²°í•˜ê²Œ)
            first_line = actionable['message'].split('\n')[0]
            if first_line and 'ì¡°ì •' in first_line:
                messages.append(first_line)

        return ". ".join(messages) if messages else "í”„ë ˆì´ë°ì´ ì ì ˆí•©ë‹ˆë‹¤"

    def _generate_friendly_summary_v6(self, all_gates: Dict, overall_score: float) -> str:
        """v6 ì¹œì ˆí•œ ìš”ì•½ ì½”ë©˜íŠ¸ ìƒì„±"""

        passed = []
        failed = []

        # êµ¬ì²´ì  ì¡°ì • ë°©ë²• ìˆ˜ì§‘
        specific_actions = []

        for gate_name, gate_data in all_gates.items():
            if 'passed' in gate_data:
                if gate_data['passed']:
                    if gate_name == 'aspect_ratio':
                        passed.append('ì¢…íš¡ë¹„')
                    elif gate_name == 'framing':
                        passed.append('í”„ë ˆì´ë°')
                    elif gate_name == 'composition':
                        passed.append('êµ¬ë„')
                    elif gate_name == 'compression':
                        passed.append('ì••ì¶•ê°')
                else:
                    if gate_name == 'aspect_ratio':
                        failed.append('ì¢…íš¡ë¹„')
                    elif gate_name == 'framing':
                        failed.append('í”„ë ˆì´ë°')
                        # v6: ê°œì„ ëœ ì—¬ë°± ë¶„ì„ì—ì„œ êµ¬ì²´ì  ì¡°ì • ì¶”ì¶œ
                        if 'details' in gate_data and 'improved_margin_analysis' in gate_data['details']:
                            margin_feedback = gate_data['details']['improved_margin_analysis']['actionable_feedback']
                            if margin_feedback.get('primary_action'):
                                action = margin_feedback['primary_action']
                                if action.get('camera'):
                                    specific_actions.append(action['camera'])
                    elif gate_name == 'composition':
                        failed.append('êµ¬ë„')
                    elif gate_name == 'compression':
                        failed.append('ì••ì¶•ê°')

        # ë©”ì‹œì§€ ìƒì„± (v6 ê°œì„ )
        if overall_score >= 95:
            return "ê±°ì˜ ì™„ë²½í•©ë‹ˆë‹¤! ë ˆí¼ëŸ°ìŠ¤ì™€ ë§¤ìš° ìœ ì‚¬í•´ìš”."
        elif overall_score >= 85:
            if len(failed) == 1:
                if specific_actions:
                    return f"ë ˆí¼ëŸ°ìŠ¤ì™€ ë¹„ìŠ·í•©ë‹ˆë‹¤. {specific_actions[0]}í•˜ë©´ ë” ì¢‹ì•„ì§ˆ ê±°ì˜ˆìš”."
                else:
                    return f"ë ˆí¼ëŸ°ìŠ¤ì™€ ë¹„ìŠ·í•©ë‹ˆë‹¤. {failed[0]}ë§Œ ì¡°ì •í•˜ë©´ ë” ì¢‹ì•„ì§ˆ ê±°ì˜ˆìš”."
            else:
                return "ë ˆí¼ëŸ°ìŠ¤ì™€ ë¹„ìŠ·í•˜ì§€ë§Œ ë¯¸ì„¸ ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤."
        elif overall_score >= 75:
            if specific_actions:
                return f"ì „ë°˜ì ìœ¼ë¡œ ê´œì°®ì§€ë§Œ, {specific_actions[0]}ê°€ í•„ìš”í•´ìš”."
            elif len(passed) >= 2:
                return f"{', '.join(passed)}ì€(ëŠ”) ì˜ ë§ì§€ë§Œ, {', '.join(failed)}ì€(ëŠ”) ì¡°ì •ì´ í•„ìš”í•´ìš”."
            else:
                return "ì „ë°˜ì ìœ¼ë¡œ ê´œì°®ì§€ë§Œ ëª‡ ê°€ì§€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤."
        elif overall_score >= 65:
            if specific_actions:
                return f"ë ˆí¼ëŸ°ìŠ¤ì™€ ì°¨ì´ê°€ ìˆìœ¼ë‹ˆ {specific_actions[0]}ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            else:
                return "ë ˆí¼ëŸ°ìŠ¤ì™€ ì°¨ì´ê°€ ìˆìœ¼ë‹ˆ ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤."
        else:
            if specific_actions:
                return f"ìƒë‹¹í•œ ì°¨ì´ê°€ ìˆì–´ìš”. ë¨¼ì € {specific_actions[0]}í•´ ë³´ì„¸ìš”."
            else:
                return "ìƒë‹¹í•œ ì°¨ì´ê°€ ìˆì–´ ë‹¨ê³„ì  ì¡°ì •ì´ í•„ìš”í•´ìš”."

    # ========== ì´í•˜ v5ì™€ ë™ì¼í•œ í•¨ìˆ˜ë“¤ ==========

    def _extract_keypoints_debug(self, img: np.ndarray, label: str) -> Dict:
        """í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ (v5ì™€ ë™ì¼)"""
        if self.debug_mode:
            print(f"\n[{label} ì´ë¯¸ì§€ í‚¤í¬ì¸íŠ¸ ë¶„ì„]")

        kpts = self.wholebody.extract_wholebody_keypoints(img)

        if self.debug_mode:
            print(f"  ì¸ë¬¼ ìˆ˜: {kpts['num_persons']}ëª…")

            if kpts['num_persons'] > 0:
                body_kpts = kpts.get('body_keypoints', {})
                print(f"\n  [ì‹ ì²´ í‚¤í¬ì¸íŠ¸] {len(body_kpts)}ê°œ ê²€ì¶œ")

                key_parts = ['nose', 'left_shoulder', 'right_shoulder',
                           'left_hip', 'right_hip', 'left_knee', 'right_knee',
                           'left_ankle', 'right_ankle']

                for part in key_parts[:3]:  # ê°„ëµíˆ 3ê°œë§Œ
                    if part in body_kpts:
                        pos = body_kpts[part]['position']
                        conf = body_kpts[part].get('confidence', 0)
                        print(f"    {part:15s}: ({pos[0]:4.0f}, {pos[1]:4.0f}) ì‹ ë¢°ë„={conf:.2f}")

        return kpts

    def _check_aspect_ratio_debug(self, curr_shape: Tuple, ref_shape: Tuple) -> Tuple[float, Optional[Dict]]:
        """ì¢…íš¡ë¹„ ì²´í¬ (v6 ê°œì„ : ì •í™•í•œ ë¹„ìœ¨ í‘œì‹œ)"""
        # shapeëŠ” (height, width) ìˆœì„œ
        curr_ratio = curr_shape[1] / curr_shape[0]  # width / height
        ref_ratio = ref_shape[1] / ref_shape[0]

        def get_ratio_name(ratio):
            """ì¢…íš¡ë¹„ë¥¼ ì´ë¦„ìœ¼ë¡œ ë³€í™˜ (ë„ˆë¹„:ë†’ì´ í˜•ì‹)"""
            if abs(ratio - 1.0) < 0.1:
                return "1:1 (ì •ì‚¬ê°í˜•)"
            elif abs(ratio - 1.33) < 0.1:
                return "4:3 (ê°€ë¡œ)"
            elif abs(ratio - 1.5) < 0.1:
                return "3:2 (ê°€ë¡œ DSLR)"
            elif abs(ratio - 1.78) < 0.1:
                return "16:9 (ê°€ë¡œ ì™€ì´ë“œ)"
            elif abs(ratio - 0.75) < 0.1:
                return "3:4 (ì„¸ë¡œ)"  # 0.75 = 3/4 = ë„ˆë¹„ 3, ë†’ì´ 4
            elif abs(ratio - 0.67) < 0.1:
                return "2:3 (ì„¸ë¡œ DSLR)"
            elif abs(ratio - 0.56) < 0.1:
                return "9:16 (ì„¸ë¡œ ì™€ì´ë“œ)"
            else:
                # ê¸°ë³¸ê°’
                if ratio > 1:
                    return f"{ratio:.2f}:1 (ê°€ë¡œ)"
                else:
                    return f"1:{(1/ratio):.2f} (ì„¸ë¡œ)"

        curr_name = get_ratio_name(curr_ratio)
        ref_name = get_ratio_name(ref_ratio)

        if self.debug_mode:
            print(f"  Current ì´ë¯¸ì§€: {curr_shape[1]}x{curr_shape[0]} (WxH)")
            print(f"    ì¢…íš¡ë¹„: {curr_ratio:.3f} = {curr_name}")
            print(f"  Reference ì´ë¯¸ì§€: {ref_shape[1]}x{ref_shape[0]} (WxH)")
            print(f"    ì¢…íš¡ë¹„: {ref_ratio:.3f} = {ref_name}")

        diff = abs(curr_ratio - ref_ratio)

        if diff < 0.1:
            if self.debug_mode:
                print(f"  -> ì¢…íš¡ë¹„ ì¼ì¹˜")
            return 100, None

        score = max(30, 100 - (diff * 100))

        if self.debug_mode:
            print(f"  -> ì¢…íš¡ë¹„ ë¶ˆì¼ì¹˜ (ì ìˆ˜: {score:.0f})")
            print(f"  ğŸ“ ì¡°ì • ë°©ë²•: {ref_name}ë¡œ ë¹„ìœ¨ì„ ë³€ê²½í•˜ì„¸ìš”")

            # êµ¬ì²´ì ì¸ ë³€ê²½ ë°©ë²• ì œì•ˆ
            if "16:9" in ref_name and "4:3" in curr_name:
                print(f"     ì¹´ë©”ë¼ ì„¤ì •ì—ì„œ 16:9 ì™€ì´ë“œìŠ¤í¬ë¦°ìœ¼ë¡œ ë³€ê²½")
            elif "4:3" in ref_name and "16:9" in curr_name:
                print(f"     ì¹´ë©”ë¼ ì„¤ì •ì—ì„œ 4:3 í‘œì¤€ ë¹„ìœ¨ë¡œ ë³€ê²½")
            elif "1:1" in ref_name:
                print(f"     ì¹´ë©”ë¼ ì„¤ì •ì—ì„œ ì •ì‚¬ê°í˜•(1:1)ìœ¼ë¡œ ë³€ê²½")
            elif "9:16" in ref_name or "3:4" in ref_name:
                print(f"     ì„¸ë¡œ ëª¨ë“œë¡œ ì´¬ì˜í•˜ê³  {ref_name} ë¹„ìœ¨ë¡œ ì„¤ì •")

        return score, {
            'issue': 'ASPECT_RATIO_MISMATCH',
            'diff': diff,
            'current_name': curr_name,
            'target_name': ref_name,
            'action': f"{ref_name}ë¡œ ë¹„ìœ¨ì„ ë³€ê²½í•˜ì„¸ìš”"
        }

    def _check_composition_debug(self, curr_kpts: Dict, ref_kpts: Dict,
                                curr_shape: Tuple, ref_shape: Tuple) -> Tuple[float, Optional[Dict]]:
        """êµ¬ë„ ì²´í¬ (v5ì™€ ë™ì¼)"""
        if self.debug_mode:
            print("\n  [êµ¬ë„ ë¶„ì„]")

        curr_center = self._calculate_face_center(curr_kpts, curr_shape)
        ref_center = self._calculate_face_center(ref_kpts, ref_shape)

        if not curr_center or not ref_center:
            return 75, None

        curr_grid = self._to_grid_position(curr_center)
        ref_grid = self._to_grid_position(ref_center)

        if self.debug_mode:
            print(f"  Current ì–¼êµ´: ({curr_center[0]:.2f}, {curr_center[1]:.2f}) â†’ {curr_grid}")
            print(f"  Reference ì–¼êµ´: ({ref_center[0]:.2f}, {ref_center[1]:.2f}) â†’ {ref_grid}")

        if curr_grid == ref_grid:
            if self.debug_mode:
                print(f"  -> êµ¬ë„ ì¼ì¹˜")
            return 90, None

        distance = math.sqrt((curr_center[0] - ref_center[0])**2 +
                           (curr_center[1] - ref_center[1])**2)
        score = max(40, 80 - (distance * 100))

        if self.debug_mode:
            print(f"  -> êµ¬ë„ ë¶ˆì¼ì¹˜ (ì ìˆ˜: {score:.0f})")

        return score, {
            'issue': 'POSITION_MISMATCH',
            'current_grid': curr_grid,
            'target_grid': ref_grid
        }

    def _check_compression_debug(self, legacy_result: Any, device_type: str) -> Tuple[float, Optional[Dict]]:
        """ì••ì¶•ê° ì²´í¬ (v6 ê°œì„ : ê´‘ê°/ë§ì› ê°ì§€ + êµ¬ì²´ì  ì¡°ì •)"""
        if self.debug_mode:
            print("\n  [ì••ì¶•ê° ë¶„ì„]")

        if not hasattr(legacy_result, 'detailed_feedback'):
            return 80, None

        if 'compression' not in legacy_result.detailed_feedback:
            return 80, None

        comp_data = legacy_result.detailed_feedback['compression']

        import re
        curr_match = re.search(r'\(([0-9.]+)\)', comp_data.get('current', ''))
        ref_match = re.search(r'\(([0-9.]+)\)', comp_data.get('reference', ''))

        if not (curr_match and ref_match):
            return 80, None

        curr_comp = float(curr_match.group(1))
        ref_comp = float(ref_match.group(1))

        def describe_lens_type(value):
            """ë Œì¦ˆ íƒ€ì… íŒë³„"""
            if value < 0.3:
                return "ê´‘ê°ë Œì¦ˆ", "wide"
            elif value < 0.45:
                return "ì¤€ê´‘ê°", "semi-wide"
            elif value < 0.6:
                return "í‘œì¤€ë Œì¦ˆ", "normal"
            elif value < 0.75:
                return "ì¤‘ë§ì›", "medium-tele"
            else:
                return "ë§ì›ë Œì¦ˆ", "telephoto"

        curr_lens, curr_type = describe_lens_type(curr_comp)
        ref_lens, ref_type = describe_lens_type(ref_comp)

        if self.debug_mode:
            print(f"  Current: {curr_comp:.2f} ({curr_lens})")
            print(f"  Reference: {ref_comp:.2f} ({ref_lens})")

        diff = abs(ref_comp - curr_comp)

        if diff < 0.05:
            if self.debug_mode:
                print(f"  -> ì••ì¶•ê° ì¼ì¹˜")
            return 95, None

        # ì ìˆ˜ ê³„ì‚°
        if diff < 0.2:
            score = 95 - (diff - 0.05) * 100
        elif diff < 0.4:
            score = 80 - (diff - 0.2) * 75
        else:
            score = max(50, 65 - (diff - 0.4) * 50)

        # êµ¬ì²´ì  ì¡°ì • ë°©ë²• ìƒì„±
        adjustment_message = self._generate_compression_adjustment(
            curr_comp, ref_comp, curr_lens, ref_lens
        )

        if self.debug_mode:
            print(f"  -> ì••ì¶•ê° ì°¨ì´ (ì ìˆ˜: {score:.0f})")
            print(f"\n  ğŸ“· ì¡°ì • ë°©ë²•:")
            for line in adjustment_message.split('\n'):
                if line.strip():
                    print(f"     {line.strip()}")

        return score, {
            'issue': 'COMPRESSION_MISMATCH',
            'current_compression': curr_comp,
            'target_compression': ref_comp,
            'current_lens': curr_lens,
            'target_lens': ref_lens,
            'adjustment': adjustment_message
        }

    def _generate_compression_adjustment(self, curr_comp: float, ref_comp: float,
                                        curr_lens: str, ref_lens: str) -> str:
        """ì••ì¶•ê° ì¡°ì • ë©”ì‹œì§€ ìƒì„±"""

        messages = []

        if curr_comp < ref_comp:  # í˜„ì¬ê°€ ë” ê´‘ê°
            diff_level = ref_comp - curr_comp

            if diff_level < 0.15:
                messages.append(f"í˜„ì¬ ì‚¬ì§„ì´ ë ˆí¼ëŸ°ìŠ¤ë³´ë‹¤ ì•½ê°„ ë” ê´‘ê°ì…ë‹ˆë‹¤ (ì••ì¶•ê° {curr_comp:.2f} vs {ref_comp:.2f})")
                messages.append("í•œë‘ ê±¸ìŒ ë’¤ë¡œ ë¬¼ëŸ¬ë‚œ ë’¤, ì¤Œì„ í•œ ë‹¨ê³„ í‚¤ì›Œì„œ ì´¬ì˜í•˜ë©´")
                messages.append("ë°°ê²½ì´ ì¡°ê¸ˆ ë” ë‹¹ê²¨ì§€ê³ , ë ˆí¼ëŸ°ìŠ¤ì— ê°€ê¹Œìš´ ì••ì¶•ê°ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            elif diff_level < 0.3:
                messages.append(f"í˜„ì¬ {curr_lens}ë¡œ ì´¬ì˜ë˜ì–´ ë ˆí¼ëŸ°ìŠ¤({ref_lens})ë³´ë‹¤ ê´‘ê°ì…ë‹ˆë‹¤")
                messages.append("ëª‡ ê±¸ìŒ ë’¤ë¡œ ë¬¼ëŸ¬ë‚˜ì„œ ì¤Œì„ 2-3ë‹¨ê³„ í‚¤ìš°ê±°ë‚˜")
                messages.append("ë” ê¸´ ì´ˆì ê±°ë¦¬ì˜ ë Œì¦ˆë¥¼ ì‚¬ìš©í•˜ì„¸ìš”")
                messages.append("ë°°ê²½ì´ í”¼ì‚¬ì²´ì™€ ê°€ê¹Œì›Œ ë³´ì´ëŠ” íš¨ê³¼ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            else:
                messages.append(f"ìƒë‹¹í•œ ì••ì¶•ê° ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤ ({curr_lens} â†’ {ref_lens})")
                messages.append("ì—¬ëŸ¬ ê±¸ìŒ ë’¤ë¡œ ë¬¼ëŸ¬ë‚˜ì„œ ìµœëŒ€í•œ ì¤Œì¸í•˜ê±°ë‚˜")
                messages.append("ë§ì› ë Œì¦ˆë¡œ êµì²´í•˜ì—¬ ì´¬ì˜í•˜ì„¸ìš”")

        else:  # í˜„ì¬ê°€ ë” ë§ì›
            diff_level = curr_comp - ref_comp

            if diff_level < 0.15:
                messages.append(f"í˜„ì¬ ì‚¬ì§„ì´ ë ˆí¼ëŸ°ìŠ¤ë³´ë‹¤ ì•½ê°„ ë” ì••ì¶•ë˜ì–´ ìˆìŠµë‹ˆë‹¤ (ì••ì¶•ê° {curr_comp:.2f} vs {ref_comp:.2f})")
                messages.append("í•œë‘ ê±¸ìŒ ì•ìœ¼ë¡œ ë‹¤ê°€ê°„ ë’¤, ì¤Œì„ í•œ ë‹¨ê³„ ì¤„ì—¬ì„œ ì´¬ì˜í•˜ë©´")
                messages.append("ë°°ê²½ì´ ì¡°ê¸ˆ ë” ë„“ì–´ì§€ê³ , ë ˆí¼ëŸ°ìŠ¤ì— ê°€ê¹Œìš´ ëŠë‚Œì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            elif diff_level < 0.3:
                messages.append(f"í˜„ì¬ {curr_lens}ë¡œ ì´¬ì˜ë˜ì–´ ë ˆí¼ëŸ°ìŠ¤({ref_lens})ë³´ë‹¤ ì••ì¶•ê°ì´ ê°•í•©ë‹ˆë‹¤")
                messages.append("ëª‡ ê±¸ìŒ ì•ìœ¼ë¡œ ë‹¤ê°€ê°€ì„œ ì¤Œì„ 2-3ë‹¨ê³„ ì¤„ì´ê±°ë‚˜")
                messages.append("ë” ì§§ì€ ì´ˆì ê±°ë¦¬ì˜ ë Œì¦ˆë¥¼ ì‚¬ìš©í•˜ì„¸ìš”")
                messages.append("ë°°ê²½ì´ ë” ë„“ê³  ê³µê°„ê° ìˆê²Œ ë³´ì¼ ê²ƒì…ë‹ˆë‹¤")
            else:
                messages.append(f"ìƒë‹¹í•œ ì••ì¶•ê° ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤ ({curr_lens} â†’ {ref_lens})")
                messages.append("ì—¬ëŸ¬ ê±¸ìŒ ì•ìœ¼ë¡œ ë‹¤ê°€ê°€ì„œ ì¤Œì•„ì›ƒí•˜ê±°ë‚˜")
                messages.append("ê´‘ê° ë Œì¦ˆë¡œ êµì²´í•˜ì—¬ ì´¬ì˜í•˜ì„¸ìš”")

        return "\n".join(messages)

    def _check_pose_details_debug(self, curr_kpts: Dict, ref_kpts: Dict) -> Optional[List[Dict]]:
        """í¬ì¦ˆ ì„¸ë¶€ ì²´í¬ (v5ì™€ ë™ì¼)"""
        if self.debug_mode:
            print("\n  [í¬ì¦ˆ ì„¸ë¶€ ë¶„ì„]")

        minor_adjustments = []
        curr_body = curr_kpts.get('body_keypoints', {})

        # ì–´ê¹¨ ì •ë ¬ ì²´í¬
        if 'left_shoulder' in curr_body and 'right_shoulder' in curr_body:
            curr_left = curr_body['left_shoulder']['position']
            curr_right = curr_body['right_shoulder']['position']

            dx = curr_right[0] - curr_left[0]
            dy = curr_right[1] - curr_left[1]
            angle_deg = math.degrees(math.atan2(dy, dx))

            if abs(angle_deg) > 90:
                deviation = abs(abs(angle_deg) - 180)
            else:
                deviation = abs(angle_deg)

            if self.debug_mode:
                print(f"  ì–´ê¹¨ ê¸°ìš¸ê¸°: {deviation:.1f}ë„")

            if deviation > 20:
                minor_adjustments.append({
                    'category': 'posture',
                    'importance': 'optional',
                    'suggestion': f"ì–´ê¹¨ê°€ ê¸°ìš¸ì–´ì ¸ ìˆìŠµë‹ˆë‹¤ ({deviation:.1f}ë„)"
                })

        return minor_adjustments if minor_adjustments else None

    def _generate_integrated_feedback_v6(self, all_gates: Dict) -> Optional[Dict]:
        """
        V6 í†µí•© í”¼ë“œë°± ìƒì„±
        ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ í•˜ë‚˜ì˜ ì‹¤í–‰ ê°€ëŠ¥í•œ ì§€ì‹œ ìƒì„±
        """
        framing_gate = all_gates.get('framing', {})
        compression_gate = all_gates.get('compression', {})

        if not framing_gate.get('details'):
            return None

        framing_details = framing_gate['details']
        subject_data = framing_details.get('subject_ratio', {})
        margin_analysis = framing_details.get('improved_margin_analysis', {})
        compression_feedback = compression_gate.get('feedback')

        # ë¬¸ì œ ìˆ˜ì§‘
        problems = []

        # 1. ì¸ë¬¼ í¬ê¸°
        if subject_data.get('direction') == 'smaller':
            detailed = subject_data.get('detailed_action', {})
            problems.append({
                'type': 'subject_small',
                'priority': 1,
                'ratio_diff': detailed.get('ratio_diff', 0),
                'distance': self._estimate_distance(detailed.get('ratio_diff', 0))
            })
        elif subject_data.get('direction') == 'larger':
            detailed = subject_data.get('detailed_action', {})
            problems.append({
                'type': 'subject_large',
                'priority': 1,
                'ratio_diff': detailed.get('ratio_diff', 0),
                'distance': self._estimate_distance(detailed.get('ratio_diff', 0))
            })

        # 2. ìƒí•˜ ì—¬ë°±
        v_analysis = margin_analysis.get('vertical', {})
        if v_analysis.get('adjustment'):
            adj = v_analysis['adjustment']
            problems.append({
                'type': 'vertical_position',
                'priority': 2,
                'adjustment': adj,
                'is_high_angle': adj.get('is_high_angle', False)
            })

        # 3. ì¢Œìš° ì—¬ë°±
        h_analysis = margin_analysis.get('horizontal', {})
        if h_analysis.get('adjustment'):
            problems.append({
                'type': 'horizontal_position',
                'priority': 3,
                'adjustment': h_analysis['adjustment']
            })

        # 4. ì••ì¶•ê°
        if compression_feedback and compression_feedback.get('issue'):
            problems.append({
                'type': 'compression',
                'priority': 4,
                'feedback': compression_feedback
            })

        if not problems:
            return None

        # ìš°ì„ ìˆœìœ„ ì •ë ¬
        problems.sort(key=lambda x: x['priority'])

        # í†µí•© ì§€ì‹œ ìƒì„±
        return self._create_unified_instruction(problems, subject_data, v_analysis, h_analysis)

    def _estimate_distance(self, ratio_diff: float) -> str:
        """ë¹„ìœ¨ ì°¨ì´ë¥¼ ê±°ë¦¬ë¡œ ë³€í™˜"""
        if ratio_diff < 10:
            return "í•œ ê±¸ìŒ"
        elif ratio_diff < 20:
            return "ë‘ì„¸ ê±¸ìŒ"
        else:
            return "ì—¬ëŸ¬ ê±¸ìŒ"

    def _create_unified_instruction(self, problems: List[Dict],
                                   subject_data: Dict, v_analysis: Dict,
                                   h_analysis: Dict) -> Dict:
        """
        í†µí•© ì‹¤í–‰ ì§€ì‹œ ìƒì„±
        """
        # ì£¼ìš” ë¬¸ì œ íŒŒì•…
        has_size_issue = any(p['type'] in ['subject_small', 'subject_large'] for p in problems)
        has_vertical_issue = any(p['type'] == 'vertical_position' for p in problems)
        has_horizontal_issue = any(p['type'] == 'horizontal_position' for p in problems)

        # ë‹¨ì¼ ì§€ì‹œ ìƒì„±
        instructions = []
        step_by_step = []
        expected_results = []

        # 1. ì „í›„ ì´ë™ (ì¸ë¬¼ í¬ê¸°)
        if has_size_issue:
            size_problem = next(p for p in problems if p['type'] in ['subject_small', 'subject_large'])

            if size_problem['type'] == 'subject_small':
                distance = size_problem['distance']
                instructions.append(f"í”¼ì‚¬ì²´ ìª½ìœ¼ë¡œ {distance} ì´ë™")
                step_by_step.append(f"ì¹´ë©”ë¼ë¥¼ í”¼ì‚¬ì²´ ìª½ìœ¼ë¡œ {distance} ì•ìœ¼ë¡œ ì´ë™")
                expected_results.append("ì¸ë¬¼ì´ í™”ë©´ì„ ë” ë§ì´ ì±„ì›€")

                # ìƒí•˜ ì¡°ì •ê³¼ í†µí•©
                if has_vertical_issue:
                    v_problem = next(p for p in problems if p['type'] == 'vertical_position')
                    adj = v_problem['adjustment']

                    if adj['direction'] == 'lower_camera' and adj.get('is_high_angle'):
                        # í•˜ì´ì•µê¸€ + ì¸ë¬¼ ì‘ìŒ â†’ ì•ìœ¼ë¡œ ê°€ë©´ì„œ ì¹´ë©”ë¼ë¥¼ ë‚´ë¦¬ê³  í‰í–‰í•˜ê²Œ
                        instructions[0] = f"í”¼ì‚¬ì²´ ìª½ìœ¼ë¡œ {distance} ì´ë™í•˜ë©´ì„œ ì¹´ë©”ë¼ë¥¼ ì•„ë˜ë¡œ ë‚´ë¦¬ê¸°"
                        step_by_step.append("ë™ì‹œì— ì¹´ë©”ë¼ ë†’ì´ë¥¼ ë‚®ì¶”ê³  ì•µê¸€ì„ í‰í–‰í•˜ê²Œ ì¡°ì •")
                        expected_results.append("ì¸ë¬¼ì´ í™”ë©´ ì¤‘ì•™ìœ¼ë¡œ ì´ë™")
                    elif adj['direction'] == 'tilt_down':
                        instructions[0] = f"í”¼ì‚¬ì²´ ìª½ìœ¼ë¡œ {distance} ì´ë™í•˜ë©´ì„œ ì¹´ë©”ë¼ë¥¼ ì•„ë˜ë¡œ í‹¸íŠ¸"
                        step_by_step.append(f"ë™ì‹œì— ì¹´ë©”ë¼ë¥¼ {adj['angle']}ë„ ì•„ë˜ë¡œ í‹¸íŠ¸")
                        expected_results.append("ì¸ë¬¼ì´ í™”ë©´ ì¤‘ì•™ìœ¼ë¡œ ì´ë™")

            else:  # subject_large
                distance = size_problem['distance']
                instructions.append(f"í”¼ì‚¬ì²´ì—ì„œ {distance} ë’¤ë¡œ ì´ë™")
                step_by_step.append(f"ì¹´ë©”ë¼ë¥¼ í”¼ì‚¬ì²´ì—ì„œ {distance} ë’¤ë¡œ ì´ë™")
                expected_results.append("ì¸ë¬¼ í¬ê¸°ê°€ ì ì ˆí•´ì§")

        # 2. ì¢Œìš° ì´ë™ (ë³„ë„ë¡œ í•„ìš”í•œ ê²½ìš°ë§Œ)
        if has_horizontal_issue and not (has_size_issue and has_vertical_issue):
            h_problem = next(p for p in problems if p['type'] == 'horizontal_position')
            adj = h_problem['adjustment']
            step_by_step.append(f"ì¶”ê°€ë¡œ {adj['camera_action']}")

        # ì£¼ìš” ì§€ì‹œë¬¸ ìƒì„±
        if instructions:
            primary = instructions[0]
        else:
            primary = "í˜„ì¬ êµ¬ë„ê°€ ì ì ˆí•©ë‹ˆë‹¤"

        return {
            'has_issues': len(problems) > 0,
            'primary_instruction': primary,
            'step_by_step': step_by_step,
            'expected_result': expected_results,
            'problems_detected': [p['type'] for p in problems]
        }

    def _generate_summary(self, all_gates: Dict) -> str:
        """ì „ì²´ ë¶„ì„ ìš”ì•½ ìƒì„± (v5ì™€ ë™ì¼)"""
        summary = []

        gates_info = [
            ('aspect_ratio', 'ì¢…íš¡ë¹„'),
            ('framing', 'í”„ë ˆì´ë°'),
            ('composition', 'êµ¬ë„'),
            ('compression', 'ì••ì¶•ê°')
        ]

        for gate_key, gate_name in gates_info:
            if gate_key in all_gates:
                gate = all_gates[gate_key]
                if 'score' in gate:
                    status = "[OK]" if gate['passed'] else "[!]"
                    summary.append(f"{status} {gate_name}: {gate['score']:.0f}ì ")

        return "\n".join(summary)

    def _load_image(self, path: str) -> Optional[np.ndarray]:
        """ì´ë¯¸ì§€ ë¡œë“œ (v5ì™€ ë™ì¼)"""
        try:
            if 'PIL' in sys.modules:
                img = Image.open(path).convert('RGB')
                return np.array(img)
            else:
                img = cv2.imread(path)
                return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        except Exception as e:
            print(f"[ERROR] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def _calculate_face_center(self, kpts: Dict, img_shape: Tuple) -> Optional[Tuple[float, float]]:
        """ì–¼êµ´ ì¤‘ì‹¬ ê³„ì‚° (v5ì™€ ë™ì¼)"""
        if kpts['num_persons'] == 0:
            return None

        face = kpts.get('face_landmarks', {})

        if len(face) > 30:
            positions = [kpt['position'] for kpt in face.values()]
            avg_x = np.mean([p[0] for p in positions]) / img_shape[1]
            avg_y = np.mean([p[1] for p in positions]) / img_shape[0]
            return (avg_x, avg_y)

        if 'nose' in kpts.get('body_keypoints', {}):
            nose = kpts['body_keypoints']['nose']['position']
            return (nose[0] / img_shape[1], nose[1] / img_shape[0])

        return None

    def _to_grid_position(self, pos: Tuple[float, float]) -> Tuple[int, int]:
        """3ë¶„í•  êµ¬ë„ ìœ„ì¹˜ ë³€í™˜ (v5ì™€ ë™ì¼)"""
        grid_x = min(int(pos[0] * 3) + 1, 3)
        grid_y = min(int(pos[1] * 3) + 1, 3)
        return (grid_x, grid_y)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    try:
        print("\n" + "="*70)
        print("  TryAngle v6 - ê°œì„ ëœ ì—¬ë°± ë¶„ì„  ")
        print("="*70)

        # ì‹œìŠ¤í…œ ì´ˆê¸°í™” (v6)
        feedback_system = SmartFeedbackV6(language='ko', debug_mode=True)

        # ì´ë¯¸ì§€ ì…ë ¥
        print("\n[ì´ë¯¸ì§€ ì…ë ¥]")
        print("-" * 40)

        current_path = input("Current ì´ë¯¸ì§€ ê²½ë¡œ: ").strip().replace('"', '').replace("'", '')
        if not Path(current_path).exists():
            print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {current_path}")
            return

        reference_path = input("Reference ì´ë¯¸ì§€ ê²½ë¡œ: ").strip().replace('"', '').replace("'", '')
        if not Path(reference_path).exists():
            print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_path}")
            return

        # ë¶„ì„ ì‹¤í–‰
        print("\n[ì²˜ë¦¬ ì¤‘...]")

        start_time = time.time()

        result = feedback_system.analyze_with_gates(
            current_path=current_path,
            reference_path=reference_path,
            device_type='generic',
            test_mode=True
        )

        total_time = time.time() - start_time

        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*70)
        print("[ë¶„ì„ ì™„ë£Œ]")
        print("="*70)

        print(f"\n[ì „ì²´ ì ìˆ˜] {result.get('overall_score', 0):.0f}/100")

        print(f"\n[ìš”ì•½]")
        print(result.get('summary', ''))

        # ì¹œì ˆí•œ ìš”ì•½
        if 'friendly_summary' in result:
            print(f"\n[ì¹œì ˆí•œ í”¼ë“œë°±]")
            print(result.get('friendly_summary', ''))

        print(f"\në¶„ì„ ì‹œê°„: {total_time:.1f}ì´ˆ")

        # ì¬ì‹¤í–‰
        print("\n" + "="*70)
        again = input("\në‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ë¹„êµí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower()
        if again == 'y':
            main()
        else:
            print("\nv6 ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")

    except KeyboardInterrupt:
        print("\n\nì¢…ë£Œí•©ë‹ˆë‹¤...")
    except Exception as e:
        print(f"\nì˜¤ë¥˜: {e}")
        traceback.print_exc()

    # =================== v7 ì¶”ê°€ ë©”ì„œë“œ ===================

    def _analyze_reference_fast(self, reference_path: str) -> Dict[str, Any]:
        """
        ë¹ ë¥¸ ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„ (Legacy ì—†ì´)
        RTMPoseë§Œ ì‚¬ìš©í•˜ì—¬ iOSì—ì„œ ë¹ ë¥´ê²Œ ë¶„ì„
        """
        ref_img = self._load_image(reference_path)
        if ref_img is None:
            return {'error': 'ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨'}

        # RTMPose í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
        ref_kpts = self.wholebody.extract_wholebody_keypoints(ref_img)

        # ì—¬ë°± ë¶„ì„ (RTMPose ê¸°ë°˜)
        margin_result = self.margin_analyzer.analyze_margins_unified(
            ref_kpts, ref_kpts,  # ìê¸° ìì‹ ê³¼ ë¹„êµ
            ref_img.shape, ref_img.shape
        )

        # í”„ë ˆì´ë° ë¶„ì„
        framing_result = self.framing_analyzer.analyze(ref_kpts, ref_img.shape)

        return {
            'keypoints': ref_kpts,
            'margins': margin_result['current_margins'],
            'framing': framing_result,
            'image_shape': ref_img.shape,
            'mode': 'fast',
            'timestamp': time.time()
        }

    def _analyze_reference_full(self, reference_path: str) -> Dict[str, Any]:
        """
        ì™„ì „í•œ ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„ (Legacy ì‚¬ìš©)
        Grounding DINO + Depth Anything í¬í•¨
        """
        # Legacy ì‹œìŠ¤í…œìœ¼ë¡œ ì •ë°€ ë¶„ì„
        legacy_result = self.legacy_comparator.analyze_image(reference_path)

        # RTMPose í‚¤í¬ì¸íŠ¸ë„ ì¶”ì¶œ
        ref_img = self._load_image(reference_path)
        ref_kpts = self.wholebody.extract_wholebody_keypoints(ref_img)

        return {
            'keypoints': ref_kpts,
            'legacy_analysis': legacy_result,
            'margins': {
                'top': legacy_result.margins[0],
                'right': legacy_result.margins[1],
                'bottom': legacy_result.margins[2],
                'left': legacy_result.margins[3]
            },
            'compression': legacy_result.compression_index,
            'person_bbox': legacy_result.person_bbox,
            'image_shape': ref_img.shape,
            'mode': 'full',
            'timestamp': time.time()
        }

    def _compare_realtime(self, curr_kpts: Dict, ref_cache: Dict, curr_shape: Tuple) -> Dict[str, Any]:
        """
        ì‹¤ì‹œê°„ ë¹„êµ (ìºì‹œëœ ë ˆí¼ëŸ°ìŠ¤ì™€)
        """
        ref_kpts = ref_cache['keypoints']
        ref_shape = ref_cache['image_shape']

        # ì—¬ë°± ë¶„ì„
        margin_result = self.margin_analyzer.analyze_margins_unified(
            curr_kpts, ref_kpts,
            curr_shape, ref_shape
        )

        # í”„ë ˆì´ë° ë¶„ì„
        framing_result = self.framing_analyzer.analyze(curr_kpts, curr_shape)

        # ê°„ë‹¨í•œ í”¼ë“œë°± ìƒì„±
        feedback = self._generate_realtime_feedback(
            margin_result, framing_result, ref_cache
        )

        return {
            'margins': margin_result,
            'framing': framing_result,
            'feedback': feedback,
            'processing_time': time.time() - ref_cache['timestamp']
        }

    def _generate_realtime_feedback(self, margin_result: Dict, framing_result: Dict, ref_cache: Dict) -> str:
        """
        ì‹¤ì‹œê°„ í”¼ë“œë°± ìƒì„± (ê°„ë‹¨í•˜ê³  ì§ê´€ì )
        """
        feedbacks = []

        # ì—¬ë°± í”¼ë“œë°±
        if margin_result['actionable_feedback']:
            if margin_result['actionable_feedback'].get('horizontal'):
                h_feedback = margin_result['actionable_feedback']['horizontal']
                if 'ì™¼ìª½' in h_feedback:
                    feedbacks.append("â† ì™¼ìª½ìœ¼ë¡œ")
                elif 'ì˜¤ë¥¸ìª½' in h_feedback:
                    feedbacks.append("â†’ ì˜¤ë¥¸ìª½ìœ¼ë¡œ")

            if margin_result['actionable_feedback'].get('vertical'):
                v_feedback = margin_result['actionable_feedback']['vertical']
                if 'ìœ„ë¡œ' in v_feedback or 'ì˜¬ë ¤' in v_feedback:
                    feedbacks.append("â†‘ ìœ„ë¡œ")
                elif 'ì•„ë˜' in v_feedback or 'ë‚´ë ¤' in v_feedback:
                    feedbacks.append("â†“ ì•„ë˜ë¡œ")

        # í”„ë ˆì´ë° í”¼ë“œë°±
        if framing_result and 'subject_ratio' in framing_result:
            ratio = framing_result['subject_ratio']
            if ratio < 0.3:
                feedbacks.append("ğŸ” ê°€ê¹Œì´")
            elif ratio > 0.6:
                feedbacks.append("ğŸ” ë©€ë¦¬")

        # ìµœëŒ€ 2ê°œ í”¼ë“œë°±ë§Œ í‘œì‹œ
        if feedbacks:
            return " | ".join(feedbacks[:2])
        else:
            return "âœ“ ì¢‹ì•„ìš”"


if __name__ == "__main__":
    # v7 í…ŒìŠ¤íŠ¸ìš© mainì€ ë”°ë¡œ ì‘ì„± í•„ìš”
    print("[SmartFeedbackV7] í…ŒìŠ¤íŠ¸ëŠ” tests/test_realtime.pyë¥¼ ì‚¬ìš©í•˜ì„¸ìš”")