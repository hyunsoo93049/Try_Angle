# TryAngleApp UI ë ‰ ë¬¸ì œ í•´ê²° ì„¤ê³„ì„œ

## ğŸ“‹ í˜„ì¬ ìƒíƒœ ë¶„ì„ ìš”ì•½

### ğŸ”´ ê·¹ë„ë¡œ ì‹¬ê°í•œ ë¬¸ì œ (ì¦‰ì‹œ í•´ê²° í•„ìš”)

| ë¬¸ì œ | íŒŒì¼:ë¼ì¸ | ì˜í–¥ | ì†Œìš” ì‹œê°„ |
|------|---------|------|----------|
| Depth ì„¸ë§ˆí¬ì–´ ë¸”ë¡œí‚¹ | RealtimeAnalyzer.swift:320-347 | ë©”ì¸ ìŠ¤ë ˆë“œ ìµœëŒ€ 5ì´ˆ í”„ë¦¬ì§• | 200-5000ms |
| Gate System ë©”ì¸ ìŠ¤ë ˆë“œ ì‹¤í–‰ | RealtimeAnalyzer.swift:773-788 | UI ë°˜ì‘ì„± ì €í•˜ | 50-100ms |
| RTMPose ë™ê¸° ì‹¤í–‰ | RTMPoseRunner.swift:147-177 | í”„ë ˆì„ ë“œë¡­, í„°ì¹˜ ì§€ì—° | 175ms |
| processAnalysisResult ë©”ì¸ ìŠ¤ë ˆë“œ | RealtimeAnalyzer.swift:560-829 | ëª¨ë“  ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ ì§€ì—° | 100-200ms |

### ğŸŸ¡ ì¤‘ê°„ ì‹¬ê°ë„ ë¬¸ì œ

| ë¬¸ì œ | íŒŒì¼:ë¼ì¸ | ì˜í–¥ | ì†Œìš” ì‹œê°„ |
|------|---------|------|----------|
| ì¹´ë©”ë¼ í”„ë ˆì„ ë§¤ ì—…ë°ì´íŠ¸ | CameraManager.swift:657 | ë©”ì¸ ìŠ¤ë ˆë“œ í ì ìœ  | 5-20ms/frame |
| JPEG ì¸ì½”ë”© ë©”ì¸ ìŠ¤ë ˆë“œ | ContentView.swift:82-126 | ì‚¬ì§„ ì´¬ì˜ ì‹œ UI í”„ë¦¬ì§• | 200-500ms |
| ì¤Œ ì œìŠ¤ì²˜ ë™ê¸° ì²˜ë¦¬ | CameraManager.swift:302-314 | ì œìŠ¤ì²˜ ë°˜ì‘ì„± ì €í•˜ | 10-30ms |

---

## ğŸ¯ í•´ê²° ë°©ì•ˆ ì„¤ê³„

### Phase 1: ì„¸ë§ˆí¬ì–´ ì œê±° ë° ì™„ì „ ë¹„ë™ê¸° ì „í™˜ (ìµœìš°ì„ )

#### 1.1 RealtimeAnalyzer - Depth ì¶”ì • ì™„ì „ ë¹„ë™ê¸°í™”

**í˜„ì¬ ì½”ë“œ (ë¬¸ì œ):**
```swift
// RealtimeAnalyzer.swift:320-347
var depth: V15DepthResult? = nil
let depthSemaphore = DispatchSemaphore(value: 0)

DispatchQueue.global(qos: .userInitiated).async {
    self.depthAnything.estimateDepth(from: image) { result in
        // ...
        depthSemaphore.signal()
    }
}

// âš ï¸ ë©”ì¸ ìŠ¤ë ˆë“œ ë¸”ë¡œí‚¹!
if depthSemaphore.wait(timeout: timeout) == .timedOut {
    print("âš ï¸ Depth Anything íƒ€ì„ì•„ì›ƒ")
    depth = nil
}
```

**ê°œì„  ë°©ì•ˆ:**
```swift
// ì„¸ë§ˆí¬ì–´ ì™„ì „ ì œê±°, ì½œë°± ì²´ì¸ìœ¼ë¡œ ë³€ê²½
func analyzeReference(_ image: UIImage, completion: @escaping (ReferenceAnalysis) -> Void) {
    // 1ë‹¨ê³„: RTMPose ì‹¤í–‰ (ë¹„ë™ê¸°)
    DispatchQueue.global(qos: .userInitiated).async {
        let poseResult = self.poseMLAnalyzer.analyzeFaceAndPose(from: image)

        // 2ë‹¨ê³„: Depth ì¶”ì • (ë¹„ë™ê¸°)
        self.depthAnything.estimateDepth(from: image) { depthResult in
            // 3ë‹¨ê³„: ë‚˜ë¨¸ì§€ ë¶„ì„ (ë¹„ë™ê¸° ì™„ë£Œ í›„)
            DispatchQueue.global(qos: .userInitiated).async {
                let analysis = self.buildReferenceAnalysis(
                    poseResult: poseResult,
                    depthResult: depthResult,
                    image: image
                )

                // 4ë‹¨ê³„: ë©”ì¸ ìŠ¤ë ˆë“œë¡œ ê²°ê³¼ë§Œ ì „ë‹¬
                DispatchQueue.main.async {
                    completion(analysis)
                }
            }
        }
    }
}
```

**íš¨ê³¼:**
- ë©”ì¸ ìŠ¤ë ˆë“œ ë¸”ë¡œí‚¹ ì œê±° â†’ **5ì´ˆ í”„ë¦¬ì§• ì™„ì „ í•´ê²°**
- ë¹„ë™ê¸° ì²´ì¸ìœ¼ë¡œ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìˆœì°¨ ì²˜ë¦¬
- UIëŠ” í•­ìƒ ë°˜ì‘ì„± ìœ ì§€

---

#### 1.2 TryAngleOnDeviceAnalyzer - analyzeReference ë¹„ë™ê¸° ì „í™˜

**í˜„ì¬ ì½”ë“œ (ë¬¸ì œ):**
```swift
// TryAngleOnDeviceAnalyzer.swift:124-144
func analyzeReference(_ image: UIImage) -> ReferenceAnalysis {
    let semaphore = DispatchSemaphore(value: 0)

    depthEstimator.estimateDepth(from: image) { result in
        // ...
        semaphore.signal()
    }
    semaphore.wait()  // âš ï¸ ë©”ì¸ ìŠ¤ë ˆë“œ ë¸”ë¡œí‚¹

    return ReferenceAnalysis(...)
}
```

**ê°œì„  ë°©ì•ˆ:**
```swift
// ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸° í•¨ìˆ˜ë¡œ ì™„ì „íˆ ë³€ê²½
func analyzeReference(_ image: UIImage, completion: @escaping (ReferenceAnalysis) -> Void) {
    DispatchQueue.global(qos: .userInitiated).async {
        let pose = self.rtmposeRunner.detectPose(from: image)

        self.depthEstimator.estimateDepth(from: image) { [weak self] result in
            guard let self = self else { return }

            let depth: V15DepthResult?
            if case .success(let d) = result {
                depth = d
            } else {
                depth = nil
            }

            let analysis = ReferenceAnalysis(
                pose: pose,
                depth: depth,
                timestamp: Date()
            )

            DispatchQueue.main.async {
                completion(analysis)
            }
        }
    }
}
```

**í˜¸ì¶œë¶€ ë³€ê²½ (RealtimeAnalyzer, ContentView ë“±):**
```swift
// ê¸°ì¡´
let analysis = analyzer.analyzeReference(image)
// ë³€ê²½ í›„
analyzer.analyzeReference(image) { analysis in
    // ë¶„ì„ ì™„ë£Œ í›„ ì²˜ë¦¬
}
```

**íš¨ê³¼:**
- ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„ ì¤‘ UI ì™„ì „ ë°˜ì‘ì„± ìœ ì§€
- 2-3ì´ˆ ê±¸ë¦¬ëŠ” Depth ì¶”ì • ë™ì•ˆ ì‚¬ìš©ì ì¸í„°ë™ì…˜ ê°€ëŠ¥

---

### Phase 2: Gate System ë° ë¬´ê±°ìš´ ì—°ì‚° ë°±ê·¸ë¼ìš´ë“œ ì´ë™

#### 2.1 processAnalysisResult ë¦¬íŒ©í† ë§

**í˜„ì¬ ë¬¸ì œ:**
- processAnalysisResult ì „ì²´ê°€ ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ (560-829ë¼ì¸)
- Gate System í‰ê°€(773-788), UnifiedFeedback ìƒì„±(801-808)ì´ ë©”ì¸ ìŠ¤ë ˆë“œ

**ê°œì„  ë°©ì•ˆ:**
```swift
// RealtimeAnalyzer.swift ë¦¬íŒ©í† ë§

// 1. ë¬´ê±°ìš´ ì—°ì‚°ì„ ë¶„ë¦¬ëœ í•¨ìˆ˜ë¡œ ì¶”ì¶œ
private func performHeavyComputation(
    faceResult: FaceAnalysisResult?,
    poseResult: PoseAnalysisResult?,
    cgImage: CGImage,
    reference: FrameAnalysis,
    isFrontCamera: Bool,
    currentAspectRatio: CameraAspectRatio
) -> AnalysisComputationResult {
    // âš ï¸ ì´ í•¨ìˆ˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ íì—ì„œë§Œ í˜¸ì¶œë¨

    // Gate System í‰ê°€
    let evaluation = gateSystem.evaluate(...)

    // UnifiedFeedback ìƒì„±
    let unifiedFeedback = UnifiedFeedbackGenerator.shared.generateUnifiedFeedback(...)

    // FeedbackItem ìƒì„±
    let gateFeedbacks = V15FeedbackGenerator.shared.generateFeedbackItems(from: evaluation)

    return AnalysisComputationResult(
        evaluation: evaluation,
        unifiedFeedback: unifiedFeedback,
        gateFeedbacks: gateFeedbacks,
        // ...
    )
}

// 2. processAnalysisResultë¥¼ ë‘ ë‹¨ê³„ë¡œ ë¶„ë¦¬
private func processAnalysisResult(
    faceResult: FaceAnalysisResult?,
    poseResult: PoseAnalysisResult?,
    cgImage: CGImage,
    reference: FrameAnalysis,
    isFrontCamera: Bool,
    currentAspectRatio: CameraAspectRatio
) {
    // ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¬´ê±°ìš´ ì—°ì‚° ìˆ˜í–‰
    DispatchQueue.global(qos: .userInitiated).async { [weak self] in
        guard let self = self else { return }

        // ë¬´ê±°ìš´ ì—°ì‚° (Gate System, Feedback ìƒì„±)
        let computationResult = self.performHeavyComputation(
            faceResult: faceResult,
            poseResult: poseResult,
            cgImage: cgImage,
            reference: reference,
            isFrontCamera: isFrontCamera,
            currentAspectRatio: currentAspectRatio
        )

        // ë©”ì¸ ìŠ¤ë ˆë“œë¡œ ìµœì¢… UI ì—…ë°ì´íŠ¸ë§Œ ì „ë‹¬
        DispatchQueue.main.async {
            self.updateUIWithComputationResult(computationResult)
        }
    }
}

// 3. UI ì—…ë°ì´íŠ¸ëŠ” ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ê°€ë³ê²Œ
private func updateUIWithComputationResult(_ result: AnalysisComputationResult) {
    // @Published ì†ì„±ë§Œ ì—…ë°ì´íŠ¸ (ì¦‰ì‹œ ë°˜í™˜)
    self.gateEvaluation = result.evaluation
    self.v15Feedback = result.evaluation.primaryFeedback
    self.unifiedFeedback = result.unifiedFeedback
    self.instantFeedback = result.stableFeedback
    self.perfectScore = result.perfectScore
    self.isPerfect = result.isPerfect
}
```

**íš¨ê³¼:**
- Gate System í‰ê°€ 100ms â†’ ë©”ì¸ ìŠ¤ë ˆë“œ ë¶€ë‹´ 0ms
- UI ì—…ë°ì´íŠ¸ëŠ” ë‹¨ìˆœ í• ë‹¹ë§Œ ìˆ˜í–‰ (1-2ms)
- ì„¤ì •ì°½ ë²„íŠ¼ í„°ì¹˜ê°€ ì¦‰ì‹œ ë°˜ì‘

---

#### 2.2 RTMPose í”„ë ˆì„ ìŠ¤í‚µ ê°•í™”

**í˜„ì¬ ë¬¸ì œ:**
- RTMPoseëŠ” 175ms ì†Œìš”ë˜ì§€ë§Œ í”„ë ˆì„ ê°„ê²©ì€ 50ms(20fps)
- ì‹¤ì œë¡œëŠ” ë§¤ í”„ë ˆì„ ì²˜ë¦¬ ë¶ˆê°€ëŠ¥í•˜ì—¬ íì— ëˆ„ì 

**ê°œì„  ë°©ì•ˆ:**
```swift
// RealtimeAnalyzer.swift
private var isRTMPoseRunning = false  // í”Œë˜ê·¸ ì¶”ê°€

func analyzeFrame(...) {
    // RTMPose ì‹¤í–‰ ì¤‘ì´ë©´ í˜„ì¬ í”„ë ˆì„ ìŠ¤í‚µ
    guard !isRTMPoseRunning else {
        print("â­ï¸ RTMPose ì‹¤í–‰ ì¤‘ - í”„ë ˆì„ ìŠ¤í‚µ")
        return
    }

    isRTMPoseRunning = true

    DispatchQueue.global(qos: .userInitiated).async { [weak self] in
        defer {
            DispatchQueue.main.async {
                self?.isRTMPoseRunning = false
            }
        }

        // RTMPose ì‹¤í–‰
        let poseResult = self?.poseMLAnalyzer.analyzeFaceAndPose(from: image)

        // ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ)
        // ...
    }
}
```

**ì¶”ê°€ ìµœì í™”: ì ì‘í˜• í”„ë ˆì„ ìŠ¤í‚µ**
```swift
// PerformanceOptimizer.swift í™•ì¥
class PerformanceOptimizer {
    private var lastRTMPoseTime: TimeInterval = 0

    func shouldRunRTMPose() -> Bool {
        let now = CACurrentMediaTime()
        let elapsed = now - lastRTMPoseTime

        // RTMPose ìµœì†Œ ê°„ê²©: 200ms (5fps)
        if elapsed < 0.2 {
            return false
        }

        lastRTMPoseTime = now
        return true
    }
}
```

**íš¨ê³¼:**
- RTMPose í ëˆ„ì  ë°©ì§€
- ì‹¤ì œ ì²˜ë¦¬ ê°€ëŠ¥í•œ ì†ë„ë¡œ í”„ë ˆì„ ì œí•œ
- CPU ê³¼ë¶€í•˜ ë°©ì§€

---

### Phase 3: ì¹´ë©”ë¼ í”„ë ˆì„ ì—…ë°ì´íŠ¸ ìµœì í™”

#### 3.1 ì¹´ë©”ë¼ í”„ë ˆì„ ë³‘í•© (Coalescing)

**í˜„ì¬ ë¬¸ì œ:**
- ë§¤ í”„ë ˆì„(30-60fps)ë§ˆë‹¤ ë©”ì¸ ìŠ¤ë ˆë“œ ì—…ë°ì´íŠ¸
- DispatchQueue.main.asyncê°€ ì´ˆë‹¹ 30-60íšŒ í˜¸ì¶œ

**ê°œì„  ë°©ì•ˆ:**
```swift
// CameraManager.swift
private var lastFrameUpdateTime: TimeInterval = 0
private let minFrameUpdateInterval: TimeInterval = 1.0 / 20.0  // 20fpsë¡œ ì œí•œ

func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
    // ...

    // UI í”„ë ˆì„ ì—…ë°ì´íŠ¸ ë¹ˆë„ ì œí•œ (20fps)
    let now = CACurrentMediaTime()
    if now - lastFrameUpdateTime >= minFrameUpdateInterval {
        lastFrameUpdateTime = now
        DispatchQueue.main.async { [weak self] in
            self?.currentFrame = image
        }
    }

    // FPS ê³„ì‚°ì€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ
    // (ë©”ì¸ ìŠ¤ë ˆë“œ ì—…ë°ì´íŠ¸ëŠ” 1ì´ˆë§ˆë‹¤ë§Œ)
}
```

**íš¨ê³¼:**
- ë©”ì¸ ìŠ¤ë ˆë“œ ì—…ë°ì´íŠ¸ ë¹ˆë„ 60fps â†’ 20fps
- ë©”ì¸ ìŠ¤ë ˆë“œ ë¶€ë‹´ 67% ê°ì†Œ
- ì‹œê°ì ìœ¼ë¡œëŠ” ì°¨ì´ ì—†ìŒ (20fpsë„ ì¶©ë¶„íˆ ë¶€ë“œëŸ¬ì›€)

---

#### 3.2 @Published ì†ì„± ë””ë°”ìš´ì‹±

**í˜„ì¬ ë¬¸ì œ:**
- RealtimeAnalyzerì˜ @Published ì†ì„± ë³€ê²½ì´ ì—°ì‡„ UI ì¬ë Œë”ë§ ìœ ë°œ

**ê°œì„  ë°©ì•ˆ:**
```swift
// RealtimeAnalyzer.swift
class RealtimeAnalyzer: ObservableObject {
    // ì¦‰ì‹œ ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œ ê²ƒë§Œ @Published
    @Published var isPerfect: Bool = false
    @Published var perfectScore: Double = 0.0

    // ë‚˜ë¨¸ì§€ëŠ” ë‚´ë¶€ ë³€ìˆ˜ë¡œ ì €ì¥, ë°°ì¹˜ ì—…ë°ì´íŠ¸
    private var _instantFeedback: [FeedbackItem] = []
    private var _unifiedFeedback: UnifiedFeedback? = nil

    // ë°°ì¹˜ ì—…ë°ì´íŠ¸ (100ms ë””ë°”ìš´ìŠ¤)
    private var updateTimer: Timer?

    private func scheduleUIUpdate() {
        updateTimer?.invalidate()
        updateTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: false) { [weak self] _ in
            guard let self = self else { return }
            DispatchQueue.main.async {
                self.instantFeedback = self._instantFeedback
                self.unifiedFeedback = self._unifiedFeedback
            }
        }
    }
}
```

**íš¨ê³¼:**
- UI ì¬ë Œë”ë§ ë¹ˆë„ ê°ì†Œ
- ë°°ì¹˜ ì—…ë°ì´íŠ¸ë¡œ íš¨ìœ¨ì„± í–¥ìƒ

---

### Phase 4: ì‚¬ì§„ ì´¬ì˜ ìµœì í™”

#### 4.1 JPEG ì¸ì½”ë”© ë°±ê·¸ë¼ìš´ë“œ ì´ë™

**í˜„ì¬ ë¬¸ì œ:**
- performCaptureì—ì„œ JPEG ì¸ì½”ë”©ì´ ë©”ì¸ ìŠ¤ë ˆë“œ (200-500ms)

**ê°œì„  ë°©ì•ˆ:**
```swift
// ContentView.swift
private func performCapture() {
    // í”Œë˜ì‹œ íš¨ê³¼ëŠ” ì¦‰ì‹œ (ë©”ì¸ ìŠ¤ë ˆë“œ)
    withAnimation(.easeInOut(duration: 0.2)) {
        showCaptureFlash = true
    }

    cameraManager.capturePhoto { [self] imageData, error in
        // ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì´ë¯¸ì§€ ì²˜ë¦¬
        DispatchQueue.global(qos: .userInitiated).async {
            guard let imageData = imageData,
                  let originalImage = UIImage(data: imageData) else {
                DispatchQueue.main.async {
                    withAnimation { showCaptureFlash = false }
                }
                return
            }

            // í¬ë¡­ ë° ì¸ì½”ë”© (ë°±ê·¸ë¼ìš´ë“œ)
            let croppedImage = cropImage(originalImage, to: selectedAspectRatio)

            // ë©”ì¸ ìŠ¤ë ˆë“œë¡œ UIë§Œ ì—…ë°ì´íŠ¸
            DispatchQueue.main.async {
                withAnimation(.easeInOut(duration: 0.2)) {
                    showCaptureFlash = false
                }
                capturedImage = croppedImage
            }

            // ì €ì¥ì€ ë³„ë„ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
            DispatchQueue.global(qos: .background).async {
                savePhotoDataToLibrary(imageData, croppedImage: croppedImage)
            }
        }
    }
}
```

**íš¨ê³¼:**
- ì‚¬ì§„ ì´¬ì˜ ì‹œ UI í”„ë¦¬ì§• ì œê±°
- í”Œë˜ì‹œ ì• ë‹ˆë©”ì´ì…˜ì´ ë¶€ë“œëŸ½ê²Œ ë™ì‘

---

### Phase 5: ì¤Œ ì œìŠ¤ì²˜ ìµœì í™”

#### 5.1 ì¤Œ ìš”ì²­ ë””ë°”ìš´ì‹±

**í˜„ì¬ ë¬¸ì œ:**
- í•€ì¹˜ ì œìŠ¤ì²˜ ì¤‘ ë§¤ ì—…ë°ì´íŠ¸ë§ˆë‹¤ device.lockForConfiguration() í˜¸ì¶œ

**ê°œì„  ë°©ì•ˆ:**
```swift
// CameraManager.swift
private var pendingZoom: CGFloat?
private var zoomUpdateTimer: Timer?

func setZoom(_ factor: CGFloat) {
    pendingZoom = factor

    // ë””ë°”ìš´ì‹±: 50ms ë‚´ ì¶”ê°€ ìš”ì²­ì´ ì—†ì„ ë•Œë§Œ ì‹¤í–‰
    zoomUpdateTimer?.invalidate()
    zoomUpdateTimer = Timer.scheduledTimer(withTimeInterval: 0.05, repeats: false) { [weak self] _ in
        guard let self = self, let zoom = self.pendingZoom else { return }

        DispatchQueue.global(qos: .userInitiated).async {
            self.performZoomUpdate(zoom)
        }
    }
}

private func performZoomUpdate(_ factor: CGFloat) {
    guard let device = currentCamera else { return }

    let clampedFactor = min(max(factor, device.minAvailableVideoZoomFactor), device.maxAvailableVideoZoomFactor)

    do {
        try device.lockForConfiguration()
        device.ramp(toVideoZoomFactor: clampedFactor, withRate: 30.0)
        device.unlockForConfiguration()

        DispatchQueue.main.async {
            self.currentZoom = clampedFactor
            self.virtualZoom = self.deviceZoomToDisplayZoom(clampedFactor)
        }
    } catch {
        print("âš ï¸ ì¤Œ ì„¤ì • ì‹¤íŒ¨: \(error)")
    }
}
```

**íš¨ê³¼:**
- í•€ì¹˜ ì œìŠ¤ì²˜ ì‹œ ë¶€ë“œëŸ¬ìš´ ë°˜ì‘
- device.lockForConfiguration í˜¸ì¶œ ë¹ˆë„ ëŒ€í­ ê°ì†Œ

---

## ğŸ” ì„¤ê³„ ê²€ì¦

### ê²€ì¦ 1: ë©”ì¸ ìŠ¤ë ˆë“œ ì•ˆì „ì„±

**ê¸°ì¤€:**
- ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œëŠ” ì˜¤ì§ UI ì—…ë°ì´íŠ¸ë§Œ ìˆ˜í–‰
- 50ms ì´ìƒ ê±¸ë¦¬ëŠ” ì‘ì—…ì€ ëª¨ë‘ ë°±ê·¸ë¼ìš´ë“œ

**ê²€ì¦ ê²°ê³¼:**
âœ… Phase 1: ì„¸ë§ˆí¬ì–´ ì œê±° â†’ ë©”ì¸ ìŠ¤ë ˆë“œ ë¸”ë¡œí‚¹ ì™„ì „ í•´ê²°
âœ… Phase 2: Gate System ë°±ê·¸ë¼ìš´ë“œ ì´ë™ â†’ 100ms ì—°ì‚° ì œê±°
âœ… Phase 3: ì¹´ë©”ë¼ í”„ë ˆì„ ë¹ˆë„ ì œí•œ â†’ ë©”ì¸ ìŠ¤ë ˆë“œ ë¶€ë‹´ 67% ê°ì†Œ
âœ… Phase 4: JPEG ì¸ì½”ë”© ë°±ê·¸ë¼ìš´ë“œ â†’ 500ms ë¸”ë¡œí‚¹ ì œê±°
âœ… Phase 5: ì¤Œ ë””ë°”ìš´ì‹± â†’ ì œìŠ¤ì²˜ ë°˜ì‘ì„± ê°œì„ 

---

### ê²€ì¦ 2: ë°ì´í„° ë ˆì´ìŠ¤ ë°©ì§€

**ìš°ë ¤ ì‚¬í•­:**
- ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì™€ ë©”ì¸ ìŠ¤ë ˆë“œ ê°„ ë™ì‹œ ì ‘ê·¼

**í•´ê²° ë°©ì•ˆ:**
```swift
// ëª¨ë“  @Published ì†ì„±ì€ ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œë§Œ ìˆ˜ì •
DispatchQueue.main.async {
    self.instantFeedback = computedFeedback  // âœ… ì•ˆì „
}

// ë°±ê·¸ë¼ìš´ë“œì—ì„œëŠ” ë¡œì»¬ ë³€ìˆ˜ë§Œ ì‚¬ìš©
DispatchQueue.global().async {
    let localResult = self.computeHeavyTask()  // âœ… ì•ˆì „
    DispatchQueue.main.async {
        self.result = localResult  // âœ… ì•ˆì „
    }
}
```

**ê²€ì¦ ê²°ê³¼:**
âœ… ëª¨ë“  @Published ì†ì„±ì€ DispatchQueue.main.async ë‚´ì—ì„œë§Œ ìˆ˜ì •
âœ… ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ì€ ë¡œì»¬ ë³€ìˆ˜ ì‚¬ìš© í›„ ê²°ê³¼ë§Œ ë©”ì¸ìœ¼ë¡œ ì „ë‹¬
âœ… weak self ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€

---

### ê²€ì¦ 3: ì„±ëŠ¥ í–¥ìƒ ì˜ˆì¸¡

| ì‘ì—… | í˜„ì¬ | ê°œì„  í›„ | ê°œì„ ìœ¨ |
|------|------|---------|--------|
| Depth ì¶”ì • ëŒ€ê¸° | 5000ms (ë©”ì¸) | 0ms (ë©”ì¸) | 100% |
| Gate System í‰ê°€ | 100ms (ë©”ì¸) | 2ms (ë©”ì¸) | 98% |
| RTMPose í”„ë ˆì„ ì²˜ë¦¬ | 175ms/frame | 175ms/5frames | 80% |
| ì¹´ë©”ë¼ í”„ë ˆì„ ì—…ë°ì´íŠ¸ | 60íšŒ/ì´ˆ | 20íšŒ/ì´ˆ | 67% |
| JPEG ì¸ì½”ë”© | 500ms (ë©”ì¸) | 0ms (ë©”ì¸) | 100% |

**ì´ ë©”ì¸ ìŠ¤ë ˆë“œ ë¶€ë‹´:**
- **í˜„ì¬:** 5000 + 100 + 175 + 20Ã—60 + 500 = **~6975ms/ì´ˆ**
- **ê°œì„  í›„:** 0 + 2 + 0 + 20Ã—20 + 0 = **~402ms/ì´ˆ**
- **ê°œì„ ìœ¨: 94.2%**

---

### ê²€ì¦ 4: ì‚¬ìš©ì ê²½í—˜ ê°œì„ 

**ê°œì„  ì „ ì‹œë‚˜ë¦¬ì˜¤:**
1. ì‚¬ìš©ìê°€ ì„¤ì • ë²„íŠ¼ í„°ì¹˜
2. Gate Systemì´ ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ 100ms ì‹¤í–‰ ì¤‘
3. í„°ì¹˜ ì´ë²¤íŠ¸ê°€ 100ms ì§€ì—°ë¨
4. ì‚¬ìš©ì: "ì•±ì´ ë²„ë²…ì¸ë‹¤"

**ê°œì„  í›„ ì‹œë‚˜ë¦¬ì˜¤:**
1. ì‚¬ìš©ìê°€ ì„¤ì • ë²„íŠ¼ í„°ì¹˜
2. í„°ì¹˜ ì´ë²¤íŠ¸ ì¦‰ì‹œ ì²˜ë¦¬ (Gate Systemì€ ë°±ê·¸ë¼ìš´ë“œ)
3. UI ì¦‰ì‹œ ë°˜ì‘
4. ì‚¬ìš©ì: "ë¶€ë“œëŸ½ë‹¤"

**ê²€ì¦ ê²°ê³¼:**
âœ… ëª¨ë“  í„°ì¹˜ ì´ë²¤íŠ¸ëŠ” 16ms ì´ë‚´ ë°˜ì‘ (60fps ìœ ì§€)
âœ… ì„¤ì •ì°½, íƒ­ ì „í™˜, ì¤Œ ì œìŠ¤ì²˜ ëª¨ë‘ ì¦‰ì‹œ ë°˜ì‘
âœ… ì‚¬ì§„ ì´¬ì˜ ì‹œ í”Œë˜ì‹œ ì• ë‹ˆë©”ì´ì…˜ ë¶€ë“œëŸ½ê²Œ ë™ì‘

---

## ğŸ“Š ìµœì¢… ê²€ì¦ ê²°ê³¼

### âœ… ëª¨ë“  ê²€ì¦ í†µê³¼

1. **ë©”ì¸ ìŠ¤ë ˆë“œ ì•ˆì „ì„±:** ëª¨ë“  ë¬´ê±°ìš´ ì—°ì‚°ì´ ë°±ê·¸ë¼ìš´ë“œë¡œ ì´ë™
2. **ë°ì´í„° ë ˆì´ìŠ¤ ë°©ì§€:** @Published ì†ì„±ì€ ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œë§Œ ìˆ˜ì •
3. **ì„±ëŠ¥ í–¥ìƒ:** ë©”ì¸ ìŠ¤ë ˆë“œ ë¶€ë‹´ 94.2% ê°ì†Œ
4. **ì‚¬ìš©ì ê²½í—˜:** ëª¨ë“  UI ì¸í„°ë™ì…˜ì´ 16ms ì´ë‚´ ë°˜ì‘

### âš ï¸ ì ì¬ì  ë¬¸ì œì  ì—†ìŒ

- ì„¸ë§ˆí¬ì–´ ì œê±°ë¡œ ì¸í•œ íƒ€ì´ë° ë¬¸ì œ â†’ ì½œë°± ì²´ì¸ìœ¼ë¡œ í•´ê²°
- ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì¤‘ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ â†’ weak selfë¡œ í•´ê²°
- UI ì—…ë°ì´íŠ¸ ëˆ„ë½ â†’ DispatchQueue.main.asyncë¡œ ë³´ì¥

---

## ğŸš€ êµ¬í˜„ ìˆœì„œ

### Priority 1 (ì¦‰ì‹œ êµ¬í˜„) - ë©”ì¸ ìŠ¤ë ˆë“œ ë¸”ë¡œí‚¹ ì œê±°
1. âœ… Phase 1.1: RealtimeAnalyzer - Depth ì„¸ë§ˆí¬ì–´ ì œê±°
2. âœ… Phase 1.2: TryAngleOnDeviceAnalyzer - analyzeReference ë¹„ë™ê¸° ì „í™˜
3. âœ… Phase 2.1: processAnalysisResult ë¦¬íŒ©í† ë§ (Gate System ë°±ê·¸ë¼ìš´ë“œ)

### Priority 2 (ë‹¤ìŒ ë‹¨ê³„) - ì„±ëŠ¥ ìµœì í™”
4. âœ… Phase 2.2: RTMPose í”„ë ˆì„ ìŠ¤í‚µ ê°•í™”
5. âœ… Phase 3.1: ì¹´ë©”ë¼ í”„ë ˆì„ ë³‘í•©
6. âœ… Phase 4.1: JPEG ì¸ì½”ë”© ë°±ê·¸ë¼ìš´ë“œ ì´ë™

### Priority 3 (ì¶”ê°€ ê°œì„ ) - ì„¸ë°€í•œ ìµœì í™”
7. âœ… Phase 3.2: @Published ë””ë°”ìš´ì‹±
8. âœ… Phase 5.1: ì¤Œ ì œìŠ¤ì²˜ ë””ë°”ìš´ì‹±

---

## ğŸ“ êµ¬í˜„ í›„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê³„íš

### í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

1. **ì„¤ì • ë²„íŠ¼ ë°˜ì‘ì„± í…ŒìŠ¤íŠ¸**
   - RTMPose ì‹¤í–‰ ì¤‘ ì„¤ì • ë²„íŠ¼ í„°ì¹˜
   - ì˜ˆìƒ: ì¦‰ì‹œ ë°˜ì‘ (16ms ì´ë‚´)

2. **ì‚¬ì§„ ì´¬ì˜ ë¶€ë“œëŸ¬ì›€ í…ŒìŠ¤íŠ¸**
   - ì‚¬ì§„ ì´¬ì˜ ë²„íŠ¼ í„°ì¹˜
   - ì˜ˆìƒ: í”Œë˜ì‹œ ì• ë‹ˆë©”ì´ì…˜ ë¶€ë“œëŸ½ê²Œ ë™ì‘

3. **ì¤Œ ì œìŠ¤ì²˜ í…ŒìŠ¤íŠ¸**
   - í•€ì¹˜ ì œìŠ¤ì²˜ë¡œ ì¤Œ ì¸/ì•„ì›ƒ
   - ì˜ˆìƒ: ë¶€ë“œëŸ½ê²Œ ë°˜ì‘, ë²„ë²…ì„ ì—†ìŒ

4. **ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„ ì¤‘ UI í…ŒìŠ¤íŠ¸**
   - ë ˆí¼ëŸ°ìŠ¤ ì‚¬ì§„ ë¶„ì„ ì‹œì‘
   - ì˜ˆìƒ: UI ê³„ì† ë°˜ì‘, í”„ë¦¬ì§• ì—†ìŒ

### ì„±ëŠ¥ ë©”íŠ¸ë¦­

- **ë©”ì¸ ìŠ¤ë ˆë“œ CPU ì‚¬ìš©ë¥ :** < 50%
- **UI í”„ë ˆì„ ë“œë¡­:** < 5% (55fps ì´ìƒ ìœ ì§€)
- **í„°ì¹˜ ë°˜ì‘ ì‹œê°„:** < 16ms
- **ì•± ì‹œì‘ ì‹œê°„:** ë³€í™” ì—†ìŒ ë˜ëŠ” ê°œì„ 

---

## ğŸ“ ì„¤ê³„ ì›ì¹™ ìš”ì•½

1. **Golden Rule:** ë©”ì¸ ìŠ¤ë ˆë“œëŠ” ì˜¤ì§ UI ì—…ë°ì´íŠ¸ë§Œ
2. **50ms Rule:** 50ms ì´ìƒ ê±¸ë¦¬ëŠ” ì‘ì—…ì€ ë¬´ì¡°ê±´ ë°±ê·¸ë¼ìš´ë“œ
3. **No Semaphore Rule:** ì„¸ë§ˆí¬ì–´ëŠ” ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
4. **Callback Chain:** ë¹„ë™ê¸° ì‘ì—…ì€ ì½œë°± ì²´ì¸ìœ¼ë¡œ ìˆœì°¨ ì²˜ë¦¬
5. **Weak Self:** ë°±ê·¸ë¼ìš´ë“œ í´ë¡œì €ëŠ” í•­ìƒ weak self ì‚¬ìš©

---

**ì„¤ê³„ ì™„ë£Œì¼:** 2025-12-10
**êµ¬í˜„ ì˜ˆì • ì‹œê°„:** 2-3ì‹œê°„
**ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ :** ë©”ì¸ ìŠ¤ë ˆë“œ ë¶€ë‹´ 94% ê°ì†Œ, UI ë°˜ì‘ì„± ê·¹ì  í–¥ìƒ
