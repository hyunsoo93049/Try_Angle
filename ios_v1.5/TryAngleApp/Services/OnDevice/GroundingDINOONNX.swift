// GroundingDINOONNX.swift
// Grounding DINO ONNX Runtime Íµ¨ÌòÑ (ÏµúÏ†ÅÌôî Î≤ÑÏ†Ñ)
// ÏàòÏ†ïÏùº: 2025-12-09

import Foundation
import CoreImage
import UIKit
import onnxruntime_objc
import Accelerate

class GroundingDINOONNX {

    private var ortSession: ORTSession?
    private var ortEnv: ORTEnv?
    private let inputSize = 800  // Grounding DINO ÏûÖÎ†• ÌÅ¨Í∏∞

    // üî• [ÏàòÏ†ï 1] CIContextÎ•º ÌÅ¥ÎûòÏä§ Î©§Î≤ÑÎ°ú ÏÑ†Ïñ∏ÌïòÏó¨ Ïû¨ÏÇ¨Ïö© (ÏÑ±Îä• ÏµúÏ†ÅÌôî & Î∞úÏó¥ Í∞êÏÜå)
    // useSoftwareRenderer: falseÎ°ú ÏÑ§Ï†ïÌïòÏó¨ Í∞ÄÎä•Ìïú Í≤ΩÏö∞ GPUÎ•º ÏÇ¨Ïö©ÌïòÎèÑÎ°ù Ïú†ÎèÑ
    private let ciContext = CIContext(options: [.useSoftwareRenderer: false])

    // "person" ÌÜ†ÌÅ∞ (BERT tokenizer)
    // [CLS] person [SEP] = [101, 2711, 102]
    private let personTokenIds: [Int64] = [101, 2711, 102]

    // MARK: - ÏÑ∏ÏÖò ÏÉÅÌÉú
    private(set) var isSessionLoaded: Bool = false

    // Î°úÎî© ÏôÑÎ£å ÏΩúÎ∞±
    var onLoadingComplete: ((Bool) -> Void)?

    // MARK: - Initialization
    init(completion: ((Bool) -> Void)? = nil) {
        self.onLoadingComplete = completion

        // üî• [ÏàòÏ†ï] Î∞±Í∑∏ÎùºÏö¥ÎìúÏóêÏÑú Î™®Îç∏ Î°úÎî© (UI Î∏îÎ°úÌÇπ Î∞©ÏßÄ)
        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            self?.setupONNXRuntime()
        }
    }

    private func setupONNXRuntime() {
        do {
            // ONNX Runtime ÌôòÍ≤Ω ÏÑ§Ï†ï
            ortEnv = try ORTEnv(loggingLevel: .warning)

            // Î™®Îç∏ Í≤ΩÎ°ú
            guard let modelPath = Bundle.main.path(forResource: "grounding_dino", ofType: "onnx") else {
                print("‚ùå Grounding DINO ONNX Î™®Îç∏ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§")
                print("   Models/GroundingDINO/grounding_dino.onnx Í≤ΩÎ°úÎ•º ÌôïÏù∏ÌïòÏÑ∏Ïöî")
                notifyLoadingComplete(success: false)
                return
            }

            // 1Ï∞® ÏãúÎèÑ: CoreML EP (GPU Í∞ÄÏÜç)
            if let session = tryCreateSessionWithCoreML(modelPath: modelPath) {
                ortSession = session
                isSessionLoaded = true
                print("‚úÖ Grounding DINO ONNX Î™®Îç∏ Î°úÎìú ÏÑ±Í≥µ (CoreML GPU)")
                print("   ÏûÖÎ†• ÌÅ¨Í∏∞: \(inputSize)x\(inputSize)")
                notifyLoadingComplete(success: true)
                return
            }

            // 2Ï∞® ÏãúÎèÑ: CPUÎßå (CoreML Ïã§Ìå® Ïãú Ìè¥Î∞±)
            print("‚ö†Ô∏è CoreML EP Ïã§Ìå®, CPU Î™®ÎìúÎ°ú Ïû¨ÏãúÎèÑ...")
            if let session = tryCreateSessionCPUOnly(modelPath: modelPath) {
                ortSession = session
                isSessionLoaded = true
                print("‚úÖ Grounding DINO ONNX Î™®Îç∏ Î°úÎìú ÏÑ±Í≥µ (CPU)")
                print("   ÏûÖÎ†• ÌÅ¨Í∏∞: \(inputSize)x\(inputSize)")
                notifyLoadingComplete(success: true)
                return
            }

            // Îëò Îã§ Ïã§Ìå®
            isSessionLoaded = false
            print("‚ùå Grounding DINO Î™®Îç∏ Î°úÎìú ÏôÑÏ†Ñ Ïã§Ìå®")
            notifyLoadingComplete(success: false)

        } catch {
            isSessionLoaded = false
            print("‚ùå ONNX Runtime ÏÑ§Ï†ï Ïã§Ìå®: \(error)")
            notifyLoadingComplete(success: false)
        }
    }

    // CoreML EPÎ°ú ÏÑ∏ÏÖò ÏÉùÏÑ± ÏãúÎèÑ
    private func tryCreateSessionWithCoreML(modelPath: String) -> ORTSession? {
        do {
            let sessionOptions = try ORTSessionOptions()
            try sessionOptions.setGraphOptimizationLevel(.all)
            try sessionOptions.setIntraOpNumThreads(4)

            // CoreML EP Ï∂îÍ∞Ä
            try sessionOptions.appendCoreMLExecutionProvider(with: .init())

            let session = try ORTSession(env: ortEnv!, modelPath: modelPath, sessionOptions: sessionOptions)
            print("‚úÖ GroundingDINO: CoreML(GPU) Í∞ÄÏÜç ÌôúÏÑ±Ìôî ÏÑ±Í≥µ")
            return session
        } catch {
            print("‚ö†Ô∏è CoreML EP ÏÑ∏ÏÖò ÏÉùÏÑ± Ïã§Ìå®: \(error.localizedDescription)")
            return nil
        }
    }

    // CPUÎßåÏúºÎ°ú ÏÑ∏ÏÖò ÏÉùÏÑ±
    private func tryCreateSessionCPUOnly(modelPath: String) -> ORTSession? {
        do {
            let sessionOptions = try ORTSessionOptions()
            try sessionOptions.setGraphOptimizationLevel(.all)
            try sessionOptions.setIntraOpNumThreads(4)
            // CoreML EP ÏóÜÏù¥ CPUÎßå ÏÇ¨Ïö©

            let session = try ORTSession(env: ortEnv!, modelPath: modelPath, sessionOptions: sessionOptions)
            return session
        } catch {
            print("‚ùå CPU ÏÑ∏ÏÖò ÏÉùÏÑ±ÎèÑ Ïã§Ìå®: \(error.localizedDescription)")
            return nil
        }
    }

    // ÏΩúÎ∞± Ìò∏Ï∂ú Ìó¨Ìçº
    private func notifyLoadingComplete(success: Bool) {
        DispatchQueue.main.async { [weak self] in
            self?.onLoadingComplete?(success)
        }
    }

    // MARK: - Person Detection
    func detectPerson(in image: CIImage, completion: @escaping (CGRect?) -> Void) {
        guard let session = ortSession else {
            print("‚ö†Ô∏è ONNX ÏÑ∏ÏÖòÏù¥ Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§")
            completion(nil)
            return
        }

        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            guard let self = self else {
                completion(nil)
                return
            }

            do {
                // Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨
                let pixelValues = self.preprocessImage(image)
                let pixelMask = self.createPixelMask()
                let (inputIds, attentionMask, tokenTypeIds) = self.createTextInputs()

                // ÏûÖÎ†• ÌÖêÏÑú ÏÉùÏÑ±
                let inputs = try self.createInputTensors(
                    pixelValues: pixelValues,
                    pixelMask: pixelMask,
                    inputIds: inputIds,
                    attentionMask: attentionMask,
                    tokenTypeIds: tokenTypeIds
                )

                // Ï∂îÎ°† Ïã§Ìñâ
                let outputs = try session.run(
                    withInputs: inputs,
                    outputNames: ["logits", "pred_boxes"],
                    runOptions: nil
                )

                // Í≤∞Í≥º Ï≤òÎ¶¨
                if let bbox = self.postprocess(outputs: outputs) {
                    DispatchQueue.main.async {
                        completion(bbox)
                    }
                } else {
                    DispatchQueue.main.async {
                        completion(nil)
                    }
                }

            } catch {
                print("‚ùå ONNX Ï∂îÎ°† Ïã§Ìå®: \(error)")
                DispatchQueue.main.async {
                    completion(nil)
                }
            }
        }
    }

    // MARK: - Image Preprocessing (üî• Accelerate ÏµúÏ†ÅÌôî + CIContext Ïû¨ÏÇ¨Ïö©)
    private func preprocessImage(_ image: CIImage) -> [Float] {
        // üî• [ÏàòÏ†ï 3] ÌÅ¥ÎûòÏä§ Î©§Î≤Ñ ciContext ÏÇ¨Ïö© (Îß§Î≤à ÏÉùÏÑ±ÌïòÏßÄ ÏïäÏùå)
        let context = self.ciContext
        
        let pixelCount = inputSize * inputSize

        // 800x800ÏúºÎ°ú Î¶¨ÏÇ¨Ïù¥Ï¶à
        let scale = CGFloat(inputSize) / max(image.extent.width, image.extent.height)
        let scaledImage = image.transformed(by: CGAffineTransform(scaleX: scale, y: scale))

        // Ï§ëÏïô ÌÅ¨Î°≠
        let cropRect = CGRect(
            x: (scaledImage.extent.width - CGFloat(inputSize)) / 2,
            y: (scaledImage.extent.height - CGFloat(inputSize)) / 2,
            width: CGFloat(inputSize),
            height: CGFloat(inputSize)
        )
        let croppedImage = scaledImage.cropped(to: cropRect)

        // CGImageÎ°ú Î≥ÄÌôò
        guard let cgImage = context.createCGImage(croppedImage, from: croppedImage.extent) else {
            return [Float](repeating: 0, count: 3 * pixelCount)
        }

        // ÌîΩÏÖÄ Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú
        let width = cgImage.width
        let height = cgImage.height
        var pixelData = [UInt8](repeating: 0, count: width * height * 4)

        let colorSpace = CGColorSpaceCreateDeviceRGB()
        guard let cgContext = CGContext(
            data: &pixelData,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: width * 4,
            space: colorSpace,
            bitmapInfo: CGImageAlphaInfo.premultipliedLast.rawValue
        ) else {
            return [Float](repeating: 0, count: 3 * pixelCount)
        }

        cgContext.draw(cgImage, in: CGRect(x: 0, y: 0, width: width, height: height))

        // üî• vDSP Í∏∞Î∞ò Í≥†ÏÜç Ï†ïÍ∑úÌôî (ImageNet ÌèâÍ∑†/ÌëúÏ§ÄÌé∏Ï∞®)
        let mean: [Float] = [0.485, 0.456, 0.406]
        let std: [Float] = [0.229, 0.224, 0.225]

        var result = [Float](repeating: 0, count: 3 * pixelCount)

        // Í∞Å Ï±ÑÎÑêÎ≥Ñ Î≥ëÎ†¨ Ï≤òÎ¶¨
        DispatchQueue.concurrentPerform(iterations: 3) { c in
            var channelData = [Float](repeating: 0, count: pixelCount)

            // RGBAÏóêÏÑú Ìï¥Îãπ Ï±ÑÎÑê Ï∂îÏ∂ú
            for i in 0..<pixelCount {
                channelData[i] = Float(pixelData[i * 4 + c])
            }

            // vDSP: /255.0 Ï†ïÍ∑úÌôî
            var scale: Float = 1.0 / 255.0
            vDSP_vsmul(channelData, 1, &scale, &channelData, 1, vDSP_Length(pixelCount))

            // vDSP: (x - mean)
            var negMean = -mean[c]
            vDSP_vsadd(channelData, 1, &negMean, &channelData, 1, vDSP_Length(pixelCount))

            // vDSP: / std
            var invStd = 1.0 / std[c]
            vDSP_vsmul(channelData, 1, &invStd, &channelData, 1, vDSP_Length(pixelCount))

            // CHW Ìè¨Îß∑ÏúºÎ°ú Î≥µÏÇ¨
            let offset = c * pixelCount
            for i in 0..<pixelCount {
                result[offset + i] = channelData[i]
            }
        }

        return result
    }

    // MARK: - Create Pixel Mask
    private func createPixelMask() -> [Int64] {
        // Î™®Îì† ÌîΩÏÖÄÏù¥ Ïú†Ìö®Ìï®ÏùÑ ÎÇòÌÉÄÎÇ¥Îäî ÎßàÏä§ÌÅ¨
        return [Int64](repeating: 1, count: inputSize * inputSize)
    }

    // MARK: - Create Text Inputs
    private func createTextInputs() -> ([Int64], [Int64], [Int64]) {
        // "person" Í≤ÄÏ∂úÏùÑ ÏúÑÌïú Í≥†Ï†ï ÌÜ†ÌÅ∞
        let inputIds = personTokenIds
        let attentionMask = [Int64](repeating: 1, count: personTokenIds.count)
        let tokenTypeIds = [Int64](repeating: 0, count: personTokenIds.count)

        return (inputIds, attentionMask, tokenTypeIds)
    }

    // MARK: - Create Input Tensors
    private func createInputTensors(
        pixelValues: [Float],
        pixelMask: [Int64],
        inputIds: [Int64],
        attentionMask: [Int64],
        tokenTypeIds: [Int64]
    ) throws -> [String: ORTValue] {

        var inputs = [String: ORTValue]()

        // pixel_values: [1, 3, 800, 800]
        let pixelValuesData = Data(bytes: pixelValues, count: pixelValues.count * MemoryLayout<Float>.size)
        let pixelValuesTensor = try ORTValue(
            tensorData: NSMutableData(data: pixelValuesData),
            elementType: .float,
            shape: [1, 3, NSNumber(value: inputSize), NSNumber(value: inputSize)]
        )
        inputs["pixel_values"] = pixelValuesTensor

        // pixel_mask: [1, 800, 800]
        let pixelMaskData = Data(bytes: pixelMask, count: pixelMask.count * MemoryLayout<Int64>.size)
        let pixelMaskTensor = try ORTValue(
            tensorData: NSMutableData(data: pixelMaskData),
            elementType: .int64,
            shape: [1, NSNumber(value: inputSize), NSNumber(value: inputSize)]
        )
        inputs["pixel_mask"] = pixelMaskTensor

        // input_ids: [1, seq_len]
        let seqLen = inputIds.count
        let inputIdsData = Data(bytes: inputIds, count: seqLen * MemoryLayout<Int64>.size)
        let inputIdsTensor = try ORTValue(
            tensorData: NSMutableData(data: inputIdsData),
            elementType: .int64,
            shape: [1, NSNumber(value: seqLen)]
        )
        inputs["input_ids"] = inputIdsTensor

        // attention_mask: [1, seq_len]
        let attentionMaskData = Data(bytes: attentionMask, count: seqLen * MemoryLayout<Int64>.size)
        let attentionMaskTensor = try ORTValue(
            tensorData: NSMutableData(data: attentionMaskData),
            elementType: .int64,
            shape: [1, NSNumber(value: seqLen)]
        )
        inputs["attention_mask"] = attentionMaskTensor

        // token_type_ids: [1, seq_len]
        let tokenTypeIdsData = Data(bytes: tokenTypeIds, count: seqLen * MemoryLayout<Int64>.size)
        let tokenTypeIdsTensor = try ORTValue(
            tensorData: NSMutableData(data: tokenTypeIdsData),
            elementType: .int64,
            shape: [1, NSNumber(value: seqLen)]
        )
        inputs["token_type_ids"] = tokenTypeIdsTensor

        return inputs
    }

    // MARK: - Postprocessing
    private func postprocess(outputs: [String: ORTValue]) -> CGRect? {
        guard let logitsValue = outputs["logits"],
              let boxesValue = outputs["pred_boxes"] else {
            return nil
        }

        do {
            // logits: [1, num_queries, num_classes]
            let logitsData = try logitsValue.tensorData() as Data
            let logits = logitsData.withUnsafeBytes { ptr in
                Array(ptr.bindMemory(to: Float.self))
            }

            // pred_boxes: [1, num_queries, 4] (cx, cy, w, h) normalized
            let boxesData = try boxesValue.tensorData() as Data
            let boxes = boxesData.withUnsafeBytes { ptr in
                Array(ptr.bindMemory(to: Float.self))
            }

            // ÏµúÍ≥† confidence person Ï∞æÍ∏∞
            let numQueries = 900  // Grounding DINO default
            var bestScore: Float = 0.6  // threshold
            var bestBox: CGRect?

            for i in 0..<numQueries {
                // sigmoid Ï†ÅÏö©
                let score = 1.0 / (1.0 + exp(-logits[i]))

                if score > bestScore {
                    bestScore = score

                    let cx = boxes[i * 4 + 0]
                    let cy = boxes[i * 4 + 1]
                    let w = boxes[i * 4 + 2]
                    let h = boxes[i * 4 + 3]

                    // (cx, cy, w, h) -> (x, y, w, h)
                    bestBox = CGRect(
                        x: CGFloat(cx - w/2),
                        y: CGFloat(cy - h/2),
                        width: CGFloat(w),
                        height: CGFloat(h)
                    )
                }
            }

            if let box = bestBox {
                print("‚úÖ Person detected: score=\(bestScore), box=\(box)")
            }

            return bestBox

        } catch {
            print("‚ùå Ï∂úÎ†• Ï≤òÎ¶¨ Ïã§Ìå®: \(error)")
            return nil
        }
    }

    // MARK: - Detect All Persons
    func detectAllPersons(in image: CIImage, completion: @escaping ([Detection]) -> Void) {
        guard let session = ortSession else {
            completion([])
            return
        }

        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            guard let self = self else {
                completion([])
                return
            }

            do {
                let pixelValues = self.preprocessImage(image)
                let pixelMask = self.createPixelMask()
                let (inputIds, attentionMask, tokenTypeIds) = self.createTextInputs()

                let inputs = try self.createInputTensors(
                    pixelValues: pixelValues,
                    pixelMask: pixelMask,
                    inputIds: inputIds,
                    attentionMask: attentionMask,
                    tokenTypeIds: tokenTypeIds
                )

                let outputs = try session.run(
                    withInputs: inputs,
                    outputNames: ["logits", "pred_boxes"],
                    runOptions: nil
                )

                let detections = self.postprocessMultiple(outputs: outputs)
                DispatchQueue.main.async {
                    completion(detections)
                }

            } catch {
                print("‚ùå ONNX Ï∂îÎ°† Ïã§Ìå®: \(error)")
                DispatchQueue.main.async {
                    completion([])
                }
            }
        }
    }

    private func postprocessMultiple(outputs: [String: ORTValue]) -> [Detection] {
        guard let logitsValue = outputs["logits"],
              let boxesValue = outputs["pred_boxes"] else {
            return []
        }

        do {
            let logitsData = try logitsValue.tensorData() as Data
            let logits = logitsData.withUnsafeBytes { ptr in
                Array(ptr.bindMemory(to: Float.self))
            }

            let boxesData = try boxesValue.tensorData() as Data
            let boxes = boxesData.withUnsafeBytes { ptr in
                Array(ptr.bindMemory(to: Float.self))
            }

            var detections = [Detection]()
            let numQueries = 900
            let threshold: Float = 0.5

            for i in 0..<numQueries {
                let score = 1.0 / (1.0 + exp(-logits[i]))

                if score > threshold {
                    let cx = boxes[i * 4 + 0]
                    let cy = boxes[i * 4 + 1]
                    let w = boxes[i * 4 + 2]
                    let h = boxes[i * 4 + 3]

                    let bbox = CGRect(
                        x: CGFloat(cx - w/2),
                        y: CGFloat(cy - h/2),
                        width: CGFloat(w),
                        height: CGFloat(h)
                    )

                    detections.append(Detection(
                        label: "person",
                        confidence: score,
                        boundingBox: bbox
                    ))
                }
            }

            // NMS (Non-Maximum Suppression)
            return nonMaximumSuppression(detections, iouThreshold: 0.5)

        } catch {
            return []
        }
    }

    // MARK: - NMS
    private func nonMaximumSuppression(_ detections: [Detection], iouThreshold: Float) -> [Detection] {
        guard !detections.isEmpty else { return [] }

        var sorted = detections.sorted { $0.confidence > $1.confidence }
        var result = [Detection]()

        while !sorted.isEmpty {
            let best = sorted.removeFirst()
            result.append(best)

            sorted = sorted.filter { detection in
                let iou = calculateIoU(best.boundingBox, detection.boundingBox)
                return iou < iouThreshold
            }
        }

        return result
    }

    private func calculateIoU(_ a: CGRect, _ b: CGRect) -> Float {
        let intersection = a.intersection(b)
        if intersection.isNull { return 0 }

        let intersectionArea = intersection.width * intersection.height
        let unionArea = a.width * a.height + b.width * b.height - intersectionArea

        return Float(intersectionArea / unionArea)
    }
}
