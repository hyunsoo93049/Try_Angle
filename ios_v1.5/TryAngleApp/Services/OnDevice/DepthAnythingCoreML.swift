//
//  DepthAnythingCoreML.swift
//  Depth Anything CoreML Integration
//  ì‘ì„±ì¼: 2025-12-05
//

import Foundation
import CoreML
import Vision
import UIKit

// MARK: - Depth Anything CoreML Wrapper
class DepthAnythingCoreML {

    private var model: VNCoreMLModel?
    private let modelType: ModelType

    // ğŸ”¥ ë©”ëª¨ë¦¬ ìµœì í™”: CIContext ì‹±ê¸€í†¤ (ì•½ 100MB ì ˆì•½)
    private static let sharedContext = CIContext(options: [
        .useSoftwareRenderer: false,
        .cacheIntermediates: false
    ])

    // ğŸ”¥ ë™ì‹œ ì‹¤í–‰ ë°©ì§€ (ë©”ëª¨ë¦¬ í­ë°œ ë°©ì§€)
    private var isProcessing = false
    private let processingQueue = DispatchQueue(label: "depth.processing", qos: .userInitiated)

    enum ModelType {
        case small
        case base

        var modelName: String {
            switch self {
            case .small: return "DepthAnythingV2SmallF16"
            case .base: return "DepthAnythingV2SmallF16"  // ê°™ì€ ëª¨ë¸ ì‚¬ìš©
            }
        }
    }

    init(modelType: ModelType = .small) {
        self.modelType = modelType
        setupModel()
    }

    // MARK: - ëª¨ë¸ ì„¤ì •
    private func setupModel() {
        // ë°©ë²• 1: Apple ê³µì‹ CoreML ëª¨ë¸ ì‚¬ìš© (ë‹¤ìš´ë¡œë“œ í•„ìš”)
        // https://huggingface.co/apple/coreml-depth-anything-v2-small

        guard let modelURL = Bundle.main.url(forResource: modelType.modelName, withExtension: "mlmodelc") else {
            print("âŒ Depth Anything ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            print("   ë‹¤ìš´ë¡œë“œ: https://huggingface.co/apple/coreml-depth-anything-v2-small")
            return
        }

        do {
            let mlModel = try MLModel(contentsOf: modelURL)
            model = try VNCoreMLModel(for: mlModel)
            print("âœ… Depth Anything CoreML ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        } catch {
            print("âŒ Depth Anything ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: \(error)")
        }
    }

    // MARK: - ê¹Šì´ ì¶”ì •
    func estimateDepth(from image: UIImage, completion: @escaping (Result<V15DepthResult, Error>) -> Void) {
        // ğŸ”¥ ë™ì‹œ ì‹¤í–‰ ë°©ì§€ (ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì´ë©´ ìŠ¤í‚µ)
        guard !isProcessing else {
            print("â­ï¸ Depth Anything: ì´ë¯¸ ì²˜ë¦¬ ì¤‘ - ìŠ¤í‚µ")
            return
        }

        guard let model = model else {
            print("âŒ Depth Anything: ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            completion(.failure(DepthError.modelNotLoaded))
            return
        }

        isProcessing = true

        // ğŸ”¥ ë©”ëª¨ë¦¬ ìµœì í™”: ì´ë¯¸ì§€ ë‹¤ìš´ìƒ˜í”Œë§ (518x518ë¡œ ë¦¬ì‚¬ì´ì¦ˆ)
        let targetSize = CGSize(width: 518, height: 518)
        guard let resizedImage = image.resized(to: targetSize),
              let cgImage = resizedImage.cgImage else {
            print("âŒ Depth Anything: ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ì‹¤íŒ¨")
            completion(.failure(DepthError.invalidImage))
            return
        }

        // Vision ìš”ì²­ ìƒì„±
        let request = VNCoreMLRequest(model: model) { [weak self] request, error in
            defer {
                self?.isProcessing = false  // ğŸ”¥ ì²˜ë¦¬ ì™„ë£Œ í”Œë˜ê·¸
            }

            if let error = error {
                print("âŒ Depth Anything Vision ì—ëŸ¬: \(error.localizedDescription)")
                completion(.failure(error))
                return
            }

            // ğŸ”§ ë””ë²„ê·¸: ê²°ê³¼ íƒ€ì… í™•ì¸
            if let results = request.results {
                print("ğŸ” Depth Anything ê²°ê³¼ íƒ€ì…: \(type(of: results)), ê°œìˆ˜: \(results.count)")
                if let first = results.first {
                    print("ğŸ” ì²« ë²ˆì§¸ ê²°ê³¼ íƒ€ì…: \(type(of: first))")
                }
            }

            // ë°©ë²• 1: VNCoreMLFeatureValueObservation (MLMultiArray ì¶œë ¥)
            if let results = request.results as? [VNCoreMLFeatureValueObservation],
               let depthMap = results.first?.featureValue.multiArrayValue {
                print("âœ… Depth Anything: MLMultiArray ì¶œë ¥ ì‚¬ìš©")
                guard let strongSelf = self else { return }
                let result = strongSelf.processDepthMap(depthMap, originalImage: image)
                completion(.success(result))
                return
            }

            // ë°©ë²• 2: VNPixelBufferObservation (CVPixelBuffer ì¶œë ¥ - Apple ëª¨ë¸)
            if let results = request.results as? [VNPixelBufferObservation],
               let pixelBuffer = results.first?.pixelBuffer {
                print("âœ… Depth Anything: PixelBuffer ì¶œë ¥ ì‚¬ìš©")
                guard let strongSelf = self else { return }
                let result = strongSelf.processPixelBuffer(pixelBuffer, originalImage: image)
                completion(.success(result))
                return
            }

            // ë°©ë²• 3: VNCoreMLFeatureValueObservationì—ì„œ ë‹¤ë¥¸ íƒ€ì… ì‹œë„
            if let results = request.results as? [VNCoreMLFeatureValueObservation],
               let first = results.first {
                print("ğŸ” FeatureValue íƒ€ì…: \(first.featureValue.type.rawValue)")
                // ì´ë¯¸ì§€ ì¶œë ¥ì¼ ìˆ˜ë„ ìˆìŒ
                if let imageBuffer = first.featureValue.imageBufferValue {
                    print("âœ… Depth Anything: ImageBuffer ì¶œë ¥ ì‚¬ìš©")
                    guard let strongSelf = self else { return }
                    let result = strongSelf.processPixelBuffer(imageBuffer, originalImage: image)
                    completion(.success(result))
                    return
                }
            }

            print("âŒ Depth Anything: ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¶œë ¥ í˜•ì‹")
            completion(.failure(DepthError.processingFailed))
        }

        // ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° ì„¤ì • (518x518)
        request.imageCropAndScaleOption = VNImageCropAndScaleOption.centerCrop

        // ìš”ì²­ ì‹¤í–‰ (ë©”ëª¨ë¦¬ ìµœì í™”)
        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            autoreleasepool {
                // ğŸ”¥ CIContext ì˜µì…˜ ì œê±° (Visionì´ ìì²´ì ìœ¼ë¡œ ê´€ë¦¬)
                let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])

                do {
                    try handler.perform([request])
                } catch {
                    print("âŒ Depth Anything perform ì—ëŸ¬: \(error.localizedDescription)")
                    self?.isProcessing = false  // ì—ëŸ¬ ì‹œì—ë„ í”Œë˜ê·¸ í•´ì œ
                    completion(.failure(error))
                }
            }
        }
    }

    // MARK: - PixelBuffer ì²˜ë¦¬ (Apple CoreML ëª¨ë¸ìš©)
    private func processPixelBuffer(_ pixelBuffer: CVPixelBuffer, originalImage: UIImage) -> V15DepthResult {
        let width = CVPixelBufferGetWidth(pixelBuffer)
        let height = CVPixelBufferGetHeight(pixelBuffer)

        CVPixelBufferLockBaseAddress(pixelBuffer, .readOnly)
        defer { CVPixelBufferUnlockBaseAddress(pixelBuffer, .readOnly) }

        var foregroundDepth: Float = 0
        var backgroundDepth: Float = 0
        var foregroundCount = 0
        var backgroundCount = 0

        // Float32 ë˜ëŠ” Float16 ë°ì´í„° ì²˜ë¦¬
        let pixelFormat = CVPixelBufferGetPixelFormatType(pixelBuffer)
        print("ğŸ” PixelBuffer í˜•ì‹: \(pixelFormat), í¬ê¸°: \(width)x\(height)")

        if let baseAddress = CVPixelBufferGetBaseAddress(pixelBuffer) {
            let bytesPerRow = CVPixelBufferGetBytesPerRow(pixelBuffer)

            // ìƒë‹¨ 1/3 (ë°°ê²½)
            for y in 0..<(height/3) {
                for x in 0..<width {
                    let offset = y * bytesPerRow + x * MemoryLayout<Float>.size
                    let value = baseAddress.load(fromByteOffset: offset, as: Float.self)
                    if !value.isNaN && !value.isInfinite {
                        backgroundDepth += value
                        backgroundCount += 1
                    }
                }
            }

            // í•˜ë‹¨ 1/4 (ì „ê²½)
            for y in (3*height/4)..<height {
                for x in 0..<width {
                    let offset = y * bytesPerRow + x * MemoryLayout<Float>.size
                    let value = baseAddress.load(fromByteOffset: offset, as: Float.self)
                    if !value.isNaN && !value.isInfinite {
                        foregroundDepth += value
                        foregroundCount += 1
                    }
                }
            }
        }

        // í‰ê·  ê³„ì‚°
        let avgBackground = backgroundCount > 0 ? backgroundDepth / Float(backgroundCount) : 0
        let avgForeground = foregroundCount > 0 ? foregroundDepth / Float(foregroundCount) : 0

        // ì••ì¶•ê° ì§€ìˆ˜ ê³„ì‚°
        let depthRange = abs(avgBackground - avgForeground)
        let compressionIndex = 1.0 - min(depthRange * 2, 1.0)

        print("ğŸ” Depth: ë°°ê²½=\(avgBackground), ì „ê²½=\(avgForeground), ì••ì¶•ê°=\(compressionIndex)")

        let cameraType = determineCameraType(compression: compressionIndex)

        return V15DepthResult(
            depthImage: nil,
            compressionIndex: compressionIndex,
            cameraType: cameraType
        )
    }

    // MARK: - ê¹Šì´ë§µ ì²˜ë¦¬
    private func processDepthMap(_ depthMap: MLMultiArray, originalImage: UIImage) -> V15DepthResult {
        // ì••ì¶•ê° ê³„ì‚°
        let compressionIndex = calculateCompression(from: depthMap)

        // ì¹´ë©”ë¼ íƒ€ì… íŒì •
        let cameraType = determineCameraType(compression: compressionIndex)

        // ê¹Šì´ë§µì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ì˜µì…˜ - ë””ë²„ê¹…ìš©)
        // ğŸ”¥ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ê¸°ë³¸ì ìœ¼ë¡œ nil ë°˜í™˜
        // let depthImage = convertToImage(depthMap)

        return V15DepthResult(
            depthImage: nil,  // ğŸ”¥ ë©”ëª¨ë¦¬ ìµœì í™”: í•„ìš”ì‹œì—ë§Œ ìƒì„±
            compressionIndex: compressionIndex,
            cameraType: cameraType
        )
    }

    // MARK: - ì••ì¶•ê° ê³„ì‚°
    private func calculateCompression(from depthMap: MLMultiArray) -> Float {
        // ê¹Šì´ë§µì—ì„œ ì „ê²½ê³¼ ë°°ê²½ì˜ ê¹Šì´ ì°¨ì´ ê³„ì‚°
        let shape = depthMap.shape
        let height = shape[0].intValue
        let width = shape[1].intValue

        var foregroundDepth: Float = 0
        var backgroundDepth: Float = 0

        // ìƒë‹¨ 1/3 (ë°°ê²½)
        for y in 0..<(height/3) {
            for x in 0..<width {
                let index = y * width + x
                backgroundDepth += depthMap[index].floatValue
            }
        }
        backgroundDepth /= Float(height * width / 3)

        // í•˜ë‹¨ 1/4 (ì „ê²½)
        for y in (3*height/4)..<height {
            for x in 0..<width {
                let index = y * width + x
                foregroundDepth += depthMap[index].floatValue
            }
        }
        foregroundDepth /= Float(height * width / 4)

        // ì••ì¶•ê° ì§€ìˆ˜ (0=ê´‘ê°, 1=ë§ì›)
        let depthRange = abs(backgroundDepth - foregroundDepth)
        let compressionIndex = 1.0 - min(depthRange * 2, 1.0)

        return compressionIndex
    }

    // MARK: - ì¹´ë©”ë¼ íƒ€ì… íŒì •
    private func determineCameraType(compression: Float) -> V15CameraType {
        switch compression {
        case ..<0.3:
            return .wide
        case 0.3..<0.5:
            return .normal
        case 0.5..<0.7:
            return .semiTele
        default:
            return .telephoto
        }
    }

    // MARK: - ê¹Šì´ë§µì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    private func convertToImage(_ depthMap: MLMultiArray) -> UIImage? {
        let shape = depthMap.shape
        let height = shape[0].intValue
        let width = shape[1].intValue

        // ì •ê·œí™”
        var minDepth = Float.greatestFiniteMagnitude
        var maxDepth = Float.leastNormalMagnitude

        for i in 0..<depthMap.count {
            let value = depthMap[i].floatValue
            minDepth = min(minDepth, value)
            maxDepth = max(maxDepth, value)
        }

        let range = maxDepth - minDepth

        // ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ ìƒì„±
        var pixels = [UInt8]()
        for i in 0..<depthMap.count {
            let normalized = (depthMap[i].floatValue - minDepth) / range
            pixels.append(UInt8(normalized * 255))
        }

        // CGImage ìƒì„±
        let colorSpace = CGColorSpaceCreateDeviceGray()
        guard let context = CGContext(
            data: &pixels,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: width,
            space: colorSpace,
            bitmapInfo: CGImageAlphaInfo.none.rawValue
        ) else { return nil }

        guard let cgImage = context.makeImage() else { return nil }
        return UIImage(cgImage: cgImage)
    }
}

// MARK: - ê²°ê³¼ êµ¬ì¡°ì²´ (v1.5 ì „ìš© - ê¸°ì¡´ DepthResultì™€ ì¶©ëŒ ë°©ì§€)
// ğŸ”¥ MLMultiArray ì œê±°í•˜ì—¬ ë©”ëª¨ë¦¬ ìµœì í™” (ì•½ 4MB ì ˆì•½)
struct V15DepthResult {
    let depthImage: UIImage?       // ì‹œê°í™”ìš© (ì˜µì…˜)
    let compressionIndex: Float    // ì••ì¶•ê° ì§€ìˆ˜ (0=ê´‘ê°, 1=ë§ì›)
    let cameraType: V15CameraType  // ì¶”ì • ì¹´ë©”ë¼ íƒ€ì…
}

enum V15CameraType {
    case wide       // ê´‘ê° (24-35mm)
    case normal     // í‘œì¤€ (35-50mm)
    case semiTele   // ì¤€ë§ì› (50-85mm)
    case telephoto  // ë§ì› (85mm+)

    var description: String {
        switch self {
        case .wide: return "ê´‘ê°"
        case .normal: return "í‘œì¤€"
        case .semiTele: return "ì¤€ë§ì›"
        case .telephoto: return "ë§ì›"
        }
    }

    var recommendation: String? {
        switch self {
        case .wide: return "ë” ê°€ê¹Œì´ ì ‘ê·¼í•˜ê±°ë‚˜ ë§ì› ë Œì¦ˆ ì‚¬ìš©"
        case .normal: return nil
        case .semiTele: return nil
        case .telephoto: return "ê°•í•œ ì••ì¶•ê° - ê´‘ê° ë Œì¦ˆ ê³ ë ¤"
        }
    }
}

// MARK: - ì—ëŸ¬ íƒ€ì…
enum DepthError: LocalizedError {
    case modelNotLoaded
    case invalidImage
    case processingFailed

    var errorDescription: String? {
        switch self {
        case .modelNotLoaded:
            return "Depth Anything ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        case .invalidImage:
            return "ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ì…ë‹ˆë‹¤"
        case .processingFailed:
            return "ê¹Šì´ ì¶”ì • ì²˜ë¦¬ ì‹¤íŒ¨"
        }
    }
}

// MARK: - ì‹±ê¸€í†¤ (ë©”ëª¨ë¦¬ ì ˆì•½)
extension DepthAnythingCoreML {
    static let shared = DepthAnythingCoreML(modelType: .small)
}

// MARK: - UIImage ë¦¬ì‚¬ì´ì¦ˆ Extension (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
extension UIImage {
    func resized(to targetSize: CGSize) -> UIImage? {
        let format = UIGraphicsImageRendererFormat()
        format.scale = 1.0  // @1xë¡œ ê°•ì œ (ë©”ëª¨ë¦¬ ì ˆì•½)

        let renderer = UIGraphicsImageRenderer(size: targetSize, format: format)
        return renderer.image { context in
            self.draw(in: CGRect(origin: .zero, size: targetSize))
        }
    }
}