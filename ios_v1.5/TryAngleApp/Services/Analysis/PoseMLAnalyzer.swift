import Foundation
import UIKit
import Vision  // FaceAnalysisResultÏùò VNFaceObservation ÌÉÄÏûÖ ÎïåÎ¨∏Ïóê ÌïÑÏöî

// MARK: - PoseML Î∂ÑÏÑùÍ∏∞ (RTMPose via ONNX Runtime)
// RTMPose 133 ÌÇ§Ìè¨Ïù∏Ìä∏Î°ú ÏñºÍµ¥ + Ìè¨Ï¶à ÎèôÏãú Î∂ÑÏÑù
class PoseMLAnalyzer {

    // RTMPose Runner (ONNX Runtime)
    // üî• publicÏúºÎ°ú ÎÖ∏Ï∂úÌïòÏó¨ PersonDetectorÏóêÏÑú YOLOX Ïû¨ÏÇ¨Ïö© Í∞ÄÎä•
    let rtmPoseRunner: RTMPoseRunner?

    // üêõ ÎîîÎ≤ÑÍ∑∏ Î°úÍ∑∏ ÌååÏùº Í≤ΩÎ°ú
    private lazy var logFileURL: URL? = {
        if let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first {
            return documentsPath.appendingPathComponent("pose_debug.txt")
        }
        return nil
    }()

    init() {
        print("üöÄ PoseMLAnalyzer init() ÏãúÏûë")

        // RTMPose Runner Ï¥àÍ∏∞Ìôî ÏãúÎèÑ (stored property Î®ºÏ†Ä Ï¥àÍ∏∞Ìôî)
        rtmPoseRunner = RTMPoseRunner()

        // Ï¥àÍ∏∞Ìôî ÏôÑÎ£å ÌõÑ Î°úÍ∑∏
        logToFile("üöÄ PoseMLAnalyzer init() ÏãúÏûë - \(Date())")

        if rtmPoseRunner != nil {
            print("‚úÖ RTMPose Runner Ï¥àÍ∏∞Ìôî ÏÑ±Í≥µ")
            logToFile("‚úÖ RTMPose ÏÇ¨Ïö© (ONNX Runtime with CoreML EP)")
        } else {
            print("‚ùå RTMPose Runner Ï¥àÍ∏∞Ìôî Ïã§Ìå® - ONNX Î™®Îç∏ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏùå")
            logToFile("‚ùå RTMPose Ï¥àÍ∏∞Ìôî Ïã§Ìå®")
        }

        print("üöÄ PoseMLAnalyzer init() ÏôÑÎ£å")
    }

    // üêõ ÌååÏùºÏóê Î°úÍ∑∏ Í∏∞Î°ù
    private func logToFile(_ message: String) {
        guard let logFileURL = logFileURL else { return }

        let timestamp = DateFormatter.localizedString(from: Date(), dateStyle: .none, timeStyle: .medium)
        let logMessage = "[\(timestamp)] \(message)\n"

        if let data = logMessage.data(using: .utf8) {
            if FileManager.default.fileExists(atPath: logFileURL.path) {
                if let fileHandle = try? FileHandle(forWritingTo: logFileURL) {
                    fileHandle.seekToEndOfFile()
                    fileHandle.write(data)
                    fileHandle.closeFile()
                }
            } else {
                try? data.write(to: logFileURL)
            }
        }

        // ÏΩòÏÜîÏóêÎèÑ Ï∂úÎ†•
        print(message)
    }

    // MARK: - ÏñºÍµ¥ + Ìè¨Ï¶à ÎèôÏãú Î∂ÑÏÑù (VisionAnalyzerÏôÄ ÎèôÏùºÌïú Ïù∏ÌÑ∞ÌéòÏù¥Ïä§)
    private var analysisCallCount = 0
    func analyzeFaceAndPose(from image: UIImage) -> (face: FaceAnalysisResult?, pose: PoseAnalysisResult?) {
        analysisCallCount += 1

        // 10Î≤àÎßàÎã§ Î°úÍ∑∏ (ÎÑàÎ¨¥ ÎßéÏùÄ Î°úÍ∑∏ Î∞©ÏßÄ)
        if analysisCallCount % 10 == 1 {
            logToFile("üîç analyzeFaceAndPose() Ìò∏Ï∂úÎê® (Ìò∏Ï∂ú ÌöüÏàò: \(analysisCallCount))")
        }

        // RTMPose Ìè¨Ï¶à Í∞êÏßÄ (ONNX Runtime)
        let poseResult = detectPoseWithRTMPose(from: image)

        // ÏñºÍµ¥ Ï†ïÎ≥¥ Ï∂îÏ∂ú (RTMPose ÌÇ§Ìè¨Ïù∏Ìä∏ Í∏∞Î∞ò)
        let faceResult = extractFaceFromPose(poseResult: poseResult, imageSize: image.size)

        // 10Î≤àÎßàÎã§ ÏÉÅÏÑ∏ Î°úÍ∑∏
        if analysisCallCount % 10 == 1 {
            logToFile("   ÏñºÍµ¥: \(faceResult != nil ? "‚úì" : "‚úó") | Ìè¨Ï¶à: \(poseResult != nil ? "‚úì (RTMPose)" : "‚úó")")
        }

        return (faceResult, poseResult)
    }

    // MARK: - RTMPose ÌÇ§Ìè¨Ïù∏Ìä∏ÏóêÏÑú ÏñºÍµ¥ Ï†ïÎ≥¥ Ï∂îÏ∂ú
    private func extractFaceFromPose(poseResult: PoseAnalysisResult?, imageSize: CGSize) -> FaceAnalysisResult? {
        guard let pose = poseResult, pose.keypoints.count >= 23 else {
            return nil
        }

        // RTMPose ÏñºÍµ¥ ÌÇ§Ìè¨Ïù∏Ìä∏ (23~90Î≤à): 68Í∞ú
        let faceKeypoints = Array(pose.keypoints[23..<min(91, pose.keypoints.count)])

        // Ïã†Î¢∞ÎèÑ ÏûàÎäî ÏñºÍµ¥ ÌÇ§Ìè¨Ïù∏Ìä∏ ÌïÑÌÑ∞ÎßÅ
        let validFacePoints = faceKeypoints.filter { $0.confidence > 0.3 }
        guard validFacePoints.count >= 5 else {
            return nil  // ÏµúÏÜå 5Í∞ú Ïù¥ÏÉÅÏùò ÌÇ§Ìè¨Ïù∏Ìä∏ ÌïÑÏöî
        }

        // ÏñºÍµ¥ Î∞îÏö¥Îî© Î∞ïÏä§ Í≥ÑÏÇ∞
        let facePoints = validFacePoints.map { $0.point }
        let minX = facePoints.map { $0.x }.min() ?? 0
        let maxX = facePoints.map { $0.x }.max() ?? 0
        let minY = facePoints.map { $0.y }.min() ?? 0
        let maxY = facePoints.map { $0.y }.max() ?? 0

        // Ï†ïÍ∑úÌôîÎêú Ï¢åÌëúÎ°ú Î≥ÄÌôò (0.0 ~ 1.0)
        let faceRect = CGRect(
            x: minX / imageSize.width,
            y: minY / imageSize.height,
            width: (maxX - minX) / imageSize.width,
            height: (maxY - minY) / imageSize.height
        )

        // yaw, pitch, roll Ï∂îÏ†ï (RTMPose Îàà/ÏΩî/ÏûÖ ÌÇ§Ìè¨Ïù∏Ìä∏ÏóêÏÑú)
        let (yaw, pitch, roll) = estimateFaceAngles(from: pose.keypoints, imageSize: imageSize)

        return FaceAnalysisResult(
            faceRect: faceRect,
            landmarks: nil,  // Vision landmarks ÏóÜÏùå
            yaw: yaw,
            pitch: pitch,
            roll: roll,
            observation: nil  // VNFaceObservation ÏóÜÏùå
        )
    }

    // MARK: - ÏñºÍµ¥ Í∞ÅÎèÑ Ï∂îÏ†ï (RTMPose ÌÇ§Ìè¨Ïù∏Ìä∏ Í∏∞Î∞ò)
    private func estimateFaceAngles(from keypoints: [(point: CGPoint, confidence: Float)], imageSize: CGSize) -> (Float?, Float?, Float?) {
        guard keypoints.count >= 17 else { return (nil, nil, nil) }

        // Îàà ÌÇ§Ìè¨Ïù∏Ìä∏ (1: left_eye, 2: right_eye)
        let leftEye = keypoints[1]
        let rightEye = keypoints[2]
        let nose = keypoints[0]

        guard leftEye.confidence > 0.5, rightEye.confidence > 0.5 else {
            return (nil, nil, nil)
        }

        // Roll (Ï¢åÏö∞ Í∏∞Ïö∏Í∏∞): Îëê ÎààÏùò y Ï∞®Ïù¥
        let eyeDy = leftEye.point.y - rightEye.point.y
        let eyeDx = leftEye.point.x - rightEye.point.x
        let roll = atan2(eyeDy, eyeDx)  // ÎùºÎîîÏïà

        // Yaw (Ï¢åÏö∞ ÌöåÏ†Ñ): Îëê ÎààÏùò x Í±∞Î¶¨ ÎπÑÏú®
        let eyeDistance = abs(leftEye.point.x - rightEye.point.x)
        let faceWidth = imageSize.width * 0.3  // ÌèâÍ∑† ÏñºÍµ¥ ÎÑàÎπÑ
        let yaw = (eyeDistance - faceWidth) / faceWidth * 0.5  // Ï†ïÍ∑úÌôî

        // Pitch (ÏÉÅÌïò Í∞ÅÎèÑ): ÏΩîÏôÄ ÎààÏùò y Ï∞®Ïù¥
        let pitch: Float? = nose.confidence > 0.5 ? Float((nose.point.y - leftEye.point.y) / imageSize.height) : nil

        return (Float(yaw), pitch, Float(roll))
    }

    // MARK: - RTMPose Ìè¨Ï¶à Í∞êÏßÄ
    private func detectPoseWithRTMPose(from image: UIImage) -> PoseAnalysisResult? {
        guard let runner = rtmPoseRunner else {
            return nil
        }

        guard let rtmResult = runner.detectPose(from: image) else {
            return nil
        }

        // üî• RTMPose 133Í∞ú ÌÇ§Ìè¨Ïù∏Ìä∏Î•º Ï†ÑÏ≤¥ ÏÇ¨Ïö©
        // RTMPoseÎäî 133Í∞ú ÌÇ§Ìè¨Ïù∏Ìä∏ Ï†úÍ≥µ (Ï†ÑÏã† 17 + ÏñºÍµ¥ 68 + ÏÜê 42 + Î∞ú 6)
        // Îçî Ï†ïÎ∞ÄÌïú Ìè¨Ï¶à ÎπÑÍµêÎ•º ÏúÑÌï¥ Ï†ÑÏ≤¥ ÌÇ§Ìè¨Ïù∏Ìä∏ ÏÇ¨Ïö©

        print("‚úÖ RTMPose: \(rtmResult.keypoints.count)Í∞ú ÌÇ§Ìè¨Ïù∏Ìä∏ Í≤ÄÏ∂ú")

        return PoseAnalysisResult(keypoints: rtmResult.keypoints)
    }

    /// Î∞ùÍ∏∞ Í≥ÑÏÇ∞ (VisionAnalyzerÏôÄ Ìò∏Ìôò)
    func calculateBrightness(from cgImage: CGImage) -> Float {
        let width = min(cgImage.width, 100)
        let height = min(cgImage.height, 100)

        guard let context = CGContext(
            data: nil,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: width * 4,
            space: CGColorSpaceCreateDeviceRGB(),
            bitmapInfo: CGImageAlphaInfo.premultipliedLast.rawValue
        ) else { return 0.5 }

        context.draw(cgImage, in: CGRect(x: 0, y: 0, width: width, height: height))
        guard let data = context.data else { return 0.5 }

        let buffer = data.bindMemory(to: UInt8.self, capacity: width * height * 4)
        var totalBrightness: Float = 0

        for i in stride(from: 0, to: width * height * 4, by: 4) {
            let r = Float(buffer[i]) / 255.0
            let g = Float(buffer[i + 1]) / 255.0
            let b = Float(buffer[i + 2]) / 255.0
            totalBrightness += (r + g + b) / 3.0
        }

        return totalBrightness / Float(width * height)
    }

    /// Ï†ÑÏã† ÏòÅÏó≠ Ï∂îÏ†ï (VisionAnalyzerÏôÄ Ìò∏Ìôò)
    func estimateBodyRect(from faceRect: CGRect?) -> CGRect? {
        guard let face = faceRect else { return nil }

        let bodyWidth = face.width * 3
        let bodyHeight = face.height * 7
        let bodyX = face.midX - bodyWidth / 2
        let bodyY = face.minY

        return CGRect(x: bodyX, y: bodyY, width: bodyWidth, height: bodyHeight)
    }
}
