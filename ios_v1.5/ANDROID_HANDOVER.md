# ğŸ¤– Android ê°œë°œì ì¸ìˆ˜ì¸ê³„ ë¬¸ì„œ

> **TryAngle v1.5 ì˜¨ë””ë°”ì´ìŠ¤ ë¶„ì„ ì‹œìŠ¤í…œ**
>
> ì‘ì„±ì¼: 2025-12-06
> iOS ë¸Œëœì¹˜: `feature/ios-v1.5-ondevice-optimization`

---

## ğŸ“‹ ëª©ì°¨

1. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ê°œìš”](#1-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜-ê°œìš”)
2. [í•„ìˆ˜ ëª¨ë¸ íŒŒì¼](#2-í•„ìˆ˜-ëª¨ë¸-íŒŒì¼)
3. [í•µì‹¬ íŒŒì¼ ëª©ë¡ ë° ì„¤ëª…](#3-í•µì‹¬-íŒŒì¼-ëª©ë¡-ë°-ì„¤ëª…)
4. [ì•Œê³ ë¦¬ì¦˜ ìƒì„¸ ì„¤ëª…](#4-ì•Œê³ ë¦¬ì¦˜-ìƒì„¸-ì„¤ëª…)
5. [ë°ì´í„° êµ¬ì¡°](#5-ë°ì´í„°-êµ¬ì¡°)
6. [ì•ˆë“œë¡œì´ë“œ ë³€í™˜ ê°€ì´ë“œ](#6-ì•ˆë“œë¡œì´ë“œ-ë³€í™˜-ê°€ì´ë“œ)

---

## 1. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ê°œìš”

### 1.1 ë ˆë²¨ë³„ ì²˜ë¦¬ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ì‹¤ì‹œê°„ ë¶„ì„ íŒŒì´í”„ë¼ì¸                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Level 1: RTMPose (ë§¤ í”„ë ˆì„)                                    â”‚
â”‚  â”œâ”€â”€ YOLOX: ì‚¬ëŒ ê²€ì¶œ (640x640)                                  â”‚
â”‚  â””â”€â”€ RTMPose: 133ê°œ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ (192x256)                       â”‚
â”‚                                                                 â”‚
â”‚  Level 2: Depth (5í”„ë ˆì„ë§ˆë‹¤)                                     â”‚
â”‚  â””â”€â”€ ì–¼êµ´ í¬ê¸° ê¸°ë°˜ ê±°ë¦¬/ì••ì¶•ê° ì¶”ì •                                â”‚
â”‚                                                                 â”‚
â”‚  Level 3: Grounding DINO (30í”„ë ˆì„ë§ˆë‹¤)                          â”‚
â”‚  â””â”€â”€ ì •ë°€ ë°”ìš´ë”© ë°•ìŠ¤ ê²€ì¶œ (800x800)                               â”‚
â”‚                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     Gate System (4ë‹¨ê³„ í‰ê°€)                      â”‚
â”‚  Gate 1: ì—¬ë°± ê· í˜• (threshold: 70%)                              â”‚
â”‚  Gate 2: í”„ë ˆì´ë° (threshold: 65%)                               â”‚
â”‚  Gate 3: êµ¬ë„ (threshold: 70%)                                   â”‚
â”‚  Gate 4: ì••ì¶•ê° (threshold: 60%)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 ë°œì—´ ìƒíƒœ ê¸°ë°˜ ë™ì  í”„ë ˆì„ ìŠ¤í‚µ

| ë°œì—´ ìƒíƒœ | Level 1 | Level 2 | Level 3 | ë¶„ì„ ê°„ê²© |
|-----------|---------|---------|---------|-----------|
| nominal   | 1í”„ë ˆì„ | 5í”„ë ˆì„ | 30í”„ë ˆì„ | 16ms (60fps) |
| fair      | 1í”„ë ˆì„ | 5í”„ë ˆì„ | 30í”„ë ˆì„ | 16ms |
| serious   | 2í”„ë ˆì„ | 10í”„ë ˆì„ | 60í”„ë ˆì„ | 22ms (45fps) |
| critical  | 3í”„ë ˆì„ | 15í”„ë ˆì„ | 90í”„ë ˆì„ | 33ms (30fps) |

---

## 2. í•„ìˆ˜ ëª¨ë¸ íŒŒì¼

### 2.1 ONNX ëª¨ë¸ (í•„ìˆ˜)

| ëª¨ë¸ | íŒŒì¼ëª… | í¬ê¸° | ë‹¤ìš´ë¡œë“œ ë§í¬ |
|------|--------|------|---------------|
| YOLOX (ì‚¬ëŒ ê²€ì¶œ) | `yolox_int8.onnx` | 97MB | [RTMDet-ONNX](https://github.com/open-mmlab/mmpose/tree/main/projects/rtmpose) |
| RTMPose (í¬ì¦ˆ ì¶”ì •) | `rtmpose_int8.onnx` | 218MB | [RTMPose-ONNX](https://github.com/open-mmlab/mmpose/tree/main/projects/rtmpose) |
| Grounding DINO | `grounding_dino.onnx` | 194MB | [HuggingFace](https://huggingface.co/onnx-community/grounding-dino-tiny-ONNX) |

### 2.2 ëª¨ë¸ ì…ë ¥/ì¶œë ¥ ìŠ¤í™

#### YOLOX (ì‚¬ëŒ ê²€ì¶œ)
```
ì…ë ¥: "input" - [1, 3, 640, 640] float32 (RGB, ImageNet ì •ê·œí™”)
ì¶œë ¥:
  - "dets" - [1, N, 5] float32 (x1, y1, x2, y2, score)
  - "labels" - [1, N] int64 (class_id, person=0)
```

#### RTMPose (í¬ì¦ˆ ì¶”ì •)
```
ì…ë ¥: "input" - [1, 3, 256, 192] float32 (RGB, ImageNet ì •ê·œí™”)
ì¶œë ¥:
  - "simcc_x" - [1, 133, 384] float32 (xì¢Œí‘œ í™•ë¥ ë¶„í¬)
  - "simcc_y" - [1, 133, 512] float32 (yì¢Œí‘œ í™•ë¥ ë¶„í¬)
```

#### Grounding DINO
```
ì…ë ¥:
  - "pixel_values" - [1, 3, 800, 800] float32
  - "pixel_mask" - [1, 800, 800] int64
  - "input_ids" - [1, 3] int64 ([101, 2711, 102] = "person")
  - "attention_mask" - [1, 3] int64
  - "token_type_ids" - [1, 3] int64
ì¶œë ¥:
  - "logits" - [1, 900, 1] float32
  - "pred_boxes" - [1, 900, 4] float32 (cx, cy, w, h normalized)
```

---

## 3. í•µì‹¬ íŒŒì¼ ëª©ë¡ ë° ì„¤ëª…

### 3.1 ğŸ”´ ë°˜ë“œì‹œ ë³€í™˜í•´ì•¼ í•  í•µì‹¬ íŒŒì¼ (ìš°ì„ ìˆœìœ„ ìˆœ)

```
ios_v1.5/TryAngleApp/Services/
â”œâ”€â”€ OnDevice/                          # â­ ì˜¨ë””ë°”ì´ìŠ¤ ë¶„ì„ í•µì‹¬
â”‚   â”œâ”€â”€ GateSystem.swift               # â­â­â­ Gate í‰ê°€ ë¡œì§ (í•„ìˆ˜)
â”‚   â”œâ”€â”€ MarginAnalyzer.swift           # â­â­â­ ì—¬ë°± ë¶„ì„ (í•„ìˆ˜)
â”‚   â”œâ”€â”€ GroundingDINOONNX.swift        # â­â­ ONNX ì¶”ë¡  (í•„ìˆ˜)
â”‚   â”œâ”€â”€ GroundingDINOCoreML.swift      # â­â­ í†µí•© ì¸í„°í˜ì´ìŠ¤
â”‚   â”œâ”€â”€ V15FeedbackGenerator.swift     # â­â­ í”¼ë“œë°± ìƒì„±
â”‚   â”œâ”€â”€ PerformanceOptimizer.swift     # â­ ì„±ëŠ¥ ìµœì í™”
â”‚   â”œâ”€â”€ CacheManager.swift             # ìºì‹œ ê´€ë¦¬
â”‚   â””â”€â”€ TryAngleOnDeviceAnalyzer.swift # í†µí•© ë¶„ì„ê¸°
â”‚
â”œâ”€â”€ Analysis/                          # ë¶„ì„ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ RTMPoseRunner.swift            # â­â­â­ ONNX í¬ì¦ˆ ì¶”ì • (í•„ìˆ˜)
â”‚   â”œâ”€â”€ PoseMLAnalyzer.swift           # í¬ì¦ˆ ë¶„ì„ ë˜í¼
â”‚   â”œâ”€â”€ DepthEstimator.swift           # ê±°ë¦¬/ì••ì¶•ê° ì¶”ì •
â”‚   â”œâ”€â”€ PhotographyFramingAnalyzer.swift # ì‚¬ì§„í•™ í”„ë ˆì´ë°
â”‚   â””â”€â”€ GazeTracker.swift              # ì‹œì„  ì¶”ì 
â”‚
â”œâ”€â”€ Comparison/                        # ë¹„êµ ë¶„ì„
â”‚   â”œâ”€â”€ AdaptivePoseComparator.swift   # â­â­ í¬ì¦ˆ ë¹„êµ (í•„ìˆ˜)
â”‚   â”œâ”€â”€ StagedFeedbackGenerator.swift  # ë‹¨ê³„ë³„ í”¼ë“œë°±
â”‚   â”œâ”€â”€ GapAnalyzer.swift              # ì°¨ì´ ë¶„ì„
â”‚   â””â”€â”€ FeedbackGenerator.swift        # í”¼ë“œë°± ìƒì„±
â”‚
â”œâ”€â”€ RuleEngine/                        # ê·œì¹™ ì—”ì§„
â”‚   â”œâ”€â”€ CameraAngleDetector.swift      # ì¹´ë©”ë¼ ì•µê¸€ ê°ì§€
â”‚   â””â”€â”€ CompositionAnalyzer.swift      # êµ¬ë„ ë¶„ì„
â”‚
â”œâ”€â”€ RealtimeAnalyzer.swift             # â­â­â­ ì‹¤ì‹œê°„ í†µí•© (í•„ìˆ˜)
â”œâ”€â”€ ThermalStateManager.swift          # ë°œì—´ ê´€ë¦¬
â””â”€â”€ CameraManager.swift                # ì¹´ë©”ë¼ ê´€ë¦¬
```

### 3.2 ë°ì´í„° ëª¨ë¸ íŒŒì¼

```
ios_v1.5/TryAngleApp/Models/
â””â”€â”€ Feedback.swift                     # â­â­â­ ëª¨ë“  ë°ì´í„° êµ¬ì¡° ì •ì˜ (í•„ìˆ˜)
```

---

## 4. ì•Œê³ ë¦¬ì¦˜ ìƒì„¸ ì„¤ëª…

### 4.1 GateSystem.swift (â­â­â­ í•µì‹¬)

```kotlin
// ì•ˆë“œë¡œì´ë“œ ë³€í™˜ ì˜ˆì‹œ (Kotlin)

data class GateResult(
    val passed: Boolean,
    val score: Float,       // 0.0 ~ 1.0
    val threshold: Float,
    val feedback: String
)

data class GateEvaluation(
    val gate1: GateResult,  // ì—¬ë°± ê· í˜•
    val gate2: GateResult,  // í”„ë ˆì´ë°
    val gate3: GateResult,  // êµ¬ë„
    val gate4: GateResult,  // ì••ì¶•ê°
    val overallScore: Float,
    val allPassed: Boolean,
    val primaryFeedback: String
)

class GateSystem {
    companion object {
        // Gate ì„ê³„ê°’
        const val MARGIN_THRESHOLD = 0.70f
        const val FRAMING_THRESHOLD = 0.65f
        const val COMPOSITION_THRESHOLD = 0.70f
        const val COMPRESSION_THRESHOLD = 0.60f
    }

    fun evaluate(
        currentBBox: RectF,
        referenceBBox: RectF,
        currentImageSize: Size,
        referenceImageSize: Size,
        compressionIndex: Float?,
        referenceCompressionIndex: Float?
    ): GateEvaluation {
        // êµ¬í˜„ ë‚´ìš©ì€ GateSystem.swift ì°¸ì¡°
    }
}
```

### 4.2 MarginAnalyzer.swift (â­â­â­ í•µì‹¬)

```kotlin
// ì—¬ë°± ë¶„ì„ ê²°ê³¼
data class MarginAnalysisResult(
    val left: Float,
    val right: Float,
    val top: Float,
    val bottom: Float,
    val horizontalBalance: Float,  // ì¢Œìš° ê· í˜• (0.0 ~ 1.0)
    val verticalBalance: Float,    // ìƒí•˜ ê· í˜• (0.0 ~ 1.0)
    val overallScore: Float,
    val movementDirection: MovementDirection?
)

// ì›€ì§ì„ ë°©í–¥ í”¼ë“œë°±
data class MovementDirection(
    val horizontal: Float,  // -1.0(ì™¼ìª½) ~ 1.0(ì˜¤ë¥¸ìª½)
    val vertical: Float,    // -1.0(ìœ„) ~ 1.0(ì•„ë˜)
    val primaryArrow: String,
    val description: String
)

class MarginAnalyzer {
    fun analyze(
        bbox: RectF,
        imageSize: Size,
        isNormalized: Boolean = true
    ): MarginAnalysisResult {
        // ì •ê·œí™” ì¢Œí‘œ (0.0 ~ 1.0) ê°€ì •
        val left = bbox.left
        val right = 1.0f - bbox.right
        val top = 1.0f - bbox.bottom  // Yì¶• ë°˜ì „ ì£¼ì˜
        val bottom = bbox.top

        // ì¢Œìš° ê· í˜• ì ìˆ˜ (ê°™ì„ìˆ˜ë¡ 1.0)
        val horizontalBalance = 1.0f - abs(left - right) * 2

        // ìƒí•˜ ê· í˜• ì ìˆ˜ (ìƒë‹¨ ì—¬ë°±ì´ ë” ì‘ì•„ì•¼ í•¨ - 2:1 ë¹„ìœ¨ ì„ í˜¸)
        val idealTopRatio = 0.33f
        val verticalBalance = 1.0f - abs(top / (top + bottom) - idealTopRatio) * 3

        // ì¢…í•© ì ìˆ˜
        val overallScore = (horizontalBalance * 0.5f + verticalBalance * 0.5f)
            .coerceIn(0.0f, 1.0f)

        return MarginAnalysisResult(...)
    }
}
```

### 4.3 RTMPoseRunner.swift (â­â­â­ í•µì‹¬)

```kotlin
// 133ê°œ í‚¤í¬ì¸íŠ¸ ì¸ë±ìŠ¤
object RTMPoseKeypoints {
    // ëª¸í†µ (0-16)
    const val NOSE = 0
    const val LEFT_EYE = 1
    const val RIGHT_EYE = 2
    const val LEFT_EAR = 3
    const val RIGHT_EAR = 4
    const val LEFT_SHOULDER = 5
    const val RIGHT_SHOULDER = 6
    const val LEFT_ELBOW = 7
    const val RIGHT_ELBOW = 8
    const val LEFT_WRIST = 9
    const val RIGHT_WRIST = 10
    const val LEFT_HIP = 11
    const val RIGHT_HIP = 12
    const val LEFT_KNEE = 13
    const val RIGHT_KNEE = 14
    const val LEFT_ANKLE = 15
    const val RIGHT_ANKLE = 16

    // ë°œ (17-22)
    const val LEFT_BIG_TOE = 17
    const val LEFT_SMALL_TOE = 18
    const val LEFT_HEEL = 19
    const val RIGHT_BIG_TOE = 20
    const val RIGHT_SMALL_TOE = 21
    const val RIGHT_HEEL = 22

    // ì–¼êµ´ (23-90): 68ê°œ ëœë“œë§ˆí¬
    val FACE_RANGE = 23..90

    // ì™¼ì† (91-111): 21ê°œ ê´€ì ˆ
    val LEFT_HAND_RANGE = 91..111

    // ì˜¤ë¥¸ì† (112-132): 21ê°œ ê´€ì ˆ
    val RIGHT_HAND_RANGE = 112..132
}

class RTMPoseRunner(context: Context) {
    private val ortEnv = OrtEnvironment.getEnvironment()
    private val yoloxSession: OrtSession
    private val poseSession: OrtSession

    init {
        // ONNX Runtime ì„¸ì…˜ ìƒì„±
        val sessionOptions = OrtSession.SessionOptions().apply {
            // NNAPI ê°€ì† (Android)
            addNnapi()
            setIntraOpNumThreads(6)
            setGraphOptimizationLevel(OrtSession.SessionOptions.OptLevel.ALL_OPT)
        }

        yoloxSession = ortEnv.createSession(loadModel("yolox_int8.onnx"), sessionOptions)
        poseSession = ortEnv.createSession(loadModel("rtmpose_int8.onnx"), sessionOptions)
    }

    fun detectPose(bitmap: Bitmap): List<Keypoint>? {
        // 1. YOLOXë¡œ ì‚¬ëŒ ê²€ì¶œ
        val bbox = detectPerson(bitmap) ?: return null

        // 2. ë°”ìš´ë”© ë°•ìŠ¤ ì˜ì—­ í¬ë¡­ (40% íŒ¨ë”©)
        val croppedBitmap = cropWithPadding(bitmap, bbox, padding = 0.4f)

        // 3. 192x256ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        val resizedBitmap = Bitmap.createScaledBitmap(croppedBitmap, 192, 256, true)

        // 4. ì´ë¯¸ì§€ ì •ê·œí™” (ImageNet)
        val inputTensor = preprocessImage(resizedBitmap)

        // 5. ì¶”ë¡ 
        val outputs = poseSession.run(mapOf("input" to inputTensor))

        // 6. SimCC ì¶œë ¥ íŒŒì‹±
        return parseSimCCOutput(outputs, bbox)
    }

    private fun preprocessImage(bitmap: Bitmap): OnnxTensor {
        val mean = floatArrayOf(0.485f, 0.456f, 0.406f)
        val std = floatArrayOf(0.229f, 0.224f, 0.225f)

        val pixels = IntArray(192 * 256)
        bitmap.getPixels(pixels, 0, 192, 0, 0, 192, 256)

        val floatBuffer = FloatBuffer.allocate(3 * 256 * 192)

        for (c in 0..2) {
            for (i in pixels.indices) {
                val pixel = pixels[i]
                val value = when (c) {
                    0 -> (pixel shr 16 and 0xFF) / 255f
                    1 -> (pixel shr 8 and 0xFF) / 255f
                    else -> (pixel and 0xFF) / 255f
                }
                floatBuffer.put(c * 256 * 192 + i, (value - mean[c]) / std[c])
            }
        }

        return OnnxTensor.createTensor(ortEnv, floatBuffer, longArrayOf(1, 3, 256, 192))
    }

    private fun parseSimCCOutput(outputs: OrtSession.Result, bbox: RectF): List<Keypoint> {
        val simccX = outputs["simcc_x"].get().value as Array<Array<FloatArray>>
        val simccY = outputs["simcc_y"].get().value as Array<Array<FloatArray>>

        val keypoints = mutableListOf<Keypoint>()

        for (i in 0 until 133) {
            // argmaxë¡œ ìµœëŒ€ê°’ ì¸ë±ìŠ¤ ì°¾ê¸°
            val xIdx = simccX[0][i].indices.maxByOrNull { simccX[0][i][it] } ?: 0
            val yIdx = simccY[0][i].indices.maxByOrNull { simccY[0][i][it] } ?: 0

            // SimCC ì¢Œí‘œë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
            val x = xIdx.toFloat() / 384f * 192f
            val y = yIdx.toFloat() / 512f * 256f

            // ë°”ìš´ë”© ë°•ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
            val realX = bbox.left + (x / 192f) * bbox.width()
            val realY = bbox.top + (y / 256f) * bbox.height()

            // ì‹ ë¢°ë„ ê³„ì‚°
            val confidence = (simccX[0][i][xIdx] + simccY[0][i][yIdx]) / 2f

            keypoints.add(Keypoint(realX, realY, confidence))
        }

        return keypoints
    }
}
```

### 4.4 AdaptivePoseComparator.swift (â­â­ ì¤‘ìš”)

```kotlin
data class PoseComparisonResult(
    val overallSimilarity: Float,      // 0.0 ~ 1.0
    val bodyAngleSimilarity: Float,
    val limbPositionSimilarity: Float,
    val missingGroups: List<KeypointGroup>,
    val mismatchedJoints: List<Int>
)

enum class KeypointGroup {
    HEAD, TORSO, LEFT_ARM, RIGHT_ARM, LEFT_LEG, RIGHT_LEG, LEFT_HAND, RIGHT_HAND
}

class AdaptivePoseComparator {

    // í‚¤í¬ì¸íŠ¸ ê·¸ë£¹ ì •ì˜
    private val groupIndices = mapOf(
        KeypointGroup.HEAD to listOf(0, 1, 2, 3, 4),
        KeypointGroup.TORSO to listOf(5, 6, 11, 12),
        KeypointGroup.LEFT_ARM to listOf(5, 7, 9),
        KeypointGroup.RIGHT_ARM to listOf(6, 8, 10),
        KeypointGroup.LEFT_LEG to listOf(11, 13, 15),
        KeypointGroup.RIGHT_LEG to listOf(12, 14, 16),
        KeypointGroup.LEFT_HAND to (91..111).toList(),
        KeypointGroup.RIGHT_HAND to (112..132).toList()
    )

    fun comparePoses(
        referenceKeypoints: List<Keypoint>,
        currentKeypoints: List<Keypoint>,
        confidenceThreshold: Float = 0.3f
    ): PoseComparisonResult {

        // 1. ìœ íš¨í•œ í‚¤í¬ì¸íŠ¸ë§Œ í•„í„°ë§
        val validRefIndices = referenceKeypoints.indices
            .filter { referenceKeypoints[it].confidence >= confidenceThreshold }
        val validCurIndices = currentKeypoints.indices
            .filter { currentKeypoints[it].confidence >= confidenceThreshold }

        // 2. ê³µí†µ í‚¤í¬ì¸íŠ¸ë¡œ ì •ê·œí™”
        val commonIndices = validRefIndices.intersect(validCurIndices.toSet())

        // 3. ê°ë„ ìœ ì‚¬ë„ ê³„ì‚° (íŒ”, ë‹¤ë¦¬ ê°ë„)
        val bodyAngleSimilarity = calculateAngleSimilarity(
            referenceKeypoints, currentKeypoints, commonIndices
        )

        // 4. ìƒëŒ€ ìœ„ì¹˜ ìœ ì‚¬ë„
        val limbPositionSimilarity = calculatePositionSimilarity(
            referenceKeypoints, currentKeypoints, commonIndices
        )

        // 5. ëˆ„ë½ëœ ê·¸ë£¹ ê°ì§€
        val missingGroups = detectMissingGroups(
            referenceKeypoints, currentKeypoints, confidenceThreshold
        )

        // 6. ì¢…í•© ìœ ì‚¬ë„
        val overallSimilarity = (bodyAngleSimilarity * 0.6f + limbPositionSimilarity * 0.4f)
            .coerceIn(0f, 1f)

        return PoseComparisonResult(
            overallSimilarity = overallSimilarity,
            bodyAngleSimilarity = bodyAngleSimilarity,
            limbPositionSimilarity = limbPositionSimilarity,
            missingGroups = missingGroups,
            mismatchedJoints = findMismatchedJoints(referenceKeypoints, currentKeypoints)
        )
    }

    private fun calculateAngleSimilarity(
        ref: List<Keypoint>,
        cur: List<Keypoint>,
        indices: Set<Int>
    ): Float {
        // íŒ”ê¿ˆì¹˜ ê°ë„ (5-7-9, 6-8-10)
        // ë¬´ë¦ ê°ë„ (11-13-15, 12-14-16)
        // ê° ê´€ì ˆì˜ ê°ë„ ì°¨ì´ ê³„ì‚° í›„ ìœ ì‚¬ë„ë¡œ ë³€í™˜
        // êµ¬í˜„ ìƒì„¸ëŠ” AdaptivePoseComparator.swift ì°¸ì¡°
        return 0.8f  // ì˜ˆì‹œ
    }
}
```

---

## 5. ë°ì´í„° êµ¬ì¡°

### 5.1 Feedback.swift ì—ì„œ ê°€ì ¸ì˜¬ êµ¬ì¡°ì²´

```kotlin
// ì¹´ë©”ë¼ ë¹„ìœ¨
enum class CameraAspectRatio(val displayName: String, val ratio: Float) {
    RATIO_16_9("16:9", 16f / 9f),
    RATIO_4_3("4:3", 4f / 3f),
    RATIO_1_1("1:1", 1f);

    companion object {
        fun detect(size: Size): CameraAspectRatio {
            val longSide = maxOf(size.width, size.height).toFloat()
            val shortSide = minOf(size.width, size.height).toFloat()
            val ratio = longSide / shortSide

            return values().minByOrNull { abs(it.ratio - ratio) } ?: RATIO_4_3
        }
    }
}

// í”¼ë“œë°± ì¹´í…Œê³ ë¦¬
enum class FeedbackCategory(val priority: Int, val displayName: String) {
    POSE(1, "í¬ì¦ˆ"),
    POSITION(2, "ì¸ë¬¼ ìœ„ì¹˜"),
    FRAMING(3, "í”„ë ˆì´ë°"),
    ANGLE(4, "ì¹´ë©”ë¼ ì•µê¸€"),
    COMPOSITION(5, "êµ¬ë„"),
    GAZE(6, "ì‹œì„ ");

    companion object {
        fun from(categoryString: String): FeedbackCategory? {
            return when {
                categoryString.startsWith("v15_margin") -> POSITION
                categoryString.startsWith("v15_framing") -> FRAMING
                categoryString.startsWith("v15_composition") -> COMPOSITION
                categoryString.startsWith("v15_compression") -> FRAMING
                categoryString.startsWith("pose_") -> POSE
                else -> null
            }
        }
    }
}

// í”¼ë“œë°± ì•„ì´í…œ
data class FeedbackItem(
    val priority: Int,
    val icon: String,
    val message: String,
    val category: String,
    val currentValue: Double?,
    val targetValue: Double?,
    val tolerance: Double?,
    val unit: String?
)

// ì¹´í…Œê³ ë¦¬ ìƒíƒœ (UI ì²´í¬í‘œì‹œìš©)
data class CategoryStatus(
    val category: FeedbackCategory,
    val isSatisfied: Boolean,
    val activeFeedbacks: List<FeedbackItem>
)
```

---

## 6. ì•ˆë“œë¡œì´ë“œ ë³€í™˜ ê°€ì´ë“œ

### 6.1 ONNX Runtime ì„¤ì •

```gradle
// build.gradle (app)
dependencies {
    implementation 'com.microsoft.onnxruntime:onnxruntime-android:1.16.3'
}
```

### 6.2 ëª¨ë¸ íŒŒì¼ ìœ„ì¹˜

```
app/src/main/assets/
â”œâ”€â”€ yolox_int8.onnx        (97MB)
â”œâ”€â”€ rtmpose_int8.onnx      (218MB)
â””â”€â”€ grounding_dino.onnx    (194MB)
```

### 6.3 ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ìµœì í™”

```kotlin
// RenderScript ë˜ëŠ” Vulkan Compute Shader í™œìš© ê¶Œì¥
// iOSì˜ Accelerate/vDSP ëŒ€ì‹  Androidì—ì„œëŠ”:
// 1. RenderScript (deprecated but fast)
// 2. Vulkan Compute Shader
// 3. NDK + NEON intrinsics
```

### 6.4 íŒŒì¼ë³„ ë³€í™˜ ìš°ì„ ìˆœìœ„

| ìˆœìœ„ | iOS íŒŒì¼ | ì„¤ëª… | ë‚œì´ë„ |
|------|----------|------|--------|
| 1 | `GateSystem.swift` | í•µì‹¬ í‰ê°€ ë¡œì§ | â­ ì‰¬ì›€ |
| 2 | `MarginAnalyzer.swift` | ì—¬ë°± ë¶„ì„ | â­ ì‰¬ì›€ |
| 3 | `RTMPoseRunner.swift` | ONNX í¬ì¦ˆ ì¶”ì • | â­â­â­ ì–´ë ¤ì›€ |
| 4 | `GroundingDINOONNX.swift` | ONNX ê°ì²´ ê²€ì¶œ | â­â­ ì¤‘ê°„ |
| 5 | `AdaptivePoseComparator.swift` | í¬ì¦ˆ ë¹„êµ | â­â­ ì¤‘ê°„ |
| 6 | `V15FeedbackGenerator.swift` | í”¼ë“œë°± ìƒì„± | â­ ì‰¬ì›€ |
| 7 | `RealtimeAnalyzer.swift` | í†µí•© ê´€ë¦¬ | â­â­â­ ì–´ë ¤ì›€ |
| 8 | `PerformanceOptimizer.swift` | ì„±ëŠ¥ ìµœì í™” | â­â­ ì¤‘ê°„ |

### 6.5 ì£¼ì˜ì‚¬í•­

1. **ì¢Œí‘œê³„ ì°¨ì´**: iOS Visionì€ Yì¶•ì´ ì•„ë˜ì—ì„œ ìœ„ë¡œ (0=í•˜ë‹¨, 1=ìƒë‹¨). AndroidëŠ” ë°˜ëŒ€ì¼ ìˆ˜ ìˆìŒ
2. **ì´ë¯¸ì§€ íšŒì „**: ì¹´ë©”ë¼ íšŒì „ ì²˜ë¦¬ í™•ì¸ í•„ìš”
3. **ë°œì—´ ê´€ë¦¬**: Androidì˜ `PowerManager` í™œìš©
4. **ë©”ëª¨ë¦¬ ê´€ë¦¬**: í° ëª¨ë¸ì´ë¯€ë¡œ ë©”ëª¨ë¦¬ ë¦­ ì£¼ì˜

---

## ğŸ“ ì—°ë½ì²˜

iOS ê°œë°œ ê´€ë ¨ ì§ˆë¬¸: [ì´ ë¬¸ì„œê°€ í¬í•¨ëœ ë¸Œëœì¹˜ì˜ ì½”ë“œ ì°¸ì¡°]

---

*ì´ ë¬¸ì„œëŠ” Claude Codeë¡œ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
