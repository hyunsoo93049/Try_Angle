# ğŸ“¸ TryAngle iOS v1.5 - ì‹¤ì‹œê°„ ì‚¬ì§„ êµ¬ë„ ê°€ì´ë“œ ì‹œìŠ¤í…œ

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

TryAngleì€ **AI ê¸°ë°˜ ì‹¤ì‹œê°„ ì‚¬ì§„ êµ¬ë„ ê°€ì´ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜**ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ë ˆí¼ëŸ°ìŠ¤ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ë©´, ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ë·°ë¥¼ ë¶„ì„í•˜ì—¬ ë™ì¼í•œ êµ¬ë„ë¥¼ ì¬í˜„í•  ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥
- **5ë‹¨ê³„ Gate ì‹œìŠ¤í…œ**: ë¹„ìœ¨, ìƒ·íƒ€ì…, ì—¬ë°±, ì••ì¶•ê°, í¬ì¦ˆë¥¼ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€
- **ì‹¤ì‹œê°„ ë¶„ì„**: 50ms ê°„ê²©ìœ¼ë¡œ í”„ë ˆì„ ë¶„ì„ ë° ì¦‰ê°ì  í”¼ë“œë°±
- **í†µí•© í”¼ë“œë°±**: í•˜ë‚˜ì˜ ë™ì‘ìœ¼ë¡œ ì—¬ëŸ¬ ë¬¸ì œë¥¼ ë™ì‹œì— í•´ê²°í•˜ëŠ” ìŠ¤ë§ˆíŠ¸ ê°€ì´ë“œ
- **ì•ˆì •í™” ì‹œìŠ¤í…œ**: ê¹œë¹¡ì„ ë°©ì§€ ë° Temporal Lockìœ¼ë¡œ ì™„ë²½í•œ ìˆœê°„ í¬ì°©

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì „ì²´ íë¦„ë„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ë ˆí¼ëŸ°ìŠ¤ ì—…ë¡œë“œ  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„ (1íšŒ)            â”‚
â”‚  - RTMPose (133 í‚¤í¬ì¸íŠ¸)        â”‚
â”‚  - Depth Anything (ì••ì¶•ê°)       â”‚
â”‚  - YOLOX (ì •ë°€ BBox)             â”‚
â”‚  - MarginAnalyzer (ì—¬ë°±)         â”‚
â”‚  - FocalLengthEstimator (ì´ˆì ê±°ë¦¬)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ ìºì‹±
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ì‹¤ì‹œê°„ ë¶„ì„ (50msë§ˆë‹¤)         â”‚
â”‚  - RTMPose (í˜„ì¬ í¬ì¦ˆ)           â”‚
â”‚  - Depth Anything (í”„ë ˆì„ ìŠ¤í‚µ)  â”‚
â”‚  - YOLOX (í”„ë ˆì„ ìŠ¤í‚µ)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Gate System í‰ê°€              â”‚
â”‚  Gate 0: ë¹„ìœ¨ (ì ˆëŒ€ ìš°ì„ )       â”‚
â”‚  Gate 1: í”„ë ˆì´ë° (ìƒ·íƒ€ì…)      â”‚
â”‚  Gate 2: ìœ„ì¹˜/ì—¬ë°±              â”‚
â”‚  Gate 3: ì••ì¶•ê° (ì´ˆì ê±°ë¦¬)      â”‚
â”‚  Gate 4: í¬ì¦ˆ                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   UnifiedFeedbackGenerator      â”‚
â”‚  "í•œ ê±¸ìŒ ì•ìœ¼ë¡œ"                â”‚
â”‚  "ì¤Œì¸ í›„ ë‘ ê±¸ìŒ ë’¤ë¡œ"          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   UI ì—…ë°ì´íŠ¸                   â”‚
â”‚  - í”¼ë“œë°± í‘œì‹œ                  â”‚
â”‚  - Gate ì ìˆ˜ ì‹œê°í™”             â”‚
â”‚  - Temporal Lock ì§„í–‰ë°”         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– AI ëª¨ë¸ êµ¬ì„±

### 1. RTMPose (í¬ì¦ˆ ì¶”ì •)

#### ëª¨ë¸ êµ¬ì¡°
- **Stage 1**: YOLOX - ì¸ë¬¼ ê²€ì¶œ (BBox ì¶”ì¶œ)
- **Stage 2**: RTMPose - 133ê°œ í‚¤í¬ì¸íŠ¸ ì¶”ì •

#### í‚¤í¬ì¸íŠ¸ êµ¬ì„±
| ê·¸ë£¹ | ë²”ìœ„ | ê°œìˆ˜ | ì„¤ëª… |
|------|------|------|------|
| Body | 0-16 | 17ê°œ | ì½”, ëˆˆ, ì–´ê¹¨, íŒ”ê¿ˆì¹˜, ì†ëª©, ì—‰ë©ì´, ë¬´ë¦, ë°œëª© |
| Feet | 17-22 | 6ê°œ | ë°œê°€ë½, ë’¤ê¿ˆì¹˜ |
| Face | 23-90 | 68ê°œ | ì–¼êµ´ ìœ¤ê³½, ëˆˆì¹, ì½”, ëˆˆ, ì… |
| Left Hand | 91-111 | 21ê°œ | ì†ëª© + ì†ê°€ë½ ê´€ì ˆ (ì—„ì§€~ì†Œì§€) |
| Right Hand | 112-132 | 21ê°œ | ì†ëª© + ì†ê°€ë½ ê´€ì ˆ (ì—„ì§€~ì†Œì§€) |

#### ë™ì‘ ì›ë¦¬
```swift
// 1. YOLOXë¡œ ì¸ë¬¼ BBox ê²€ì¶œ
640x640 ì…ë ¥ â†’ YOLOX â†’ BBox (x1, y1, x2, y2, confidence)

// 2. BBox ì˜ì—­ í¬ë¡­ (40% íŒ¨ë”© ì¶”ê°€ë¡œ ì† í¬í•¨)
croppedImage = cropWithPadding(image, bbox, padding: 0.4)

// 3. RTMPoseë¡œ í‚¤í¬ì¸íŠ¸ ì¶”ì •
192x256 ì…ë ¥ â†’ RTMPose â†’ SimCC ì¶œë ¥ (x: 384 bins, y: 512 bins)

// 4. SimCCì—ì„œ ì¢Œí‘œ ì¶”ì¶œ
for each keypoint:
    x_coord = argmax(simcc_x[i]) / 384 * 192
    y_coord = argmax(simcc_y[i]) / 512 * 256
    confidence = (max(simcc_x[i]) + max(simcc_y[i])) / 2
```

#### ì„±ëŠ¥ ìµœì í™”
- **CoreML GPU ê°€ì†**: CPU ëŒ€ë¹„ 3-5ë°° ê³ ì†í™”
- **Accelerate ë²¡í„°í™”**: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë³‘ë ¬í™” (40% ì†ë„ í–¥ìƒ)
- **ì¶”ë¡  ì‹œê°„**: 50-100ms (iPhone 12 Pro ê¸°ì¤€)

#### ì½”ë“œ ìœ„ì¹˜
- `ios_v1.5/TryAngleApp/Services/Analysis/RTMPoseRunner.swift`
- `ios_v1.5/TryAngleApp/Services/OnDevice/PersonDetector.swift`

---

### 2. Depth Anything V2 (ê¹Šì´ ì¶”ì •)

#### ëª¨ë¸ ì •ë³´
- **ëª¨ë¸ëª…**: DepthAnythingV2SmallF16 (Apple CoreML ë²„ì „)
- **ì…ë ¥**: 518x518 RGB ì´ë¯¸ì§€
- **ì¶œë ¥**: Depth Map (Float32 PixelBuffer)

#### ì••ì¶•ê° ê³„ì‚° ì•Œê³ ë¦¬ì¦˜
```python
# 1. ë°°ê²½ ê¹Šì´ (ìƒë‹¨ 1/3)
backgroundDepth = mean(depthMap[0 : height/3, :])

# 2. ì „ê²½ ê¹Šì´ (í•˜ë‹¨ 1/4)
foregroundDepth = mean(depthMap[3*height/4 : height, :])

# 3. ì••ì¶•ê° ì§€ìˆ˜ (0=ê´‘ê°, 1=ë§ì›)
depthRange = abs(backgroundDepth - foregroundDepth)
compressionIndex = 1.0 - min(depthRange * 2, 1.0)
```

#### ì••ì¶•ê° â†’ ì¹´ë©”ë¼ íƒ€ì… ë§¤í•‘
| compressionIndex | ì¹´ë©”ë¼ íƒ€ì… | 35mm í™˜ì‚° ì´ˆì ê±°ë¦¬ |
|------------------|-------------|-------------------|
| 0.0 ~ 0.3 | ê´‘ê° (Wide) | 24-35mm |
| 0.3 ~ 0.5 | í‘œì¤€ (Normal) | 35-50mm |
| 0.5 ~ 0.7 | ì¤€ë§ì› (Semi-Tele) | 50-85mm |
| 0.7 ~ 1.0 | ë§ì› (Telephoto) | 85mm+ |

#### ì„±ëŠ¥ ìµœì í™”
- **í”„ë ˆì„ ìŠ¤í‚µ**: Level 2 (10í”„ë ˆì„ë§ˆë‹¤ 1íšŒ ì‹¤í–‰)
- **ë™ì‹œ ì‹¤í–‰ ë°©ì§€**: `isProcessing` í”Œë˜ê·¸
- **ê²°ê³¼ ìºì‹±**: `lastDepthResult` ì¬ì‚¬ìš©
- **ì´ë¯¸ì§€ ë‹¤ìš´ìƒ˜í”Œë§**: 518x518ë¡œ ë¦¬ì‚¬ì´ì¦ˆ

#### ë©”ëª¨ë¦¬ ìµœì í™”
- CIContext ì‹±ê¸€í†¤ (ì•½ 100MB ì ˆì•½)
- MLMultiArray ì œê±° (ì•½ 4MB ì ˆì•½)
- autoreleasepoolë¡œ ì„ì‹œ ë©”ëª¨ë¦¬ ì¦‰ì‹œ í•´ì œ

#### ì½”ë“œ ìœ„ì¹˜
- `ios_v1.5/TryAngleApp/Services/OnDevice/DepthAnythingCoreML.swift`

---

### 3. AdaptivePoseComparator (í¬ì¦ˆ ë¹„êµ)

#### ë¹„êµ ì•Œê³ ë¦¬ì¦˜
í¬ì¦ˆ ë¹„êµëŠ” **3ê°€ì§€ ë©”íŠ¸ë¦­**ì„ ê²°í•©í•©ë‹ˆë‹¤:

##### A. ê°ë„ ì°¨ì´ (3ì  ê°ë„ ê³„ì‚°)
```swift
// íŒ” ê°ë„: ì–´ê¹¨-íŒ”ê¿ˆì¹˜-ì†ëª©
func calculateArmAngle(shoulder: CGPoint, elbow: CGPoint, wrist: CGPoint) -> Float {
    v1 = shoulder - elbow
    v2 = wrist - elbow
    angle = acos(dot(v1, v2) / (|v1| * |v2|)) * 180/Ï€
    return angle
}

refAngle = calculateArmAngle(ref.shoulder, ref.elbow, ref.wrist)
curAngle = calculateArmAngle(cur.shoulder, cur.elbow, cur.wrist)
```

##### B. ë²¡í„° ë°©í–¥ ìœ ì‚¬ë„ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
```swift
// ì™œ í•„ìš”í•œê°€? ê°ë„ë§Œìœ¼ë¡œëŠ” ë°©í–¥ êµ¬ë³„ ë¶ˆê°€!
// ì˜ˆ: íŒ”ì„ ì•ìœ¼ë¡œ ë»—ìŒ(180Â°) vs íŒ”ì„ ìœ„ë¡œ ë»—ìŒ(180Â°) â†’ ê°ë„ ê°™ì§€ë§Œ ë°©í–¥ ë‹¤ë¦„

refVector1 = normalize(shoulder â†’ elbow)
curVector1 = normalize(shoulder â†’ elbow)

cosineSimilarity = dot(refVector1, curVector1)  // -1 ~ 1
normalizedSimilarity = (cosineSimilarity + 1.0) / 2.0  // 0 ~ 1

directionPenalty = max(0, (1.0 - normalizedSimilarity) * 30.0)  // ìµœëŒ€ 30ë„ í˜ë„í‹°
```

##### C. ìƒëŒ€ ìœ„ì¹˜ ë¹„êµ (Y ì¢Œí‘œ)
```swift
// êµ¬ì²´ì ì¸ í”¼ë“œë°± ìƒì„±ìš©
refWristY = referenceKeypoints[9].point.y
curWristY = currentKeypoints[9].point.y
yDiff = curWristY - refWristY

if abs(yDiff) > 0.05:  // 5% ì´ìƒ ì°¨ì´
    if yDiff > 0:
        feedback = "ì™¼íŒ”ì„ ìœ„ë¡œ ì˜¬ë¦¬ì„¸ìš”"
    else:
        feedback = "ì™¼íŒ”ì„ ì•„ë˜ë¡œ ë‚´ë¦¬ì„¸ìš”"
```

#### ìµœì¢… ì ìˆ˜ ê³„ì‚°
```swift
totalDiff = abs(refAngle - curAngle) + directionPenalty

// ê° ë¶€ìœ„ë³„ ì •í™•ë„
accuracy = max(0.0, 1.0 - totalDiff / 180.0)  // 180ë„ ì°¨ì´ = 0ì 

// ì „ì²´ ì •í™•ë„ (í‰ê· )
overallAccuracy = sum(accuracies) / count(accuracies)
```

#### ì‹ ë¢°ë„ ì„ê³„ê°’ (ì ì‘í˜•)
| ë¶€ìœ„ | ì„ê³„ê°’ | ì´ìœ  |
|------|--------|------|
| Body (0-16) | 0.5 | ì—„ê²© (í•µì‹¬ ë¶€ìœ„) |
| Face (23-90) | 0.4 | ì¤‘ê°„ (ì–¼êµ´ ê°€ë ¤ì§€ê¸° ì‰¬ì›€) |
| Hand (91-132) | 0.3 | ê´€ëŒ€ (ì† ìì£¼ ê°€ë ¤ì§) |

#### ì½”ë“œ ìœ„ì¹˜
- `ios_v1.5/TryAngleApp/Services/Comparison/AdaptivePoseComparator.swift`

---

## ğŸšª Gate System (5ë‹¨ê³„ í‰ê°€)

### Gate 0: ë¹„ìœ¨ ì²´í¬ (ì ˆëŒ€ ìš°ì„ )

#### í‰ê°€ ê¸°ì¤€
```swift
// ë¹„ìœ¨ í—ˆìš© ì˜¤ì°¨: 2%
aspectRatioTolerance = 0.02

currentRatio = imageWidth / imageHeight
referenceRatio = refWidth / refHeight

if abs(currentRatio - referenceRatio) <= aspectRatioTolerance:
    score = 1.0
    feedback = "ë¹„ìœ¨ì´ ì™„ë²½í•©ë‹ˆë‹¤"
else:
    score = 0.0
    feedback = "ì¹´ë©”ë¼ ë¹„ìœ¨ì„ {reference}ë¡œ ë³€ê²½í•˜ì„¸ìš”"
```

#### ì§€ì› ë¹„ìœ¨
- 4:3 (1.33)
- 3:2 (1.50)
- 16:9 (1.78)
- 1:1 (1.00)

---

### Gate 1: í”„ë ˆì´ë° (ìƒ·íƒ€ì… + ì ìœ ìœ¨)

#### ìƒ·íƒ€ì… ìë™ íŒë³„ (í‚¤í¬ì¸íŠ¸ ê¸°ë°˜)
```swift
func detectShotType(keypoints: [Keypoint]) -> ShotType {
    // ê°€ì‹œì„± íŒë‹¨ (ì‹ ë¢°ë„ 0.5 ì´ìƒ)
    hasAnkles = keypoints[15].confidence > 0.5 || keypoints[16].confidence > 0.5
    hasFeet = keypoints[17...22].any { $0.confidence > 0.5 }
    hasKnees = keypoints[13].confidence > 0.5 || keypoints[14].confidence > 0.5
    hasHips = keypoints[11].confidence > 0.5 || keypoints[12].confidence > 0.5
    hasElbows = keypoints[7].confidence > 0.5 || keypoints[8].confidence > 0.5
    hasShoulders = keypoints[5].confidence > 0.5 || keypoints[6].confidence > 0.5

    // ìƒ·íƒ€ì… ê²°ì • (í•˜ì²´ë¶€í„° ì²´í¬)
    if hasAnkles || hasFeet:
        return .fullShot  // ì „ì‹ ìƒ·
    else if hasKnees:
        return kneesYRatio < 0.7 ? .mediumFullShot : .americanShot
    else if hasHips:
        return hasElbows ? .mediumShot : .mediumCloseUp
    else if hasElbows:
        return .mediumCloseUp
    else if hasShoulders:
        return faceKeypointCount > 50 ? .closeUp : .mediumCloseUp
    else:
        return .extremeCloseUp
}
```

#### ìƒ·íƒ€ì… ë¶„ë¥˜ ì²´ê³„
| ìƒ·íƒ€ì… | í•œêµ­ì–´ | ë³´ì´ëŠ” ë¶€ìœ„ | ìš©ë„ |
|--------|--------|-------------|------|
| Extreme Close-Up | ìµìŠ¤íŠ¸ë¦¼ í´ë¡œì¦ˆì—… | ì–¼êµ´ ì¼ë¶€ | ëˆˆ, ì… ê°•ì¡° |
| Close-Up | í´ë¡œì¦ˆì—… | ì–¼êµ´ ì „ì²´ | í‘œì • ì¤‘ì‹¬ |
| Medium Close-Up | ë°”ìŠ¤íŠ¸ìƒ· | ë¨¸ë¦¬~ê°€ìŠ´ | ì¸í„°ë·°, í”„ë¡œí•„ |
| Medium Shot | ì›¨ì´ìŠ¤íŠ¸ìƒ· | ë¨¸ë¦¬~í—ˆë¦¬ | ëŒ€í™”, ìƒë°˜ì‹  |
| American Shot | ë‹ˆìƒ· | ë¨¸ë¦¬~ë¬´ë¦ | ì•¡ì…˜, ì œìŠ¤ì²˜ |
| Medium Full Shot | 7ë¶€ìƒ· | ë¨¸ë¦¬~ì¢…ì•„ë¦¬ | íŒ¨ì…˜, ì „ì‹  |
| Full Shot | ì „ì‹ ìƒ· | ë¨¸ë¦¬~ë°œ | ì „ì‹  í¬ì¦ˆ |
| Long Shot | ë¡±ìƒ· | ì „ì‹  + ë°°ê²½ | í™˜ê²½ í¬í•¨ |

#### ì ìˆ˜ ê³„ì‚°
```swift
// ìƒ·íƒ€ì… ê±°ë¦¬ (0~7 ë‹¨ê³„ ì°¨ì´)
shotTypeDist = currentShotType.distance(to: referenceShotType)

if shotTypeDist == 0:
    score = 1.0  // ì™„ë²½ ì¼ì¹˜
else if shotTypeDist == 1:
    score = 0.85  // ì¸ì ‘ ìƒ·íƒ€ì… (ì˜ˆ: ì›¨ì´ìŠ¤íŠ¸ vs ë‹ˆìƒ·)
else:
    score = max(0.3, 1.0 - shotTypeDist * 0.4)  // ê±°ë¦¬ 1ë‹¹ 0.4 ê°ì 
```

#### í”„ë ˆì„ ì˜ë¦¼ ê°ì§€
```swift
// BBoxê°€ í”„ë ˆì„ ê²½ê³„ì— ë‹¿ì•˜ëŠ”ì§€ í™•ì¸ (2% ì´ë‚´)
edgeThreshold = 0.02

isAtTop = bbox.minY < edgeThreshold
isAtBottom = bbox.maxY > (1.0 - edgeThreshold)
isAtLeft = bbox.minX < edgeThreshold
isAtRight = bbox.maxX > (1.0 - edgeThreshold)

edgeCount = [isAtTop, isAtBottom, isAtLeft, isAtRight].count(where: { $0 })

if edgeCount >= 2:
    score -= 0.2

    // ì–´ë–¤ ë¶€ìœ„ê°€ ì˜ë ¸ëŠ”ì§€ íŒë‹¨
    croppedParts = detectCroppedBodyParts(bbox, keypoints)
    feedback = "ë„ˆë¬´ ê°€ê¹Œì›Œìš”! {croppedParts}ì´ ì˜ë ¸ì–´ìš”. ë’¤ë¡œ ë¬¼ëŸ¬ë‚˜ì„¸ìš”"
```

---

### Gate 2: ìœ„ì¹˜/êµ¬ë„ (ì—¬ë°± + ì •ë ¬)

#### í‰ê°€ ìš°ì„ ìˆœìœ„
1. **í‚¤í¬ì¸íŠ¸ ê¸°ë°˜ ì •ë ¬** (ìš°ì„ ) - Python v6 improved_margin_analyzer.py ì´ì‹
2. **BBox ì—¬ë°± ë¶„ì„** (Fallback)

#### A. í‚¤í¬ì¸íŠ¸ ê¸°ë°˜ ì •ë ¬ (BodyStructure)

##### 1) ë™ì  ì¤‘ì‹¬ì  ì¶”ì¶œ
```swift
struct BodyStructure {
    let centroid: CGPoint          // í•µì‹¬ í‚¤í¬ì¸íŠ¸ë“¤ì˜ í‰ê· 
    let topAnchorY: CGFloat        // ë¨¸ë¦¬ ìƒë‹¨
    let spanY: CGFloat             // ë¨¸ë¦¬~ìµœí•˜ë‹¨ ë²”ìœ„
    let lowestTier: Int            // 0:ì–´ê¹¨, 1:ì—‰ë©ì´, 2:ë¬´ë¦, 3:ë°œëª©
}

// ì¤‘ì‹¬ì  ê³„ì‚° (ì½”, ëˆˆ, ì–´ê¹¨, ì—‰ë©ì´ í‰ê· )
coreKeypoints = [nose, leftEye, rightEye, leftShoulder, rightShoulder, leftHip, rightHip]
centroid = mean(coreKeypoints.filter { $0.confidence > 0.5 })

// ë¨¸ë¦¬ ìƒë‹¨ (ì½”, ëˆˆ, ê·€ ì¤‘ ê°€ì¥ ë†’ì€ ì )
topAnchorY = min([nose.y, leftEye.y, rightEye.y, leftEar.y, rightEar.y])

// ì‹ ì²´ ë²”ìœ„ (ë¨¸ë¦¬~ìµœí•˜ë‹¨)
lowestVisibleY = max([ankle.y, knee.y, hip.y, shoulder.y])  // ê°€ì¥ ë‚®ì€ ê°€ì‹œ ë¶€ìœ„
spanY = lowestVisibleY - topAnchorY
```

##### 2) ì¢Œìš° ì •ë ¬ (Centroid X)
```swift
diffX = currStruct.centroid.x - refStruct.centroid.x

if abs(diffX) > 0.05:  // 5% ì´ìƒ ì°¨ì´
    percent = abs(diffX) * 100
    steps = toSteps(percent)  // "ë°˜ ê±¸ìŒ", "í•œ ê±¸ìŒ", etc.

    if diffX > 0:  // í˜„ì¬ê°€ ì˜¤ë¥¸ìª½ì— ì¹˜ìš°ì¹¨
        feedback = "ì™¼ìª½ìœ¼ë¡œ {steps} ì´ë™ ({percent}%)"
    else:
        feedback = "ì˜¤ë¥¸ìª½ìœ¼ë¡œ {steps} ì´ë™ ({percent}%)"
```

##### 3) ìƒí•˜ ì •ë ¬ (Top Anchor Y)
```swift
diffY = currStruct.topAnchorY - refStruct.topAnchorY

if abs(diffY) > 0.05:
    percent = abs(diffY) * 100
    angle = toTiltAngle(percent)  // 2Â°, 5Â°, 8Â°, 10Â°, 15Â°

    if diffY > 0:  // í˜„ì¬ê°€ ì•„ë˜ì— ì¹˜ìš°ì¹¨ (ìƒë‹¨ ì—¬ë°± ë§ìŒ)
        feedback = "ì¹´ë©”ë¼ë¥¼ {angle}Â° ì•„ë˜ë¡œ í‹¸íŠ¸"
    else:
        feedback = "ì¹´ë©”ë¼ë¥¼ {angle}Â° ìœ„ë¡œ í‹¸íŠ¸"
```

##### 4) ê±°ë¦¬ ì¼ì¹˜ (SpanY ë¹„ìœ¨)
```swift
scaleRatio = currStruct.spanY / refStruct.spanY
scaleDiff = abs(1.0 - scaleRatio)

if scaleDiff > 0.08:  // 8% ì´ìƒ ì°¨ì´
    percent = scaleDiff * 50
    steps = toSteps(percent)

    if scaleRatio > 1.0:  // í˜„ì¬ê°€ ë” í¼ (ë„ˆë¬´ ê°€ê¹Œì›€)
        feedback = "ë’¤ë¡œ {steps} ê°€ì„¸ìš”"
    else:  // í˜„ì¬ê°€ ë” ì‘ìŒ (ë„ˆë¬´ ë©€ìŒ)
        feedback = "ì•ìœ¼ë¡œ {steps} ë‹¤ê°€ì˜¤ì„¸ìš”"
```

#### B. BBox ì—¬ë°± ë¶„ì„ (Fallback)

##### ì—¬ë°± ê³„ì‚°
```swift
// í”½ì…€ ì—¬ë°±
leftMargin = bbox.minX
rightMargin = imageWidth - bbox.maxX
topMargin = bbox.minY
bottomMargin = imageHeight - bbox.maxY

// ë¹„ìœ¨ ì—¬ë°±
leftRatio = leftMargin / imageWidth
rightRatio = rightMargin / imageWidth
topRatio = topMargin / imageHeight
bottomRatio = bottomMargin / imageHeight

// ê· í˜• ì ìˆ˜
horizontalBalance = 1.0 - abs(leftRatio - rightRatio)
verticalBalance = 1.0 - abs(topRatio - bottomRatio * 0.5)  // í•˜ë‹¨ 2:1 ë¹„ìœ¨ ì„ í˜¸
balanceScore = (horizontalBalance + verticalBalance) / 2.0
```

##### ì¢Œìš° ê· í˜• ë¶„ì„
```swift
currBalance = curMargins.leftRatio - curMargins.rightRatio
refBalance = refMargins.leftRatio - refMargins.rightRatio
centerShift = currBalance - refBalance

if abs(centerShift) < 0.05:
    score = 0.95  // ì™„ë²½
else if abs(centerShift) < 0.10:
    score = 0.85  // ì¢‹ìŒ
else if abs(centerShift) < 0.15:
    score = 0.70  // ì¡°ì • í•„ìš”
else:
    score = max(0.50, 0.85 - abs(centerShift))

if abs(centerShift) > 0.10:
    percent = Int(abs(centerShift) * 100)
    steps = toSteps(percent)
    feedback = "ì˜¤ë¥¸ìª½ìœ¼ë¡œ {steps} ì´ë™ ({percent}%)"
```

##### ìƒí•˜ ê· í˜• + í‹¸íŠ¸ ë¶„ì„
```swift
// ì¸ë¬¼ì˜ ìˆ˜ì§ ìœ„ì¹˜ (0=ìƒë‹¨, 0.5=ì¤‘ì•™, 1=í•˜ë‹¨)
personVerticalPosition = (bbox.minY + bbox.maxY) / 2.0

currPosition = curMargins.personVerticalPosition
refPosition = refMargins.personVerticalPosition
positionDiff = currPosition - refPosition

if abs(positionDiff) > 0.10:
    tiltAngle = toTiltAngle(percent: abs(positionDiff) * 100)

    if positionDiff > 0:  // í˜„ì¬ê°€ ë” ì•„ë˜ (ìƒë‹¨ ì—¬ë°± ë§ìŒ)
        if curMargins.isHighAngle:  // í•˜ì´ì•µê¸€ ê°ì§€
            feedback = "ì¹´ë©”ë¼ë¥¼ ë‚®ì¶”ê³  {tiltAngle}Â° í‰í–‰í•˜ê²Œ"
        else:
            feedback = "ì¹´ë©”ë¼ë¥¼ {tiltAngle}Â° ì•„ë˜ë¡œ í‹¸íŠ¸"
```

##### í•˜ë‹¨ íŠ¹ë³„ ë¶„ì„
```swift
currBottom = curMargins.bottomRatio
refBottom = refMargins.bottomRatio
diff = abs(currBottom - refBottom)

if currBottom < -0.1:  // í•˜ë‹¨ 10% ì´ìƒ ì˜ë¦¼
    feedback = "í•˜ë‹¨ì´ ì˜ë ¸ì–´ìš”. ì¹´ë©”ë¼ë¥¼ ìœ„ë¡œ ë“¤ê±°ë‚˜ ë’¤ë¡œ ë¬¼ëŸ¬ë‚˜ì„¸ìš”"
else if currBottom > refBottom + 0.15:  // í•˜ë‹¨ ì—¬ë°± ë„ˆë¬´ ë§ìŒ
    feedback = "í•˜ë‹¨ ì—¬ë°±ì´ ë„ˆë¬´ ë§ì•„ìš”. ì¹´ë©”ë¼ë¥¼ ì•„ë˜ë¡œ ë‚´ë¦¬ì„¸ìš”"
```

#### í¼ì„¼íŠ¸ â†’ ê±¸ìŒìˆ˜/ê°ë„ ë³€í™˜
```swift
func toSteps(percent: CGFloat) -> String {
    if percent < 5: return "ì•„ì£¼ ì¡°ê¸ˆ"
    if percent < 10: return "ë°˜ ê±¸ìŒ"
    if percent < 20: return "í•œ ê±¸ìŒ"
    if percent < 30: return "ë‘ ê±¸ìŒ"
    if percent < 40: return "ì„¸ ê±¸ìŒ"
    return "ë„¤ ê±¸ìŒ ì´ìƒ"
}

func toTiltAngle(percent: CGFloat) -> Int {
    if percent < 5: return 2
    if percent < 10: return 5
    if percent < 15: return 8
    if percent < 20: return 10
    return min(15, Int(percent * 0.5))
}
```

---

### Gate 3: ì••ì¶•ê° (35mm í™˜ì‚° ì´ˆì ê±°ë¦¬)

#### í‰ê°€ ë°©ë²• ìš°ì„ ìˆœìœ„
1. **EXIF ê¸°ë°˜** (ìš°ì„ ) - ì •í™•ë„ ë†’ìŒ
2. **Depth ê¸°ë°˜** (Fallback) - EXIF ì—†ì„ ë•Œ

#### A. EXIF ê¸°ë°˜ ì´ˆì ê±°ë¦¬ ì¶”ì¶œ
```swift
// ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°ì—ì„œ ì¶”ì¶œ
if let exifDict = imageData.exifDictionary {
    focalLengthMM = exifDict["FocalLength"]  // ì˜ˆ: 4.25mm (iPhone ì‹¤ì œ ì´ˆì ê±°ë¦¬)
    focalLength35mm = exifDict["FocalLengthIn35mmFilm"]  // ì˜ˆ: 26mm (í™˜ì‚° ì´ˆì ê±°ë¦¬)

    if focalLength35mm == nil {
        // í¬ë¡­ íŒ©í„°ë¡œ ê³„ì‚°
        cropFactor = estimateCropFactor(sensorSize)
        focalLength35mm = focalLengthMM * cropFactor
    }
}
```

#### B. Depth ê¸°ë°˜ ì¶”ì • (EXIF ì—†ì„ ë•Œ)
```swift
compressionIndex = depthAnything.estimate(image)  // 0~1

// ì••ì¶•ê° â†’ ì´ˆì ê±°ë¦¬ ë§¤í•‘
if compressionIndex < 0.3:
    estimatedFocal = 24mm  // ê´‘ê°
else if compressionIndex < 0.5:
    estimatedFocal = 35mm  // í‘œì¤€
else if compressionIndex < 0.7:
    estimatedFocal = 50mm  // ì¤€ë§ì›
else:
    estimatedFocal = 85mm  // ë§ì›
```

#### í‰ê°€ ë¡œì§
```swift
currentMM = currentFocalLength.focalLength35mm
refMM = referenceFocalLength.focalLength35mm
diff = abs(currentMM - refMM)

// ì ìˆ˜ ê³„ì‚° (5mm ì°¨ì´ë§ˆë‹¤ 10% ê°ì )
score = max(0, 1.0 - diff / 50.0)

// 10mm ì´ìƒ ì°¨ì´ë‚˜ë©´ í”¼ë“œë°±
if diff > 10:
    targetZoom = refMM / iPhoneBaseFocalLength  // ì˜ˆ: 50mm / 26mm = 1.9x

    if currentMM < refMM:  // í˜„ì¬ê°€ ê´‘ê°
        feedback = "ë’¤ë¡œ ë¬¼ëŸ¬ë‚˜ì„œ {targetZoom}xë¡œ ì¤Œì¸ (ë°°ê²½ ì••ì¶•)"
    else:  // í˜„ì¬ê°€ ë§ì›
        feedback = "ì•ìœ¼ë¡œ ë‹¤ê°€ê°€ì„œ {targetZoom}xë¡œ ì¤Œì•„ì›ƒ (ì›ê·¼ê° ê°•ì¡°)"
```

#### ê±°ë¦¬ ì¼ì¹˜ ì²´í¬ (ë Œì¦ˆëŠ” ë§ì§€ë§Œ ê±°ë¦¬ê°€ ë‹¤ë¥¸ ê²½ìš°)
```swift
// ë Œì¦ˆê°€ ë¹„ìŠ·í•´ë„ (diff < 10mm) ê±°ë¦¬ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ!
if diff < 10:
    scaleRatio = currStruct.spanY / refStruct.spanY
    scaleDiff = abs(1.0 - scaleRatio)

    if scaleDiff > 0.15:  // 15% ì´ìƒ ì°¨ì´
        score = max(0.2, score - scaleDiff)
        steps = toSteps(percent: scaleDiff * 50)

        if scaleRatio > 1.0:  // ë„ˆë¬´ ê°€ê¹Œì›€
            feedback = "ë Œì¦ˆëŠ” ë¹„ìŠ·í•˜ì§€ë§Œ ë„ˆë¬´ ê°€ê¹ìŠµë‹ˆë‹¤. ë’¤ë¡œ {steps} ë¬¼ëŸ¬ë‚˜ì„¸ìš”"
        else:  // ë„ˆë¬´ ë©€ìŒ
            feedback = "ë Œì¦ˆëŠ” ë¹„ìŠ·í•˜ì§€ë§Œ ë„ˆë¬´ ë©‰ë‹ˆë‹¤. ì•ìœ¼ë¡œ {steps} ë‹¤ê°€ê°€ì„¸ìš”"
```

---

### Gate 4: í¬ì¦ˆ

#### í‰ê°€ í•­ëª©
- ì™¼íŒ” ê°ë„ (ì–´ê¹¨-íŒ”ê¿ˆì¹˜-ì†ëª©)
- ì˜¤ë¥¸íŒ” ê°ë„ (ì–´ê¹¨-íŒ”ê¿ˆì¹˜-ì†ëª©)
- ì™¼ë‹¤ë¦¬ ê°ë„ (ì—‰ë©ì´-ë¬´ë¦-ë°œëª©)
- ì˜¤ë¥¸ë‹¤ë¦¬ ê°ë„ (ì—‰ë©ì´-ë¬´ë¦-ë°œëª©)
- ì–´ê¹¨ ê¸°ìš¸ê¸° (ëª¸í†µ ê¸°ìš¸ê¸°)
- ì™¼ì† ëª¨ì–‘ (ì†ê°€ë½ ë°©í–¥)
- ì˜¤ë¥¸ì† ëª¨ì–‘ (ì†ê°€ë½ ë°©í–¥)
- ë°œ ìœ„ì¹˜
- ì–¼êµ´ ë°©í–¥

#### ê°ë„ ì°¨ì´ ê³„ì‚° (ì˜ˆ: ì™¼íŒ”)
```swift
// 1. ê°ë„ ê³„ì‚°
refAngle = calculateArmAngle(ref.shoulder, ref.elbow, ref.wrist)
curAngle = calculateArmAngle(cur.shoulder, cur.elbow, cur.wrist)

// 2. ë²¡í„° ë°©í–¥ ìœ ì‚¬ë„
refVector1 = normalize(ref.shoulder â†’ ref.elbow)
curVector1 = normalize(cur.shoulder â†’ cur.elbow)
directionSimilarity = cosineSimilarity(refVector1, curVector1)

// 3. ë°©í–¥ í˜ë„í‹°
directionPenalty = max(0, (1.0 - directionSimilarity) * 30.0)

// 4. ìµœì¢… ì°¨ì´
totalDiff = abs(refAngle - curAngle) + directionPenalty
angleDifferences["left_arm"] = totalDiff

// 5. êµ¬ì²´ì  ë°©í–¥
yDiff = cur.wrist.y - ref.wrist.y
if yDiff > 0.05:
    angleDirections["left_arm"] = "ì™¼íŒ”ì„ ìœ„ë¡œ ì˜¬ë¦¬ì„¸ìš”"
else if yDiff < -0.05:
    angleDirections["left_arm"] = "ì™¼íŒ”ì„ ì•„ë˜ë¡œ ë‚´ë¦¬ì„¸ìš”"
```

#### í¬ì¦ˆ ì •í™•ë„ â†’ ì ìˆ˜ ë³€í™˜
```swift
angleTolerance = 15.0  // 15ë„ ì´ë‚´ í—ˆìš©

for (part, diff) in angleDifferences:
    accuracy = max(0.0, 1.0 - diff / 180.0)  // 180ë„ ì°¨ì´ = 0ì 
    totalAccuracy += accuracy

overallAccuracy = totalAccuracy / angleDifferences.count

// ì ìˆ˜ ê³„ì‚°
if overallAccuracy >= 0.85:
    score = 1.0  // ì™„ë²½
else if overallAccuracy >= 0.70:
    score = 0.85  // ì¢‹ìŒ
else:
    score = overallAccuracy
```

#### í”¼ë“œë°± í†µí•© (ì¢Œìš° ë¶„ë¦¬ ì•ˆí•¨)
```swift
// ê¸°ì¡´: "ì™¼íŒ” ì¡°ì •", "ì˜¤ë¥¸íŒ” ì¡°ì •" (2ê°œ í”¼ë“œë°±)
// ê°œì„ : "ì–‘íŒ” ìœ„ì¹˜ ì¡°ì •" (1ê°œ í†µí•© í”¼ë“œë°±)

leftArmDiff = angleDifferences["left_arm"]
rightArmDiff = angleDifferences["right_arm"]

if abs(leftArmDiff) > 15 && abs(rightArmDiff) > 15:
    level = differenceLevel(max(leftArmDiff, rightArmDiff))
    feedback = "ì–‘íŒ” ìœ„ì¹˜ë¥¼ {level} ì¡°ì •í•´ì£¼ì„¸ìš”"
else if abs(leftArmDiff) > 15:
    feedback = "ì™¼íŒ”ì„ {level} ì¡°ì •í•´ì£¼ì„¸ìš”"
else if abs(rightArmDiff) > 15:
    feedback = "ì˜¤ë¥¸íŒ”ì„ {level} ì¡°ì •í•´ì£¼ì„¸ìš”"
```

---

## ğŸ”„ UnifiedFeedbackGenerator (í†µí•© í”¼ë“œë°±)

### í•µì‹¬ ì•„ì´ë””ì–´
**"í•˜ë‚˜ì˜ ë™ì‘ìœ¼ë¡œ ì—¬ëŸ¬ Gateë¥¼ ë™ì‹œì— í•´ê²°"**

ê¸°ì¡´ ë¬¸ì œ:
- Gate 1: "ì•ìœ¼ë¡œ ê°€ì„¸ìš”" (ìƒ·íƒ€ì…)
- Gate 2: "ì™¼ìª½ìœ¼ë¡œ ì´ë™" (ì—¬ë°±)
- Gate 3: "ì¤Œì¸í•˜ì„¸ìš”" (ì••ì¶•ê°)
- ì‚¬ìš©ì: "ì…‹ ë‹¤ í•´ì•¼ í•˜ë‚˜? ìˆœì„œëŠ”?" (í˜¼ë€)

ê°œì„ :
- "ì¤Œì¸ í›„ ë‘ ê±¸ìŒ ë’¤ë¡œ" (ì••ì¶•ê° + ìƒ·íƒ€ì… + ì—¬ë°± ë™ì‹œ í•´ê²°)

### ì••ì¶•ê° ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë¶„ê¸°

```swift
if compressionOK:
    // Case A: ì••ì¶•ê° OK â†’ ê±°ë¦¬/ìœ„ì¹˜ë§Œ ì¡°ì • (ì¤Œ ì–¸ê¸‰ ì•ˆí•¨!)
    return generateDistanceOnlyFeedback()
else:
    // Case B: ì••ì¶•ê° NG â†’ ì¤Œ + ê±°ë¦¬ ë³µí•© ì¡°ì •
    return generateZoomAndDistanceFeedback()
```

#### Case A: ì••ì¶•ê° OK - ê±°ë¦¬ë§Œ ì¡°ì •
```swift
// ì¤Œ ì œì™¸í•˜ê³  ê±°ë¦¬/ìœ„ì¹˜ ë™ì‘ë§Œ ê³„ì‚°
possibleActions = [moveForward, moveBackward, moveLeft, moveRight, tiltUp, tiltDown]

// ìŠ¤ë§ˆíŠ¸ ìƒê´€ê´€ê³„ ë¶„ì„
if shotTypeTooWide && marginTopHigh:
    recommend = tiltDown
    expectedResults = ["ìƒ·íƒ€ì…ì´ ì¢ì•„ì§‘ë‹ˆë‹¤", "ìƒë‹¨ ì—¬ë°±ì´ ì¤„ì–´ë“­ë‹ˆë‹¤"]
    feedback = "ì¹´ë©”ë¼ë¥¼ 5Â° ì•„ë˜ë¡œ í‹¸íŠ¸"

if shotTypeTooNarrow && marginBottomLow:
    recommend = moveBackward
    expectedResults = ["ìƒ·íƒ€ì…ì´ ë„“ì–´ì§‘ë‹ˆë‹¤", "í•˜ë‹¨ ì˜ë¦¼ì´ í•´ê²°ë©ë‹ˆë‹¤"]
    feedback = "ë‘ ê±¸ìŒ ë’¤ë¡œ ë¬¼ëŸ¬ë‚˜ì„¸ìš”"
```

#### Case B: ì••ì¶•ê° NG - ì¤Œ + ê±°ë¦¬ ë³µí•©
```swift
zoomRatio = targetZoom / currentZoom  // ì˜ˆ: 2.0x / 1.0x = 2.0
needZoomIn = zoomRatio > 1.1  // 10% ì´ìƒ ì°¨ì´

// ì¤Œ í›„ ì˜ˆìƒ ì¸ë¬¼ í¬ê¸°
curSize = 0.3  // í˜„ì¬ ì ìœ ìœ¨ 30%
tgtSize = 0.4  // ëª©í‘œ ì ìœ ìœ¨ 40%
predictedSize = curSize * zoomRatio  // 0.3 * 2.0 = 0.6 (60%)

if needZoomIn:
    if predictedSize > tgtSize * 1.15:  // ì¤Œì¸ í›„ ë„ˆë¬´ ì»¤ì§ (60% > 46%)
        action = zoomInThenMoveBack
        magnitude = calculateDistance(0.6 / 0.4)  // 1.5 â†’ "ë‘ ê±¸ìŒ"
        feedback = "2.0xë¡œ ì¤Œì¸ í›„, ë‘ ê±¸ìŒ ë’¤ë¡œ (ë°°ê²½ ì••ì¶•)"
        expectedResults = ["ì••ì¶•ê°ì´ ë§ì¶°ì§‘ë‹ˆë‹¤", "ì¸ë¬¼ í¬ê¸°ê°€ ì¡°ì •ë©ë‹ˆë‹¤"]
    else if predictedSize < tgtSize * 0.85:  // ì¤Œì¸ í›„ ë„ˆë¬´ ì‘ì•„ì§
        action = zoomInThenMoveForward
        feedback = "2.0xë¡œ ì¤Œì¸ í›„, í•œ ê±¸ìŒ ì•ìœ¼ë¡œ"
    else:  // ì¤Œì¸ë§Œ í•˜ë©´ í¬ê¸°ë„ OK
        action = zoomIn
        feedback = "2.0xë¡œ ì¤Œì¸"
        expectedResults = ["ì••ì¶•ê°ì´ ë§ì¶°ì§‘ë‹ˆë‹¤", "ì¸ë¬¼ í¬ê¸°ë„ ë§ì•„ì§‘ë‹ˆë‹¤"]
```

### ë™ì‘ íƒ€ì…ë³„ ì˜í–¥ Gate
| ë™ì‘ | ì˜í–¥ Gate | ì„¤ëª… |
|------|-----------|------|
| moveForward | 1, 2 | ìƒ·íƒ€ì… + ì—¬ë°± |
| moveBackward | 1, 2 | ìƒ·íƒ€ì… + ì—¬ë°± |
| moveLeft/Right | 2 | ì—¬ë°±ë§Œ |
| tiltUp/Down | 2 | ì—¬ë°±ë§Œ |
| zoomIn/Out | 1, 3 | ìƒ·íƒ€ì… + ì••ì¶•ê° |
| zoomInThenMoveBack | 1, 2, 3 | ëª¨ë“  Gate |

### í”¼ë“œë°± ì•ˆì •í™” (ê¹œë¹¡ì„ ë°©ì§€)

#### ë¬¸ì œ ìƒí™©
```
0.00ì´ˆ: "ì•ìœ¼ë¡œ ê°€ì„¸ìš”"
0.05ì´ˆ: "í‹¸íŠ¸ ë‹¤ìš´"       â† ê¹œë¹¡ì„!
0.10ì´ˆ: "ì•ìœ¼ë¡œ ê°€ì„¸ìš”"   â† í˜¼ë€!
0.15ì´ˆ: "í‹¸íŠ¸ ë‹¤ìš´"
```

#### í•´ê²°ì±…: íˆìŠ¤í…Œë¦¬ì‹œìŠ¤
```swift
// ìƒíƒœ ì¶”ì 
private var lastFeedback: UnifiedFeedback?
private var sameActionCount: Int = 0
private var consecutiveSameAction: Int = 0

// ì•ˆì •í™” ë¡œì§
func stabilizeFeedback(_ newFeedback: UnifiedFeedback) -> UnifiedFeedback? {
    if let last = lastFeedback {
        if last.primaryAction == newFeedback.primaryAction:
            // ë™ì¼í•œ í”¼ë“œë°±
            sameActionCount += 1
            consecutiveSameAction += 1

            // magnitudeë§Œ ë‹¤ë¥´ë©´ ê°±ì‹ 
            if last.magnitude != newFeedback.magnitude:
                return newFeedback

            return last  // ë™ì¼ í”¼ë“œë°± ìœ ì§€
        } else {
            // ë‹¤ë¥¸ í”¼ë“œë°± ê°ì§€ â†’ ì¦‰ì‹œ ë°˜ì˜
            consecutiveSameAction = 0
            sameActionCount = 1
        }
    }

    lastFeedback = newFeedback
    return newFeedback
}
```

#### ê²°ê³¼
```
0.00ì´ˆ: "ì•ìœ¼ë¡œ ê°€ì„¸ìš”"
0.05ì´ˆ: "ì•ìœ¼ë¡œ ê°€ì„¸ìš”"   â† ì•ˆì •ì !
0.10ì´ˆ: "ì•ìœ¼ë¡œ ê°€ì„¸ìš”"
0.15ì´ˆ: "í•œ ê±¸ìŒ ì•ìœ¼ë¡œ"  â† magnitudeë§Œ ê°±ì‹ 
```

---

## âš¡ ì‹¤ì‹œê°„ ë¶„ì„ íŒŒì´í”„ë¼ì¸

### ì´ˆê¸°í™” (ì•± ì‹œì‘)
```swift
1. RTMPoseRunner ë°±ê·¸ë¼ìš´ë“œ ë¡œë”© (ì•½ 17ì´ˆ)
   - ORTEnv ìƒì„±
   - YOLOX ëª¨ë¸ ë¡œë“œ (CoreML GPU ê°€ì†)
   - RTMPose ëª¨ë¸ ë¡œë“œ (CoreML GPU ê°€ì†)

2. DepthAnythingCoreML ëª¨ë¸ ë¡œë”©
   - DepthAnythingV2SmallF16.mlmodelc
   - VNCoreMLModel ë˜í•‘

3. PersonDetector ì—°ê²°
   - RTMPoseRunner ì°¸ì¡° ì„¤ì •
```

### ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„ (1íšŒ)
```swift
func analyzeReference(image: UIImage) {
    // 1. ë¹„ìœ¨ ê°ì§€
    aspectRatio = CameraAspectRatio.detect(imageSize)

    // 2. RTMPose í¬ì¦ˆ ì¶”ì • (133ê°œ í‚¤í¬ì¸íŠ¸)
    poseResult = rtmPoseRunner.detectPose(image)

    // 3. ìƒ·íƒ€ì… ìë™ íŒë³„
    shotType = ShotType.fromKeypoints(poseResult.keypoints)

    // 4. ë¹„ë™ê¸°: Depth Anything ê¹Šì´ ì¶”ì •
    DispatchQueue.global().async {
        depthResult = depthAnything.estimateDepth(image)
        compressionIndex = depthResult.compressionIndex

        // 5. ë¹„ë™ê¸°: YOLOX ì •ë°€ BBox
        personDetector.detectPerson(ciImage) { preciseBBox in
            // 6. ì—¬ë°± ë¶„ì„
            marginResult = marginAnalyzer.analyze(bbox: preciseBBox)

            // 7. ìºì‹œ ì €ì¥
            cachedReference = CacheManager.shared.cacheReference(
                image, bbox, margins, compressionIndex
            )
        }
    }

    // 8. 35mm í™˜ì‚° ì´ˆì ê±°ë¦¬ ì¶”ì •
    referenceFocalLength = focalLengthEstimator.estimateReferenceFocalLength(
        imageData: referenceImageData,  // EXIF ìš°ì„ 
        depthMap: referenceDepthMap     // Fallback
    )
}
```

### ì‹¤ì‹œê°„ í”„ë ˆì„ ë¶„ì„ (50msë§ˆë‹¤)
```swift
func process(buffer: CMSampleBuffer) {
    // 1. Throttling (50ms ê°„ê²©)
    guard Date().since(lastAnalysisTime) >= 0.05 else { return }
    lastAnalysisTime = Date()

    // 2. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì´ë¯¸ì§€ ë³€í™˜
    analysisQueue.async {
        cgImage = convertCMSampleBufferToCGImage(buffer)

        // 3. RTMPose í¬ì¦ˆ ì¶”ì • (Level 1: í•­ìƒ ì‹¤í–‰)
        poseResult = rtmPoseRunner.detectPose(image)

        // ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ Gate í‰ê°€
        DispatchQueue.main.async {
            processAnalysisResult(poseResult)
        }
    }
}

func processAnalysisResult(poseResult: RTMPoseResult) {
    frameCount += 1

    // Level 2: Depth Anything (ë™ì  í”„ë ˆì„ ìŠ¤í‚µ, ë³´í†µ 10í”„ë ˆì„ë§ˆë‹¤)
    if frameSkipper.shouldExecute(level: 2, frameCount: frameCount) {
        DispatchQueue.global().async {
            depthResult = depthAnything.estimateDepth(image)
            lastDepthResult = depthResult  // ìºì‹œ ì—…ë°ì´íŠ¸
        }
    }

    // Level 3: YOLOX ì •ë°€ BBox (ë™ì  í”„ë ˆì„ ìŠ¤í‚µ, ë³´í†µ 30í”„ë ˆì„ë§ˆë‹¤)
    if frameSkipper.shouldExecute(level: 3, frameCount: frameCount) {
        DispatchQueue.global().async {
            preciseBBox = personDetector.detectPerson(ciImage)
            lastPreciseBBox = preciseBBox  // ìºì‹œ ì—…ë°ì´íŠ¸
        }
    }

    // ë°±ê·¸ë¼ìš´ë“œì—ì„œ Gate í‰ê°€ (ë¬´ê±°ìš´ ì—°ì‚°)
    DispatchQueue.global().async {
        // Gate System í‰ê°€
        evaluation = gateSystem.evaluate(
            currentBBox: poseResult.boundingBox,
            referenceBBox: cachedReference.bbox,
            currentKeypoints: poseResult.keypoints,
            referenceKeypoints: cachedReference.keypoints,
            currentCompressionIndex: lastDepthResult?.compressionIndex,
            referenceCompressionIndex: cachedReference.compressionIndex,
            currentFocalLength: estimateCurrentFocalLength(),
            referenceFocalLength: cachedReference.focalLength
        )

        // UnifiedFeedback ìƒì„±
        unifiedFeedback = UnifiedFeedbackGenerator.shared.generateUnifiedFeedback(
            from: evaluation,
            currentZoom: currentZoomFactor,
            targetZoom: cachedReference.focalLength.focalLength35mm / 26.0
        )

        // íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ ì ìš© (ê¹œë¹¡ì„ ë°©ì§€)
        stableFeedback = applyHysteresis(evaluation.primaryFeedback)

        // ë©”ì¸ ìŠ¤ë ˆë“œë¡œ UI ì—…ë°ì´íŠ¸
        DispatchQueue.main.async {
            state.gateEvaluation = evaluation
            state.unifiedFeedback = unifiedFeedback
            state.instantFeedback = stableFeedback

            // Temporal Lock ìƒíƒœ ë¨¸ì‹ 
            updateStabilityProgress()
        }
    }
}
```

### í”„ë ˆì„ ìŠ¤í‚µ ì „ëµ (AdaptiveFrameSkipper)
```swift
Level 1 (RTMPose): í•­ìƒ ì‹¤í–‰ (ë§¤ í”„ë ˆì„)
Level 2 (Depth):   ë™ì  ê°„ê²© (ë³´í†µ 10í”„ë ˆì„ë§ˆë‹¤, ~200ms)
Level 3 (YOLOX):   ë™ì  ê°„ê²© (ë³´í†µ 30í”„ë ˆì„ë§ˆë‹¤, ~600ms)

// ë™ì  ì¡°ì •
if CPUUsage > 80%:
    level2Interval *= 1.5  // 15í”„ë ˆì„ë§ˆë‹¤
    level3Interval *= 1.5  // 45í”„ë ˆì„ë§ˆë‹¤
else if CPUUsage < 50%:
    level2Interval /= 1.2  // 8í”„ë ˆì„ë§ˆë‹¤
    level3Interval /= 1.2  // 25í”„ë ˆì„ë§ˆë‹¤
```

---

## ğŸŒ¡ï¸ ì„±ëŠ¥ ìµœì í™”

### 1. ì—´í™”ìƒ ê´€ë¦¬ (ThermalStateManager)
```swift
switch ProcessInfo.processInfo.thermalState {
case .nominal:        // ì •ìƒ
    analysisInterval = 0.05  // 50ms
case .fair:           // ì•½ê°„ ëœ¨ê±°ì›€
    analysisInterval = 0.10  // 100ms
case .serious:        // ëœ¨ê±°ì›€
    analysisInterval = 0.20  // 200ms
case .critical:       // ë§¤ìš° ëœ¨ê±°ì›€
    analysisInterval = 0.50  // 500ms
}
```

### 2. ë©”ëª¨ë¦¬ ìµœì í™”

#### Depth Anything
```swift
// ì‹±ê¸€í†¤ íŒ¨í„´
static let shared = DepthAnythingCoreML(modelType: .small)

// CIContext ì‹±ê¸€í†¤ (ì•½ 100MB ì ˆì•½)
private static let sharedContext = CIContext(options: [
    .useSoftwareRenderer: false,
    .cacheIntermediates: false
])

// ë™ì‹œ ì‹¤í–‰ ë°©ì§€
private var isProcessing = false
guard !isProcessing else { return }
isProcessing = true
defer { isProcessing = false }

// MLMultiArray ì œê±° (ì•½ 4MB ì ˆì•½)
struct V15DepthResult {
    let depthImage: UIImage?       // nilë¡œ ì„¤ì • ê°€ëŠ¥
    let compressionIndex: Float    // í•„ìˆ˜ë§Œ
    let cameraType: V15CameraType
}
```

#### autoreleasepool í™œìš©
```swift
DispatchQueue.global().async {
    autoreleasepool {
        // ì„ì‹œ ë©”ëª¨ë¦¬ ì¦‰ì‹œ í•´ì œ
        let result = heavyComputation()
        // autoreleasepool ì¢…ë£Œ ì‹œ ìë™ ë©”ëª¨ë¦¬ í•´ì œ
    }
}
```

### 3. íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ (ê¹œë¹¡ì„ ë°©ì§€)

#### Gateë³„ íˆìŠ¤í…Œë¦¬ì‹œìŠ¤
```swift
// ê° Gate í”¼ë“œë°±ë§ˆë‹¤ ì¹´ìš´í„° ìœ ì§€
private var feedbackHistory: [String: Int] = [:]
private let historyThreshold = 3  // 3ë²ˆ ì—°ì† ê°ì§€

func applyHysteresis(feedback: String, category: String) -> String? {
    feedbackHistory[category] = (feedbackHistory[category] ?? 0) + 1

    if feedbackHistory[category]! >= historyThreshold {
        return feedback  // 3ë²ˆ ì—°ì† â†’ í‘œì‹œ
    }

    return nil  // ì•„ì§ í‘œì‹œ ì•ˆí•¨
}
```

#### UnifiedFeedback ì•ˆì •í™”
```swift
// ë™ì¼í•œ primaryActionì´ ì—°ì†ìœ¼ë¡œ ë‚˜ì™€ì•¼ ìœ ì§€
if last.primaryAction == new.primaryAction:
    sameActionCount += 1
    if sameActionCount >= 3:  // 3ë²ˆ ì—°ì†
        return new
```

### 4. Temporal Lock (ì•ˆì •í™” íƒ€ì´ë¨¸)

#### State Machine
```swift
enum StabilityState {
    case idle                      // ì™„ë²½ ì•„ë‹˜
    case arming(startedAt: Date)   // ì™„ë²½ ìƒíƒœ ìœ ì§€ ì¤‘
    case locked                    // 0.5ì´ˆ ì´ìƒ ìœ ì§€ ì„±ê³µ!
}

private let lockDuration: TimeInterval = 0.5  // 0.5ì´ˆ

func updateStabilityProgress() {
    if evaluation.allPassed {
        switch stabilityState {
        case .idle:
            stabilityState = .arming(startedAt: Date())

        case .arming(let startedAt):
            let elapsed = Date().timeIntervalSince(startedAt)
            stabilityProgress = min(1.0, elapsed / lockDuration)

            if elapsed >= lockDuration:
                stabilityState = .locked
                triggerHapticFeedback()  // í–…í‹± í”¼ë“œë°±
                playSuccessSound()       // ì‚¬ìš´ë“œ

        case .locked:
            stabilityProgress = 1.0
        }
    } else {
        // Gate ì‹¤íŒ¨ â†’ ë¦¬ì…‹
        stabilityState = .idle
        stabilityProgress = 0.0
    }
}
```

---

## ğŸ“Š ì„±ëŠ¥ ì§€í‘œ (iPhone 12 Pro ê¸°ì¤€)

| í•­ëª© | ìˆ˜ì¹˜ | ì„¤ëª… |
|------|------|------|
| RTMPose ì¶”ë¡  ì‹œê°„ | 50-100ms | CoreML GPU ê°€ì† |
| Depth Anything ì¶”ë¡  ì‹œê°„ | 150-200ms | 10í”„ë ˆì„ë§ˆë‹¤ 1íšŒ |
| YOLOX ì¶”ë¡  ì‹œê°„ | 80-120ms | 30í”„ë ˆì„ë§ˆë‹¤ 1íšŒ |
| í”„ë ˆì„ ë¶„ì„ ê°„ê²© | 50ms | ì´ˆë‹¹ 20í”„ë ˆì„ |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | ~300MB | í”¼í¬ ì‹œ |
| ë°°í„°ë¦¬ ì†Œëª¨ | 10%/ì‹œê°„ | ì¼ë°˜ ì´¬ì˜ ì•± ìˆ˜ì¤€ |
| ì—´í™”ìƒ ê´€ë¦¬ | ìë™ ì¡°ì ˆ | nominal ~ critical |

---

## ğŸ“ ì£¼ìš” ê¸°ìˆ ì  íŠ¹ì§•

### 1. ì‹¤ì‹œê°„ì„±
- **50ms ê°„ê²© ë¶„ì„**: ì´ˆë‹¹ 20í”„ë ˆì„ ì²˜ë¦¬
- **ë¹„ë™ê¸° íŒŒì´í”„ë¼ì¸**: UI ë¸”ë¡œí‚¹ ì—†ìŒ
- **ê²°ê³¼ ìºì‹±**: ë¬´ê±°ìš´ ì—°ì‚°(Depth, YOLOX) ê²°ê³¼ ì¬ì‚¬ìš©

### 2. ì •ë°€ë„
- **133ê°œ í‚¤í¬ì¸íŠ¸**: ì–¼êµ´, ì†, ë°œê¹Œì§€ ì •ë°€ ë¶„ì„
- **ê¹Šì´ ì¶”ì •**: Depth Anythingìœ¼ë¡œ ì••ì¶•ê° ì¸¡ì •
- **EXIF ë¶„ì„**: ì‹¤ì œ ì´¬ì˜ ì´ˆì ê±°ë¦¬ ì¶”ì¶œ

### 3. ì‚¬ìš©ì„±
- **í†µí•© í”¼ë“œë°±**: "í•œ ë™ì‘ìœ¼ë¡œ ì—¬ëŸ¬ ë¬¸ì œ í•´ê²°"
- **êµ¬ì²´ì  ê°€ì´ë“œ**: "ë‘ ê±¸ìŒ ì•ìœ¼ë¡œ", "5Â° í‹¸íŠ¸"
- **ì•ˆì •í™” ì‹œìŠ¤í…œ**: ê¹œë¹¡ì„ ë°©ì§€ + Temporal Lock

### 4. íš¨ìœ¨ì„±
- **í”„ë ˆì„ ìŠ¤í‚µ**: ë™ì  ê°„ê²© ì¡°ì •
- **ì—´í™”ìƒ ê´€ë¦¬**: CPU ê³¼ì—´ ë°©ì§€
- **ë©”ëª¨ë¦¬ ìµœì í™”**: ì‹±ê¸€í†¤ + autoreleasepool

### 5. í™•ì¥ì„±
- **ëª¨ë“ˆí™” ì„¤ê³„**: Gateë³„ ë…ë¦½ í‰ê°€
- **Adaptive Difficulty**: ë‚œì´ë„ ìë™ ì¡°ì ˆ
- **í”ŒëŸ¬ê·¸ì¸ êµ¬ì¡°**: ìƒˆë¡œìš´ Gate ì¶”ê°€ ìš©ì´

---

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
ios_v1.5/TryAngleApp/
â”œâ”€â”€ Services/
â”‚   â”œâ”€â”€ Analysis/
â”‚   â”‚   â””â”€â”€ RTMPoseRunner.swift              # RTMPose (YOLOX + í¬ì¦ˆ ì¶”ì •)
â”‚   â”œâ”€â”€ OnDevice/
â”‚   â”‚   â”œâ”€â”€ DepthAnythingCoreML.swift        # Depth Anything (ì••ì¶•ê°)
â”‚   â”‚   â”œâ”€â”€ PersonDetector.swift             # ì¸ë¬¼ ê²€ì¶œ (YOLOX ì¬ì‚¬ìš©)
â”‚   â”‚   â”œâ”€â”€ GateSystem.swift                 # 5ë‹¨ê³„ Gate í‰ê°€
â”‚   â”‚   â””â”€â”€ UnifiedFeedbackGenerator.swift   # í†µí•© í”¼ë“œë°± ìƒì„±
â”‚   â”œâ”€â”€ Comparison/
â”‚   â”‚   â””â”€â”€ AdaptivePoseComparator.swift     # í¬ì¦ˆ ë¹„êµ (133 í‚¤í¬ì¸íŠ¸)
â”‚   â””â”€â”€ RealtimeAnalyzer.swift               # ì‹¤ì‹œê°„ ë¶„ì„ ë©”ì¸
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ yolox_int8.onnx                      # YOLOX ëª¨ë¸ (INT8 ì–‘ìí™”)
â”‚   â”œâ”€â”€ rtmpose_int8.onnx                    # RTMPose ëª¨ë¸ (INT8 ì–‘ìí™”)
â”‚   â””â”€â”€ DepthAnythingV2SmallF16.mlmodelc     # Depth Anything (CoreML)
â””â”€â”€ README.md                                # ë³¸ ë¬¸ì„œ
```

---

## ğŸš€ ì‹œì‘í•˜ê¸°

### ìš”êµ¬ì‚¬í•­
- iOS 15.0+
- Xcode 14.0+
- iPhone 12 ì´ìƒ ê¶Œì¥ (CoreML GPU ì„±ëŠ¥)

### ëª¨ë¸ íŒŒì¼ ì¤€ë¹„
1. **RTMPose ëª¨ë¸** (ONNX)
   - `yolox_int8.onnx` (ì•½ 35MB)
   - `rtmpose_int8.onnx` (ì•½ 45MB)
   - INT8 ì–‘ìí™”ë¡œ ëª¨ë¸ í¬ê¸° 1/4 ê°ì†Œ

2. **Depth Anything ëª¨ë¸** (CoreML)
   - ë‹¤ìš´ë¡œë“œ: https://huggingface.co/apple/coreml-depth-anything-v2-small
   - `DepthAnythingV2SmallF16.mlmodelc` (ì•½ 98MB)
   - í”„ë¡œì íŠ¸ì˜ `Resources/` í´ë”ì— ì¶”ê°€

### ë¹Œë“œ ë° ì‹¤í–‰
```bash
# 1. ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/your-repo/TryAngle.git
cd TryAngle/ios_v1.5

# 2. Xcodeì—ì„œ í”„ë¡œì íŠ¸ ì—´ê¸°
open TryAngleApp.xcodeproj

# 3. ëª¨ë¸ íŒŒì¼ ì¶”ê°€ (Build Phases > Copy Bundle Resources)
# - yolox_int8.onnx
# - rtmpose_int8.onnx
# - DepthAnythingV2SmallF16.mlmodelc

# 4. ë¹Œë“œ ë° ì‹¤í–‰ (Cmd+R)
```

---

## ğŸ”¬ ì˜ˆìƒ ì§ˆë¬¸ (FAQ)

### Q1. RTMPose ì¶”ë¡ ì´ ëŠë¦¬ë©´ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?
**A**: CoreML GPU ê°€ì†ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ì„ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.
```swift
// RTMPoseRunner.swiftì—ì„œ í™•ì¸
let poseOptions = try ORTSessionOptions()
try poseOptions.appendCoreMLExecutionProvider()  // GPU ê°€ì†
```

### Q2. Depth Anything ì—†ì´ë„ ì‘ë™í•˜ë‚˜ìš”?
**A**: ë„¤, EXIF ê¸°ë°˜ ì´ˆì ê±°ë¦¬ ì¶”ì¶œë¡œ ëŒ€ì²´ ê°€ëŠ¥í•©ë‹ˆë‹¤. DepthëŠ” EXIFê°€ ì—†ì„ ë•Œë§Œ Fallbackìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.

### Q3. Gate 3 (ì••ì¶•ê°)ê°€ í•­ìƒ ì‹¤íŒ¨í•˜ëŠ”ë°ìš”?
**A**: ë ˆí¼ëŸ°ìŠ¤ ì‚¬ì§„ì´ EXIF ë©”íƒ€ë°ì´í„°ê°€ ì—†ê³ , Depth ì¶”ì •ë„ ë¶€ì •í™•í•œ ê²½ìš°ì…ë‹ˆë‹¤. Gate 3ë¥¼ ì„ íƒì ìœ¼ë¡œ ë¹„í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
```swift
// GateSystem.swift
let enableCompressionGate = false  // ì••ì¶•ê° Gate ë¹„í™œì„±í™”
```

### Q4. í¬ì¦ˆ ë¹„êµê°€ ë„ˆë¬´ ì—„ê²©í•´ìš”
**A**: Adaptive Difficulty ì‹œìŠ¤í…œì´ 5ì´ˆ í›„ ìë™ìœ¼ë¡œ ì™„í™”ë©ë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì¡°ì •í•˜ë ¤ë©´:
```swift
// AdaptivePoseComparator.swift
private let confidenceThreshold: Float = 0.4  // 0.5 â†’ 0.4 (ë” ê´€ëŒ€)
```

### Q5. ë°°í„°ë¦¬ ì†Œëª¨ê°€ í°ë°ìš”?
**A**: ì—´í™”ìƒ ê´€ë¦¬ì™€ í”„ë ˆì„ ìŠ¤í‚µ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”:
```swift
// RealtimeAnalyzer.swift
private let analysisInterval: TimeInterval = 0.10  // 50ms â†’ 100ms (ë” ëŠë¦¬ê²Œ)
```

---

## ğŸ“ ë¼ì´ì„ ìŠ¤

ë³¸ í”„ë¡œì íŠ¸ëŠ” [MIT License](LICENSE)ë¥¼ ë”°ë¦…ë‹ˆë‹¤.

---

## ğŸ‘¥ ê¸°ì—¬ì

- **ê°œë°œì**: [Your Name]
- **ì§€ë„ êµìˆ˜**: [Professor Name]
- **í”„ë¡œì íŠ¸ ê¸°ê°„**: 2024.09 - 2025.01

---

## ğŸ™ ê°ì‚¬ì˜ ë§

ë³¸ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒ ì˜¤í”ˆì†ŒìŠ¤ë¥¼ í™œìš©í–ˆìŠµë‹ˆë‹¤:
- **RTMPose**: [MMPose](https://github.com/open-mmlab/mmpose)
- **Depth Anything V2**: [Apple CoreML](https://huggingface.co/apple/coreml-depth-anything-v2-small)
- **ONNX Runtime**: [Microsoft](https://onnxruntime.ai/)

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-12-11
