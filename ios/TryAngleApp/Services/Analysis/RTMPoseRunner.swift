import Foundation
import UIKit
import CoreGraphics
import Accelerate

// MARK: - RTMPose ê²°ê³¼ êµ¬ì¡°ì²´
struct RTMPoseResult {
    let keypoints: [(point: CGPoint, confidence: Float)]  // 133ê°œ í‚¤í¬ì¸íŠ¸
    let boundingBox: CGRect?  // ì¸ë¬¼ ê²€ì¶œ ë°•ìŠ¤
}

// MARK: - RTMPose Runner (ONNX Runtime Objective-C API)
class RTMPoseRunner {

    private var detectorSession: ORTSession?
    private var poseSession: ORTSession?
    private var env: ORTEnv?

    // ëª¨ë¸ ê²½ë¡œ
    private let detectorModelPath: String
    private let poseModelPath: String

    // ëª¨ë¸ ì…ë ¥ í¬ê¸°
    private let detectorInputSize = CGSize(width: 640, height: 640)
    private let poseInputSize = CGSize(width: 192, height: 256)

    init?() {
        print("ğŸš€ RTMPoseRunner init() ì‹œì‘")

        // ONNX format ëª¨ë¸ ì‚¬ìš© (ì „ì²´ ONNX Runtime ì‚¬ìš©)
        guard let detectorURL = Bundle.main.url(forResource: "yolox_int8", withExtension: "onnx") else {
            print("âŒ yolox_int8.onnx íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            print("   Bundle path: \(Bundle.main.bundlePath)")
            print("   Bundle resources: \(Bundle.main.paths(forResourcesOfType: "onnx", inDirectory: nil))")
            return nil
        }

        guard let poseURL = Bundle.main.url(forResource: "rtmpose_int8", withExtension: "onnx") else {
            print("âŒ rtmpose_int8.onnx íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            print("   Bundle path: \(Bundle.main.bundlePath)")
            print("   Bundle resources: \(Bundle.main.paths(forResourcesOfType: "onnx", inDirectory: nil))")
            return nil
        }

        detectorModelPath = detectorURL.path
        poseModelPath = poseURL.path

        print("âœ… ONNX ëª¨ë¸ ê²½ë¡œ í™•ì¸ (ì „ì²´ Runtime ì‚¬ìš©):")
        print("   Detector (YOLOX): \(detectorModelPath)")
        print("   Pose (RTMPose): \(poseModelPath)")

        setupONNXRuntime()
    }

    deinit {
        print("ğŸ—‘ï¸ RTMPoseRunner deinit")
    }

    // MARK: - ONNX Runtime ì´ˆê¸°í™”
    private func setupONNXRuntime() {
        print("ğŸ”§ ONNX Runtime ì´ˆê¸°í™” ì‹œì‘...")

        do {
            // 1. Environment ìƒì„±
            env = try ORTEnv(loggingLevel: ORTLoggingLevel.warning)
            print("âœ… Environment ìƒì„± ì„±ê³µ")

            // 2. YOLOXìš© Session Options (CoreML GPU ê°€ì†)
            let detectorOptions = try ORTSessionOptions()

            // ğŸ”¥ YOLOXë„ CoreML GPU ê°€ì† í™œì„±í™”
            do {
                try detectorOptions.appendCoreMLExecutionProvider()
                print("âœ… YOLOX: CoreML GPU ê°€ì† í™œì„±í™”")
            } catch {
                print("âš ï¸ YOLOX CoreML í™œì„±í™” ì‹¤íŒ¨, CPU í´ë°±: \(error)")
            }

            try detectorOptions.setIntraOpNumThreads(6)  // ë³‘ë ¬ ì²˜ë¦¬
            try detectorOptions.setGraphOptimizationLevel(.all)

            // 3. RTMPoseìš© Session Options (CoreML GPU ê°€ì†)
            let poseOptions = try ORTSessionOptions()

            // ğŸ”¥ CoreML Execution Provider í™œì„±í™” (GPU ê°€ì†)
            do {
                try poseOptions.appendCoreMLExecutionProvider()
                print("âœ… RTMPose: CoreML GPU ê°€ì† í™œì„±í™”")
            } catch {
                print("âš ï¸ RTMPose CoreML í™œì„±í™” ì‹¤íŒ¨, CPU í´ë°±: \(error)")
            }

            // ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì • (ìµœëŒ€ ì„±ëŠ¥)
            try poseOptions.setIntraOpNumThreads(6)  // ğŸ”¥ ìŠ¤ë ˆë“œ 6ê°œë¡œ ì¦ê°€
            try poseOptions.setGraphOptimizationLevel(.all)

            print("âœ… ìµœëŒ€ ì„±ëŠ¥ ìµœì í™” ì„¤ì • ì™„ë£Œ (YOLOX: CoreML GPU, RTMPose: CoreML GPU)")

            // 4. ì„¸ì…˜ ìƒì„±
            print("ğŸ“¦ Detector ëª¨ë¸ ë¡œë”© ì¤‘... (\(detectorModelPath))")
            detectorSession = try ORTSession(env: env!, modelPath: detectorModelPath, sessionOptions: detectorOptions)
            print("âœ… YOLOX Detector ë¡œë“œ ì„±ê³µ (CoreML GPU)")

            print("ğŸ“¦ Pose ëª¨ë¸ ë¡œë”© ì¤‘... (\(poseModelPath))")
            poseSession = try ORTSession(env: env!, modelPath: poseModelPath, sessionOptions: poseOptions)
            print("âœ… RTMPose ë¡œë“œ ì„±ê³µ (CoreML GPU)")

            print("ğŸ”§ ONNX Runtime ì´ˆê¸°í™” ì™„ë£Œ")

        } catch {
            print("âŒ ONNX Runtime ì´ˆê¸°í™” ì‹¤íŒ¨: \(error)")
            env = nil
            detectorSession = nil
            poseSession = nil
        }
    }

    // MARK: - í¬ì¦ˆ ì¶”ì •
    func detectPose(from image: UIImage) -> RTMPoseResult? {
        guard let detectorSession = detectorSession,
              let poseSession = poseSession,
              let env = env else {
            print("âŒ RTMPose ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            return nil
        }

        // 1. YOLOXë¡œ ì‚¬ëŒ ê²€ì¶œ
        let boundingBox: CGRect
        if let detectedBox = detectPerson(from: image, using: detectorSession, env: env) {
            print("âœ… YOLOX: ì‚¬ëŒ ê²€ì¶œ ì„±ê³µ - \(detectedBox)")
            boundingBox = detectedBox
        } else {
            // YOLOXê°€ ì‚¬ëŒì„ ê²€ì¶œí•˜ì§€ ëª»í•˜ë©´ ì „ì²´ ì´ë¯¸ì§€ ì‚¬ìš©
            print("âš ï¸ YOLOX: ì‚¬ëŒì„ ê²€ì¶œí•˜ì§€ ëª»í•¨ â†’ ì „ì²´ ì´ë¯¸ì§€ë¡œ í¬ì¦ˆ ì¶”ì • ì‹œë„")
            guard let cgImage = image.cgImage else { return nil }
            boundingBox = CGRect(x: 0, y: 0, width: cgImage.width, height: cgImage.height)
        }

        // 2. ê²€ì¶œëœ ì˜ì—­ìœ¼ë¡œ í¬ì¦ˆ ì¶”ì •
        let keypoints = estimatePose(from: image, boundingBox: boundingBox, using: poseSession, env: env)

        if let keypoints = keypoints {
            print("âœ… RTMPose: \(keypoints.count)ê°œ í‚¤í¬ì¸íŠ¸ ê²€ì¶œ ì„±ê³µ")
        } else {
            print("âŒ RTMPose: í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨")
        }

        return keypoints.map { RTMPoseResult(keypoints: $0, boundingBox: boundingBox) }
    }

    // MARK: - YOLOX ì‚¬ëŒ ê²€ì¶œ
    private func detectPerson(from image: UIImage, using session: ORTSession, env: ORTEnv) -> CGRect? {
        guard let cgImage = image.cgImage else { return nil }

        // ì´ë¯¸ì§€ë¥¼ 640x640ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        let inputSize = detectorInputSize
        guard let resizedImage = resizeImage(cgImage, targetSize: inputSize) else { return nil }

        // ì´ë¯¸ì§€ë¥¼ Float ë°°ì—´ë¡œ ë³€í™˜ (RGB, ì •ê·œí™”)
        let pixelData = preprocessImage(resizedImage, size: inputSize)

        do {
            // ì…ë ¥ í…ì„œ ìƒì„± - [1, 3, 640, 640]
            let inputShape: [NSNumber] = [1, 3, NSNumber(value: Int(inputSize.height)), NSNumber(value: Int(inputSize.width))]
            let inputTensor = try ORTValue(
                tensorData: NSMutableData(data: pixelData),
                elementType: .float,
                shape: inputShape
            )

            // ì¶”ë¡  ì‹¤í–‰
            let outputs = try session.run(
                withInputs: ["input": inputTensor],
                outputNames: ["dets", "labels"],
                runOptions: nil
            )

            guard let detsTensor = outputs["dets"],
                  let labelsTensor = outputs["labels"] else {
                print("âŒ YOLOX ì¶œë ¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return nil
            }

            // ì¶œë ¥ íŒŒì‹±í•˜ì—¬ ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œ
            return parseYOLOXOutput(detsTensor, labels: labelsTensor, imageSize: CGSize(width: cgImage.width, height: cgImage.height))

        } catch {
            print("âŒ YOLOX ì¶”ë¡  ì˜¤ë¥˜: \(error)")
            return nil
        }
    }

    // MARK: - RTMPose í¬ì¦ˆ ì¶”ì •
    private func estimatePose(from image: UIImage, boundingBox: CGRect, using session: ORTSession, env: ORTEnv) -> [(point: CGPoint, confidence: Float)]? {
        guard let cgImage = image.cgImage else { return nil }

        // ë°”ìš´ë”© ë°•ìŠ¤ ì˜ì—­ í¬ë¡­
        guard let croppedImage = cropImage(cgImage, rect: boundingBox) else { return nil }

        // 192x256ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        let inputSize = poseInputSize
        guard let resizedImage = resizeImage(croppedImage, targetSize: inputSize) else { return nil }

        // ì´ë¯¸ì§€ë¥¼ Float ë°°ì—´ë¡œ ë³€í™˜
        let pixelData = preprocessImage(resizedImage, size: inputSize)

        do {
            // ì…ë ¥ í…ì„œ ìƒì„± - [1, 3, 256, 192]
            let inputShape: [NSNumber] = [1, 3, NSNumber(value: Int(inputSize.height)), NSNumber(value: Int(inputSize.width))]
            let inputTensor = try ORTValue(
                tensorData: NSMutableData(data: pixelData),
                elementType: .float,
                shape: inputShape
            )

            // ì¶”ë¡  ì‹¤í–‰
            let outputs = try session.run(
                withInputs: ["input": inputTensor],
                outputNames: ["simcc_x", "simcc_y"],
                runOptions: nil
            )

            guard let simccX = outputs["simcc_x"],
                  let simccY = outputs["simcc_y"] else {
                print("âŒ RTMPose ì¶œë ¥(SimCC)ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return nil
            }

            // SimCC ì¶œë ¥ íŒŒì‹±í•˜ì—¬ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ (133ê°œ)
            return parseRTMPoseSimCCOutput(simccX: simccX, simccY: simccY, boundingBox: boundingBox)

        } catch {
            print("âŒ RTMPose ì¶”ë¡  ì˜¤ë¥˜: \(error)")
            return nil
        }
    }

    // MARK: - ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í—¬í¼ í•¨ìˆ˜ë“¤
    private func resizeImage(_ cgImage: CGImage, targetSize: CGSize) -> CGImage? {
        let width = Int(targetSize.width)
        let height = Int(targetSize.height)

        guard let context = CGContext(
            data: nil,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: width * 4,
            space: CGColorSpaceCreateDeviceRGB(),
            bitmapInfo: CGImageAlphaInfo.noneSkipLast.rawValue
        ) else { return nil }

        context.interpolationQuality = .high
        context.draw(cgImage, in: CGRect(origin: .zero, size: targetSize))
        return context.makeImage()
    }

    private func cropImage(_ cgImage: CGImage, rect: CGRect) -> CGImage? {
        // ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì¶©ë¶„íˆ í™•ì¥ (ì†ì´ í¬í•¨ë˜ë„ë¡ íŒ¨ë”© ì¦ê°€)
        // ğŸ”¥ ì† ì¸ì‹ ê°œì„ : íŒ¨ë”©ì„ 0.2ì—ì„œ 0.4ë¡œ ì¦ê°€
        let padding: CGFloat = 0.4  // 40% íŒ¨ë”©ìœ¼ë¡œ ì†ê¹Œì§€ í¬í•¨
        let expandedRect = CGRect(
            x: rect.minX - rect.width * padding,
            y: rect.minY - rect.height * padding,
            width: rect.width * (1 + 2 * padding),
            height: rect.height * (1 + 2 * padding)
        ).intersection(CGRect(x: 0, y: 0, width: cgImage.width, height: cgImage.height))

        return cgImage.cropping(to: expandedRect)
    }

    private func preprocessImage(_ cgImage: CGImage, size: CGSize) -> Data {
        let width = Int(size.width)
        let height = Int(size.height)
        let bytesPerPixel = 4
        let bytesPerRow = bytesPerPixel * width
        let bitsPerComponent = 8

        var rawData = [UInt8](repeating: 0, count: width * height * bytesPerPixel)

        guard let context = CGContext(
            data: &rawData,
            width: width,
            height: height,
            bitsPerComponent: bitsPerComponent,
            bytesPerRow: bytesPerRow,
            space: CGColorSpaceCreateDeviceRGB(),
            bitmapInfo: CGImageAlphaInfo.noneSkipLast.rawValue
        ) else {
            return Data()
        }

        context.draw(cgImage, in: CGRect(x: 0, y: 0, width: width, height: height))

        // RGBAë¥¼ RGBë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™” (ImageNet í‰ê· /í‘œì¤€í¸ì°¨)
        var floatData = [Float](repeating: 0, count: width * height * 3)
        let mean: [Float] = [0.485, 0.456, 0.406]
        let std: [Float] = [0.229, 0.224, 0.225]

        for y in 0..<height {
            for x in 0..<width {
                let pixelIndex = y * width + x
                let dataIndex = pixelIndex * 4

                // RGB ì±„ë„ë³„ë¡œ ì •ê·œí™”
                for c in 0..<3 {
                    let value = Float(rawData[dataIndex + c]) / 255.0
                    floatData[c * width * height + pixelIndex] = (value - mean[c]) / std[c]
                }
            }
        }

        return Data(bytes: &floatData, count: floatData.count * MemoryLayout<Float>.size)
    }

    // MARK: - ì¶œë ¥ íŒŒì‹±
    private func parseYOLOXOutput(_ dets: ORTValue, labels: ORTValue, imageSize: CGSize) -> CGRect? {
        // YOLOX ì¶œë ¥ í˜•ì‹:
        // dets: [1, num_boxes, 5] - (x1, y1, x2, y2, score)
        // labels: [1, num_boxes] - class_id

        guard let detsData = try? dets.tensorData() as NSData,
              let labelsData = try? labels.tensorData() as NSData else { return nil }
        guard let detsShape = try? dets.tensorTypeAndShapeInfo().shape else { return nil }

        let numBoxes = detsShape[1].intValue
        if numBoxes == 0 {
            print("âš ï¸ YOLOX: ê²€ì¶œëœ ë°•ìŠ¤ ì—†ìŒ")
            return nil
        }

        var bestBox: CGRect?
        var bestScore: Float = 0.3  // ìµœì†Œ ì„ê³„ê°’

        let detsPointer = detsData.bytes.bindMemory(to: Float.self, capacity: detsData.length / MemoryLayout<Float>.size)
        let labelsPointer = labelsData.bytes.bindMemory(to: Int64.self, capacity: labelsData.length / MemoryLayout<Int64>.size)

        // 640x640 ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
        let scaleX = imageSize.width / detectorInputSize.width
        let scaleY = imageSize.height / detectorInputSize.height

        for i in 0..<numBoxes {
            let label = labelsPointer[i]
            // person class = 0
            guard label == 0 else { continue }

            let offset = i * 5
            let x1 = CGFloat(detsPointer[offset + 0]) * scaleX
            let y1 = CGFloat(detsPointer[offset + 1]) * scaleY
            let x2 = CGFloat(detsPointer[offset + 2]) * scaleX
            let y2 = CGFloat(detsPointer[offset + 3]) * scaleY
            let score = detsPointer[offset + 4]

            if score > bestScore {
                bestBox = CGRect(
                    x: x1,
                    y: y1,
                    width: x2 - x1,
                    height: y2 - y1
                )
                bestScore = score
            }
        }

        return bestBox
    }

    private func parseRTMPoseSimCCOutput(simccX: ORTValue, simccY: ORTValue, boundingBox: CGRect) -> [(point: CGPoint, confidence: Float)]? {
        // SimCC ì¶œë ¥ í˜•ì‹:
        // simcc_x: [1, num_keypoints, 384] - x ì¢Œí‘œ í™•ë¥  ë¶„í¬
        // simcc_y: [1, num_keypoints, 512] - y ì¢Œí‘œ í™•ë¥  ë¶„í¬

        guard let xData = try? simccX.tensorData() as NSData,
              let yData = try? simccY.tensorData() as NSData else { return nil }
        guard let xShape = try? simccX.tensorTypeAndShapeInfo().shape,
              let yShape = try? simccY.tensorTypeAndShapeInfo().shape else { return nil }

        let numKeypoints = xShape[1].intValue
        let xBins = xShape[2].intValue  // 384
        let yBins = yShape[2].intValue  // 512

        if numKeypoints != 133 {
            print("âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ í‚¤í¬ì¸íŠ¸ ìˆ˜: \(numKeypoints)")
            return nil
        }

        var keypoints: [(point: CGPoint, confidence: Float)] = []
        let xPointer = xData.bytes.bindMemory(to: Float.self, capacity: xData.length / MemoryLayout<Float>.size)
        let yPointer = yData.bytes.bindMemory(to: Float.self, capacity: yData.length / MemoryLayout<Float>.size)

        for i in 0..<numKeypoints {
            // x ì¢Œí‘œ: argmax ì°¾ê¸°
            let xOffset = i * xBins
            var maxXIdx = 0
            var maxXVal: Float = -Float.infinity
            for j in 0..<xBins {
                let val = xPointer[xOffset + j]
                if val > maxXVal {
                    maxXVal = val
                    maxXIdx = j
                }
            }

            // y ì¢Œí‘œ: argmax ì°¾ê¸°
            let yOffset = i * yBins
            var maxYIdx = 0
            var maxYVal: Float = -Float.infinity
            for j in 0..<yBins {
                let val = yPointer[yOffset + j]
                if val > maxYVal {
                    maxYVal = val
                    maxYIdx = j
                }
            }

            // SimCC ì¢Œí‘œë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
            // 384 bins -> 192 pixels, 512 bins -> 256 pixels (ê°ê° 2ë°° í•´ìƒë„)
            let xNorm = CGFloat(maxXIdx) / CGFloat(xBins) * poseInputSize.width
            let yNorm = CGFloat(maxYIdx) / CGFloat(yBins) * poseInputSize.height

            // ë°”ìš´ë”© ë°•ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
            let point = CGPoint(
                x: boundingBox.minX + (xNorm / poseInputSize.width) * boundingBox.width,
                y: boundingBox.minY + (yNorm / poseInputSize.height) * boundingBox.height
            )

            // ì‹ ë¢°ë„: ë‘ í™•ë¥ ì˜ í‰ê· 
            let confidence = (maxXVal + maxYVal) / 2.0

            keypoints.append((point: point, confidence: confidence))

            // ğŸ” ì† í‚¤í¬ì¸íŠ¸ ë””ë²„ê·¸ (91-132ë²ˆ)
            if i >= 91 && i <= 132 {
                if confidence < 0.3 {
                    let handName = i <= 111 ? "ì™¼ì†" : "ì˜¤ë¥¸ì†"
                    let keypointIndex = i <= 111 ? i - 91 : i - 112
                    if keypointIndex % 5 == 0 {  // 5ê°œë§ˆë‹¤ í•œ ë²ˆë§Œ ë¡œê·¸
                        print("âš ï¸ \(handName) í‚¤í¬ì¸íŠ¸ \(keypointIndex): ì‹ ë¢°ë„ ë‚®ìŒ (\(String(format: "%.2f", confidence)))")
                    }
                }
            }
        }

        // ì† í‚¤í¬ì¸íŠ¸ ìš”ì•½ í†µê³„
        let leftHandConfidences = (91...111).compactMap { keypoints[$0].confidence }
        let rightHandConfidences = (112...132).compactMap { keypoints[$0].confidence }

        let leftHandAvg = leftHandConfidences.reduce(0, +) / Float(leftHandConfidences.count)
        let rightHandAvg = rightHandConfidences.reduce(0, +) / Float(rightHandConfidences.count)

        if leftHandAvg < 0.5 || rightHandAvg < 0.5 {
            print("ğŸ“Š ì† ì¸ì‹ í‰ê·  ì‹ ë¢°ë„ - ì™¼ì†: \(String(format: "%.2f", leftHandAvg)), ì˜¤ë¥¸ì†: \(String(format: "%.2f", rightHandAvg))")
            if leftHandAvg < 0.3 || rightHandAvg < 0.3 {
                print("ğŸ’¡ ì†ì´ í™”ë©´ì—ì„œ ì˜ë ¸ê±°ë‚˜ ê°€ë ¤ì¡Œì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „ì²´ ì‹ ì²´ê°€ í”„ë ˆì„ ì•ˆì— ë“¤ì–´ì˜¤ë„ë¡ ì¡°ì •í•´ë³´ì„¸ìš”.")
            }
        }

        return keypoints
    }
}
