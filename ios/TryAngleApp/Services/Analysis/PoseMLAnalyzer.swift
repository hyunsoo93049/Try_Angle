import Foundation
import Vision
import UIKit

// MARK: - PoseML ë¶„ì„ê¸° (RTMPose via ONNX Runtime)
class PoseMLAnalyzer {

    // RTMPose Runner (ONNX Runtime)
    private let rtmPoseRunner: RTMPoseRunner?

    // Visionì€ ì–¼êµ´ ê°ì§€ìš©ìœ¼ë¡œ ê³„ì† ì‚¬ìš©
    private lazy var faceDetectionRequest: VNDetectFaceLandmarksRequest = {
        let request = VNDetectFaceLandmarksRequest()
        request.revision = VNDetectFaceLandmarksRequestRevision3
        return request
    }()

    // ğŸ› ë””ë²„ê·¸ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
    private lazy var logFileURL: URL? = {
        if let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first {
            return documentsPath.appendingPathComponent("pose_debug.txt")
        }
        return nil
    }()

    init() {
        print("ğŸš€ PoseMLAnalyzer init() ì‹œì‘")

        // RTMPose Runner ì´ˆê¸°í™” ì‹œë„ (stored property ë¨¼ì € ì´ˆê¸°í™”)
        rtmPoseRunner = RTMPoseRunner()

        // ì´ˆê¸°í™” ì™„ë£Œ í›„ ë¡œê·¸
        logToFile("ğŸš€ PoseMLAnalyzer init() ì‹œì‘ - \(Date())")

        if rtmPoseRunner != nil {
            print("âœ… RTMPose Runner ì´ˆê¸°í™” ì„±ê³µ")
            logToFile("âœ… RTMPose ì‚¬ìš© (ONNX Runtime with CoreML EP)")
        } else {
            print("âŒ RTMPose Runner ì´ˆê¸°í™” ì‹¤íŒ¨ - ONNX ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            logToFile("âŒ RTMPose ì´ˆê¸°í™” ì‹¤íŒ¨")
        }

        print("ğŸš€ PoseMLAnalyzer init() ì™„ë£Œ")
    }

    // ğŸ› íŒŒì¼ì— ë¡œê·¸ ê¸°ë¡
    private func logToFile(_ message: String) {
        guard let logFileURL = logFileURL else { return }

        let timestamp = DateFormatter.localizedString(from: Date(), dateStyle: .none, timeStyle: .medium)
        let logMessage = "[\(timestamp)] \(message)\n"

        if let data = logMessage.data(using: .utf8) {
            if FileManager.default.fileExists(atPath: logFileURL.path) {
                if let fileHandle = try? FileHandle(forWritingTo: logFileURL) {
                    fileHandle.seekToEndOfFile()
                    fileHandle.write(data)
                    fileHandle.closeFile()
                }
            } else {
                try? data.write(to: logFileURL)
            }
        }

        // ì½˜ì†”ì—ë„ ì¶œë ¥
        print(message)
    }

    // MARK: - ì–¼êµ´ + í¬ì¦ˆ ë™ì‹œ ë¶„ì„ (VisionAnalyzerì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤)
    private var analysisCallCount = 0
    func analyzeFaceAndPose(from image: UIImage) -> (face: FaceAnalysisResult?, pose: PoseAnalysisResult?) {
        analysisCallCount += 1

        // 10ë²ˆë§ˆë‹¤ ë¡œê·¸ (ë„ˆë¬´ ë§ì€ ë¡œê·¸ ë°©ì§€)
        if analysisCallCount % 10 == 1 {
            logToFile("ğŸ” analyzeFaceAndPose() í˜¸ì¶œë¨ (í˜¸ì¶œ íšŸìˆ˜: \(analysisCallCount))")
        }

        // ì–¼êµ´ ê°ì§€ (Vision ê³„ì† ì‚¬ìš© - ê°€ì¥ ì •í™•í•¨)
        let faceResult = detectFace(from: image)

        // RTMPose í¬ì¦ˆ ê°ì§€ (ONNX Runtime)
        let poseResult = detectPoseWithRTMPose(from: image)

        // 10ë²ˆë§ˆë‹¤ ìƒì„¸ ë¡œê·¸
        if analysisCallCount % 10 == 1 {
            logToFile("   ì–¼êµ´: \(faceResult != nil ? "âœ“" : "âœ—") | í¬ì¦ˆ: \(poseResult != nil ? "âœ“ (RTMPose)" : "âœ—")")
        }

        return (faceResult, poseResult)
    }

    // MARK: - ì–¼êµ´ ê°ì§€ (Vision)
    private func detectFace(from image: UIImage) -> FaceAnalysisResult? {
        guard let cgImage = image.cgImage else { return nil }

        let handler = VNImageRequestHandler(
            cgImage: cgImage,
            orientation: image.cgImageOrientation,
            options: [:]
        )
        try? handler.perform([faceDetectionRequest])

        guard let observation = faceDetectionRequest.results?.first else {
            return nil
        }

        return FaceAnalysisResult(
            faceRect: observation.boundingBox,
            landmarks: observation.landmarks,
            yaw: observation.yaw?.floatValue,
            pitch: observation.pitch?.floatValue,
            roll: observation.roll?.floatValue,
            observation: observation
        )
    }

    // MARK: - RTMPose í¬ì¦ˆ ê°ì§€
    private func detectPoseWithRTMPose(from image: UIImage) -> PoseAnalysisResult? {
        guard let runner = rtmPoseRunner else {
            return nil
        }

        guard let rtmResult = runner.detectPose(from: image) else {
            return nil
        }

        // RTMPose í‚¤í¬ì¸íŠ¸ë¥¼ PoseAnalysisResult í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        // RTMPoseëŠ” 133ê°œ í‚¤í¬ì¸íŠ¸ ì œê³µ (ì „ì‹  + ì–¼êµ´ + ì† + ë°œ)
        // ê¸°ì¡´ PoseAnalysisResult í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (17ê°œ ì£¼ìš” í‚¤í¬ì¸íŠ¸)

        // COCO 17 keypoints ë§¤í•‘
        // 0: nose, 1-2: eyes, 3-4: ears, 5-6: shoulders, 7-8: elbows,
        // 9-10: wrists, 11-12: hips, 13-14: knees, 15-16: ankles

        // RTMPose 133 í‚¤í¬ì¸íŠ¸ ì¤‘ COCO í˜¸í™˜ ì¸ë±ìŠ¤ ì¶”ì¶œ
        let cocoIndices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
        var keypoints: [(point: CGPoint, confidence: Float)] = []

        for idx in cocoIndices {
            if idx < rtmResult.keypoints.count {
                let kp = rtmResult.keypoints[idx]
                keypoints.append((point: kp.point, confidence: kp.confidence))
            } else {
                keypoints.append((point: CGPoint.zero, confidence: 0.0))
            }
        }

        return PoseAnalysisResult(keypoints: keypoints)
    }

    /// ë°ê¸° ê³„ì‚° (VisionAnalyzerì™€ í˜¸í™˜)
    func calculateBrightness(from cgImage: CGImage) -> Float {
        let width = min(cgImage.width, 100)
        let height = min(cgImage.height, 100)

        guard let context = CGContext(
            data: nil,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: width * 4,
            space: CGColorSpaceCreateDeviceRGB(),
            bitmapInfo: CGImageAlphaInfo.premultipliedLast.rawValue
        ) else { return 0.5 }

        context.draw(cgImage, in: CGRect(x: 0, y: 0, width: width, height: height))
        guard let data = context.data else { return 0.5 }

        let buffer = data.bindMemory(to: UInt8.self, capacity: width * height * 4)
        var totalBrightness: Float = 0

        for i in stride(from: 0, to: width * height * 4, by: 4) {
            let r = Float(buffer[i]) / 255.0
            let g = Float(buffer[i + 1]) / 255.0
            let b = Float(buffer[i + 2]) / 255.0
            totalBrightness += (r + g + b) / 3.0
        }

        return totalBrightness / Float(width * height)
    }

    /// ì „ì‹  ì˜ì—­ ì¶”ì • (VisionAnalyzerì™€ í˜¸í™˜)
    func estimateBodyRect(from faceRect: CGRect?) -> CGRect? {
        guard let face = faceRect else { return nil }

        let bodyWidth = face.width * 3
        let bodyHeight = face.height * 7
        let bodyX = face.midX - bodyWidth / 2
        let bodyY = face.minY

        return CGRect(x: bodyX, y: bodyY, width: bodyWidth, height: bodyHeight)
    }
}
