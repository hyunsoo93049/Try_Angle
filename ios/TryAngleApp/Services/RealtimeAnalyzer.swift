import Foundation
import Vision
import UIKit
import CoreImage
import Combine

// MARK: - ì‹¤ì‹œê°„ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° êµ¬ì¡°
struct FrameAnalysis {
    let faceRect: CGRect?                           // ì–¼êµ´ ìœ„ì¹˜ (ì •ê·œí™”ëœ ì¢Œí‘œ)
    let bodyRect: CGRect?                           // ì „ì‹  ì¶”ì • ì˜ì—­
    let brightness: Float                           // í‰ê·  ë°ê¸°
    let tiltAngle: Float                            // ê¸°ìš¸ê¸° ê°ë„
    let faceYaw: Float?                             // ì–¼êµ´ ì¢Œìš° íšŒì „ (ì •ë©´=0)
    let facePitch: Float?                           // ì–¼êµ´ ìƒí•˜ ê°ë„
    let cameraAngle: CameraAngle?                   // ğŸ†• ì¹´ë©”ë¼ ê°ë„ (enum)
    let poseKeypoints: [(point: CGPoint, confidence: Float)]?  // ğŸ†• ì‹ ë¢°ë„ í¬í•¨ í‚¤í¬ì¸íŠ¸
    let compositionType: CompositionType?           // ğŸ†• êµ¬ë„ íƒ€ì…
    let faceObservation: VNFaceObservation?         // ğŸ†• ì–¼êµ´ ê´€ì°° ê²°ê³¼ (ëœë“œë§ˆí¬ í¬í•¨)
}

// MARK: - ì‹¤ì‹œê°„ í”¼ë“œë°± ìƒì„±ê¸°
class RealtimeAnalyzer: ObservableObject {
    @Published var instantFeedback: [FeedbackItem] = []
    @Published var isPerfect: Bool = false  // ì™„ë²½í•œ ìƒíƒœ ê°ì§€
    @Published var perfectScore: Double = 0.0  // ì™„ì„±ë„ ì ìˆ˜ (0~1)

    private var referenceAnalysis: FrameAnalysis?
    private var lastAnalysisTime = Date()
    private let analysisInterval: TimeInterval = 0.1  // 100msë§ˆë‹¤ ë¶„ì„

    // íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ë¥¼ ìœ„í•œ ìƒíƒœ ì¶”ì 
    private var feedbackHistory: [String: Int] = [:]  // ì¹´í…Œê³ ë¦¬ë³„ ì—°ì† ê°ì§€ íšŸìˆ˜
    private let historyThreshold = 3  // 3ë²ˆ ì—°ì† ê°ì§€ë˜ì–´ì•¼ í‘œì‹œ
    private var perfectFrameCount = 0  // ì™„ë²½í•œ í”„ë ˆì„ ì—°ì† íšŸìˆ˜
    private let perfectThreshold = 10  // 10í”„ë ˆì„(ì•½ 1ì´ˆ) ì—°ì† ì™„ë²½í•´ì•¼ ê°ì§€

    // ğŸ†• V1 ë¶„ì„ê¸°ë“¤
    private let compositionAnalyzer = CompositionAnalyzer()
    private let cameraAngleDetector = CameraAngleDetector()
    private let poseComparator = AdaptivePoseComparator()

    // Vision ìš”ì²­ ìºì‹±
    private lazy var faceDetectionRequest: VNDetectFaceLandmarksRequest = {
        let request = VNDetectFaceLandmarksRequest()
        request.revision = VNDetectFaceLandmarksRequestRevision3
        return request
    }()

    private lazy var poseDetectionRequest: VNDetectHumanBodyPoseRequest = {
        let request = VNDetectHumanBodyPoseRequest()
        return request
    }()

    // MARK: - ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ë¶„ì„
    func analyzeReference(_ image: UIImage) {
        guard let cgImage = image.cgImage else { return }

        // Vision ìš”ì²­ ì‹¤í–‰
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        try? handler.perform([faceDetectionRequest, poseDetectionRequest])

        // ì–¼êµ´ ì˜ì—­ ë° ê°ë„ ì¶”ì¶œ
        let faceObservation = faceDetectionRequest.results?.first
        let faceRect = faceObservation?.boundingBox
        let faceYaw = faceObservation?.yaw?.floatValue
        let facePitch = faceObservation?.pitch?.floatValue

        // í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ (ì‹ ë¢°ë„ í¬í•¨)
        let poseKeypoints = extractPoseKeypoints(from: poseDetectionRequest.results?.first)

        // ë°ê¸° ê³„ì‚°
        let brightness = calculateBrightness(cgImage)

        // ê¸°ìš¸ê¸° ê³„ì‚°
        let tiltAngle = calculateTilt(cgImage)

        // ì „ì‹  ì˜ì—­ ì¶”ì • (ì–¼êµ´ ê¸°ì¤€)
        let bodyRect = estimateBodyRect(from: faceRect)

        // ğŸ†• ì¹´ë©”ë¼ ê°ë„ ê°ì§€ (ê°œì„ ëœ ë°©ë²•)
        let cameraAngle = cameraAngleDetector.detectCameraAngle(
            faceRect: faceRect,
            facePitch: facePitch,
            faceObservation: faceObservation
        )

        // ğŸ†• êµ¬ë„ íƒ€ì… ë¶„ë¥˜
        var compositionType: CompositionType? = nil
        if let faceRect = faceRect {
            let subjectPosition = CGPoint(x: faceRect.midX, y: faceRect.midY)
            compositionType = compositionAnalyzer.classifyComposition(subjectPosition: subjectPosition)
        }

        referenceAnalysis = FrameAnalysis(
            faceRect: faceRect,
            bodyRect: bodyRect,
            brightness: brightness,
            tiltAngle: tiltAngle,
            faceYaw: faceYaw,
            facePitch: facePitch,
            cameraAngle: cameraAngle,
            poseKeypoints: poseKeypoints,
            compositionType: compositionType,
            faceObservation: faceObservation
        )

        print("ğŸ“¸ ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„ ì™„ë£Œ:")
        print("   - ì–¼êµ´: \(faceRect != nil ? "ê°ì§€ë¨" : "ì—†ìŒ")")
        print("   - ì–¼êµ´ ê°ë„: yaw=\(faceYaw ?? 0), pitch=\(facePitch ?? 0)")
        print("   - ì¹´ë©”ë¼ ì•µê¸€: \(cameraAngle?.description ?? "ì•Œ ìˆ˜ ì—†ìŒ")")
        print("   - êµ¬ë„: \(compositionType?.description ?? "ì•Œ ìˆ˜ ì—†ìŒ")")
        print("   - í¬ì¦ˆ í‚¤í¬ì¸íŠ¸: \(poseKeypoints?.count ?? 0)ê°œ")
        print("   - ë°ê¸°: \(brightness)")
        print("   - ê¸°ìš¸ê¸°: \(tiltAngle)ë„")
    }

    // MARK: - ì‹¤ì‹œê°„ í”„ë ˆì„ ë¶„ì„
    func analyzeFrame(_ image: UIImage) {
        // ë„ˆë¬´ ìì£¼ ë¶„ì„í•˜ì§€ ì•Šë„ë¡ ì œí•œ
        guard Date().timeIntervalSince(lastAnalysisTime) >= analysisInterval else { return }

        // ë ˆí¼ëŸ°ìŠ¤ê°€ ì—†ìœ¼ë©´ ë¶„ì„í•˜ì§€ ì•ŠìŒ (ì¤‘ìš”!)
        guard let reference = referenceAnalysis else {
            // ë ˆí¼ëŸ°ìŠ¤ ì—†ìœ¼ë©´ í”¼ë“œë°± ì´ˆê¸°í™”
            DispatchQueue.main.async {
                self.instantFeedback = []
                self.perfectScore = 0.0
                self.isPerfect = false
            }
            return
        }

        guard let cgImage = image.cgImage else { return }

        lastAnalysisTime = Date()

        // ë¹ ë¥¸ Vision ë¶„ì„
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        try? handler.perform([faceDetectionRequest, poseDetectionRequest])

        let faceObservation = faceDetectionRequest.results?.first
        let currentFaceRect = faceObservation?.boundingBox
        let currentFaceYaw = faceObservation?.yaw?.floatValue
        let currentFacePitch = faceObservation?.pitch?.floatValue
        let currentBodyRect = estimateBodyRect(from: currentFaceRect)
        let currentTilt = calculateTilt(cgImage)
        let currentPoseKeypoints = extractPoseKeypoints(from: poseDetectionRequest.results?.first)
        // ğŸ†• ê°œì„ ëœ ì¹´ë©”ë¼ ì•µê¸€ ê°ì§€
        let currentCameraAngle = cameraAngleDetector.detectCameraAngle(
            faceRect: currentFaceRect,
            facePitch: currentFacePitch,
            faceObservation: faceObservation
        )

        var feedback: [FeedbackItem] = []

        // 1ìˆœìœ„: í”„ë ˆì´ë° (ê±°ë¦¬ ê¸°ë°˜) í”¼ë“œë°±
        if let refBody = reference.bodyRect, let curBody = currentBodyRect {
            let refSize = refBody.width * refBody.height
            let curSize = curBody.width * curBody.height
            let sizeRatio = curSize / refSize

            // ê±°ë¦¬ ê¸°ë°˜ í”¼ë“œë°± (ì¤Œì´ ì•„ë‹Œ ê±¸ìŒ ìˆ˜)
            if sizeRatio < 0.7 {  // í”¼ì‚¬ì²´ê°€ ì‘ìŒ â†’ ê°€ê¹Œì´ ê°€ì•¼ í•¨
                let distanceFactor = 1.0 / sizeRatio
                let estimatedDistanceM: CGFloat = 2.5  // í‰ê·  ì´¬ì˜ ê±°ë¦¬
                let distanceChangeM = estimatedDistanceM * (distanceFactor - 1.0)
                let steps = max(1, Int(round(distanceChangeM / 0.7)))  // 0.7m per step

                feedback.append(FeedbackItem(
                    priority: 1,
                    icon: "ğŸš¶",
                    message: "\(steps)ê±¸ìŒ ì•ìœ¼ë¡œ",
                    category: "distance_closer",
                    currentValue: Double(curSize * 100),
                    targetValue: Double(refSize * 100),
                    tolerance: 10.0,
                    unit: "%"
                ))
            } else if sizeRatio > 1.4 {  // í”¼ì‚¬ì²´ê°€ í¼ â†’ ë©€ë¦¬ ê°€ì•¼ í•¨
                let distanceFactor = sizeRatio
                let estimatedDistanceM: CGFloat = 2.5
                let distanceChangeM = estimatedDistanceM * (distanceFactor - 1.0)
                let steps = max(1, Int(round(distanceChangeM / 0.7)))

                feedback.append(FeedbackItem(
                    priority: 1,
                    icon: "ğŸš¶",
                    message: "\(steps)ê±¸ìŒ ë’¤ë¡œ",
                    category: "distance_farther",
                    currentValue: Double(curSize * 100),
                    targetValue: Double(refSize * 100),
                    tolerance: 10.0,
                    unit: "%"
                ))
            }
        }

        // 2ìˆœìœ„: êµ¬ë„ (ìœ„ì¹˜) í”¼ë“œë°±
        if let refFace = reference.faceRect, let curFace = currentFaceRect {
            let xDiff = (curFace.midX - refFace.midX) * 100
            let yDiff = (curFace.midY - refFace.midY) * 100

            if abs(xDiff) > 5 {  // 5% ì´ìƒ ì°¨ì´
                let direction = xDiff > 0 ? "ì™¼ìª½ìœ¼ë¡œ" : "ì˜¤ë¥¸ìª½ìœ¼ë¡œ"
                feedback.append(FeedbackItem(
                    priority: 2,
                    icon: "â†”ï¸",
                    message: "\(direction) ì´ë™",
                    category: "position_x",
                    currentValue: Double(curFace.midX * 100),
                    targetValue: Double(refFace.midX * 100),
                    tolerance: 5.0,
                    unit: "%"
                ))
            }

            if abs(yDiff) > 5 {
                let direction = yDiff > 0 ? "ì•„ë˜ë¡œ" : "ìœ„ë¡œ"
                feedback.append(FeedbackItem(
                    priority: 2,
                    icon: "â†•ï¸",
                    message: "\(direction) ì´ë™",
                    category: "position_y",
                    currentValue: Double(curFace.midY * 100),
                    targetValue: Double(refFace.midY * 100),
                    tolerance: 5.0,
                    unit: "%"
                ))
            }
        }

        // 3ìˆœìœ„: ê¸°ìš¸ê¸° í”¼ë“œë°±
        let tiltDiff = currentTilt - reference.tiltAngle
        if abs(tiltDiff) > 3 {
            let direction = tiltDiff > 0 ? "ì™¼ìª½" : "ì˜¤ë¥¸ìª½"
            feedback.append(FeedbackItem(
                priority: 3,
                icon: "ğŸ“",
                message: "\(direction)ìœ¼ë¡œ íšŒì „",
                category: "tilt",
                currentValue: Double(currentTilt),
                targetValue: Double(reference.tiltAngle),
                tolerance: 3.0,
                unit: "ë„"
            ))
        }

        // 4ìˆœìœ„: ì–¼êµ´ ê°ë„ í”¼ë“œë°±
        if let refYaw = reference.faceYaw, let curYaw = currentFaceYaw {
            let yawDiff = (curYaw - refYaw) * 180 / .pi  // ë¼ë””ì•ˆ â†’ ë„
            if abs(yawDiff) > 10 {  // 10ë„ ì´ìƒ ì°¨ì´
                let direction = yawDiff > 0 ? "ì™¼ìª½" : "ì˜¤ë¥¸ìª½"
                feedback.append(FeedbackItem(
                    priority: 4,
                    icon: "ğŸ‘¤",
                    message: "ì–¼êµ´ì„ \(direction)ìœ¼ë¡œ",
                    category: "face_yaw",
                    currentValue: Double(curYaw * 180 / .pi),
                    targetValue: Double(refYaw * 180 / .pi),
                    tolerance: 10.0,
                    unit: "ë„"
                ))
            }
        }

        // 5ìˆœìœ„: ì¹´ë©”ë¼ ê°ë„ í”¼ë“œë°± (ğŸ†• ê°œì„ )
        if let refAngle = reference.cameraAngle, let curAngle = currentCameraAngle {
            if !cameraAngleDetector.compareAngles(reference: refAngle, current: curAngle) {
                if let message = cameraAngleDetector.generateAngleFeedback(reference: refAngle, current: curAngle) {
                    feedback.append(FeedbackItem(
                        priority: 5,
                        icon: "ğŸ“·",
                        message: message,
                        category: "camera_angle",
                        currentValue: nil,
                        targetValue: nil,
                        tolerance: nil,
                        unit: nil
                    ))
                }
            }
        }

        // 6ìˆœìœ„: í¬ì¦ˆ í”¼ë“œë°± (ğŸ†• ì ì‘í˜• ë¹„êµ)
        if let refPose = reference.poseKeypoints, let curPose = currentPoseKeypoints {
            if refPose.count >= 17 && curPose.count >= 17 {
                // ì ì‘í˜• í¬ì¦ˆ ë¹„êµ (ë¶€ë¶„ í¬ì¦ˆ ëŒ€ì‘)
                let comparisonResult = poseComparator.comparePoses(
                    referenceKeypoints: refPose,
                    currentKeypoints: curPose
                )

                // í¬ì¦ˆ í”¼ë“œë°± ìƒì„±
                let poseFeedbacks = poseComparator.generateFeedback(from: comparisonResult)
                for (message, category) in poseFeedbacks {
                    feedback.append(FeedbackItem(
                        priority: 6,
                        icon: "ğŸ’ª",
                        message: message,
                        category: category,
                        currentValue: nil,
                        targetValue: nil,
                        tolerance: nil,
                        unit: nil
                    ))
                }
            }
        }

        // íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ ì ìš©: ì—°ì†ìœ¼ë¡œ ê°ì§€ëœ í”¼ë“œë°±ë§Œ í‘œì‹œ
        var stableFeedback: [FeedbackItem] = []
        var currentCategories = Set<String>()

        for fb in feedback {
            currentCategories.insert(fb.category)
            feedbackHistory[fb.category, default: 0] += 1

            // íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ ì„ê³„ê°’ ë„˜ìœ¼ë©´ í‘œì‹œ
            if feedbackHistory[fb.category]! >= historyThreshold {
                stableFeedback.append(fb)
            }
        }

        // ì‚¬ë¼ì§„ ì¹´í…Œê³ ë¦¬ëŠ” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        for (category, _) in feedbackHistory {
            if !currentCategories.contains(category) {
                feedbackHistory[category] = 0
            }
        }

        // ì™„ë²½í•œ ìƒíƒœ ê°ì§€
        let score = calculatePerfectScore(feedback: feedback)
        let isCurrentlyPerfect = stableFeedback.isEmpty && score > 0.95

        if isCurrentlyPerfect {
            perfectFrameCount += 1
        } else {
            perfectFrameCount = 0
        }

        // ì¦‰ì‹œ í”¼ë“œë°± ì—…ë°ì´íŠ¸
        DispatchQueue.main.async {
            self.instantFeedback = stableFeedback
            self.perfectScore = score
            self.isPerfect = self.perfectFrameCount >= self.perfectThreshold
        }
    }

    // MARK: - Helper Functions

    private func calculatePerfectScore(feedback: [FeedbackItem]) -> Double {
        // í”¼ë“œë°±ì´ ì—†ìœ¼ë©´ ì™„ë²½
        if feedback.isEmpty {
            return 1.0
        }

        // ê° í”¼ë“œë°±ì˜ ì™„ì„±ë„ ê³„ì‚°
        var totalScore = 0.0
        var count = 0

        for fb in feedback {
            if let current = fb.currentValue,
               let target = fb.targetValue {
                let diff = abs(current - target)
                let maxDiff = max(abs(target) + 50, 100.0)  // ìµœëŒ€ ì°¨ì´
                let itemScore = max(0.0, 1.0 - (diff / maxDiff))
                totalScore += itemScore
                count += 1
            }
        }

        if count == 0 {
            return 0.0
        }

        // í‰ê·  ì ìˆ˜
        return totalScore / Double(count)
    }

    private func calculateBrightness(_ cgImage: CGImage) -> Float {
        // ê°„ë‹¨í•œ ë°ê¸° ê³„ì‚° (ìƒ˜í”Œë§)
        let width = min(cgImage.width, 100)  // ìƒ˜í”Œë§ìœ¼ë¡œ ì†ë„ í–¥ìƒ
        let height = min(cgImage.height, 100)

        guard let context = CGContext(
            data: nil,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: width * 4,
            space: CGColorSpaceCreateDeviceRGB(),
            bitmapInfo: CGImageAlphaInfo.premultipliedLast.rawValue
        ) else { return 0.5 }

        context.draw(cgImage, in: CGRect(x: 0, y: 0, width: width, height: height))
        guard let data = context.data else { return 0.5 }

        let buffer = data.bindMemory(to: UInt8.self, capacity: width * height * 4)
        var totalBrightness: Float = 0

        for i in stride(from: 0, to: width * height * 4, by: 4) {
            let r = Float(buffer[i]) / 255.0
            let g = Float(buffer[i + 1]) / 255.0
            let b = Float(buffer[i + 2]) / 255.0
            totalBrightness += (r + g + b) / 3.0
        }

        return totalBrightness / Float(width * height)
    }

    private func calculateTilt(_ cgImage: CGImage) -> Float {
        // ê°„ë‹¨í•œ ê¸°ìš¸ê¸° ì¶”ì • (ì—£ì§€ ê²€ì¶œ ê¸°ë°˜)
        // ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ í•„ìš”í•˜ì§€ë§Œ ì†ë„ë¥¼ ìœ„í•´ ê°„ë‹¨í•˜ê²Œ
        return 0.0  // TODO: êµ¬í˜„ í•„ìš”
    }

    private func estimateBodyRect(from faceRect: CGRect?) -> CGRect? {
        // ì–¼êµ´ ìœ„ì¹˜ë¡œë¶€í„° ì „ì‹  ì˜ì—­ ì¶”ì •
        guard let face = faceRect else { return nil }

        // ì¼ë°˜ì ìœ¼ë¡œ ì–¼êµ´ì´ ì „ì‹ ì˜ 1/7 ì •ë„
        let bodyWidth = face.width * 3
        let bodyHeight = face.height * 7
        let bodyX = face.midX - bodyWidth / 2
        let bodyY = face.minY  // ì–¼êµ´ ì•„ë˜ë¡œ í™•ì¥

        return CGRect(x: bodyX, y: bodyY, width: bodyWidth, height: bodyHeight)
    }

    // MARK: - í¬ì¦ˆ ë° ê°ë„ ë¶„ì„ í—¬í¼

    // ğŸ†• ì‹ ë¢°ë„ í¬í•¨ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
    private func extractPoseKeypoints(from observation: VNHumanBodyPoseObservation?) -> [(point: CGPoint, confidence: Float)]? {
        guard let observation = observation else { return nil }

        var keypoints: [(point: CGPoint, confidence: Float)] = []

        // VNHumanBodyPoseObservationì˜ ì£¼ìš” í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
        let jointNames: [VNHumanBodyPoseObservation.JointName] = [
            .nose,           // 0: ì½”
            .leftEye,        // 1: ì™¼ìª½ ëˆˆ
            .rightEye,       // 2: ì˜¤ë¥¸ìª½ ëˆˆ
            .leftEar,        // 3: ì™¼ìª½ ê·€
            .rightEar,       // 4: ì˜¤ë¥¸ìª½ ê·€
            .leftShoulder,   // 5: ì™¼ìª½ ì–´ê¹¨
            .rightShoulder,  // 6: ì˜¤ë¥¸ìª½ ì–´ê¹¨
            .leftElbow,      // 7: ì™¼ìª½ íŒ”ê¿ˆì¹˜
            .rightElbow,     // 8: ì˜¤ë¥¸ìª½ íŒ”ê¿ˆì¹˜
            .leftWrist,      // 9: ì™¼ìª½ ì†ëª©
            .rightWrist,     // 10: ì˜¤ë¥¸ìª½ ì†ëª©
            .leftHip,        // 11: ì™¼ìª½ ê³¨ë°˜
            .rightHip,       // 12: ì˜¤ë¥¸ìª½ ê³¨ë°˜
            .leftKnee,       // 13: ì™¼ìª½ ë¬´ë¦
            .rightKnee,      // 14: ì˜¤ë¥¸ìª½ ë¬´ë¦
            .leftAnkle,      // 15: ì™¼ìª½ ë°œëª©
            .rightAnkle      // 16: ì˜¤ë¥¸ìª½ ë°œëª©
        ]

        for jointName in jointNames {
            if let point = try? observation.recognizedPoint(jointName) {
                keypoints.append((point: point.location, confidence: point.confidence))
            } else {
                keypoints.append((point: .zero, confidence: 0.0))  // ê°ì§€ ì‹¤íŒ¨
            }
        }

        return keypoints.isEmpty ? nil : keypoints
    }

    // ğŸ—‘ï¸ êµ¬ì‹ í•¨ìˆ˜ë“¤ ì œê±°ë¨ (ìƒˆ ì»´í¬ë„ŒíŠ¸ë¡œ ëŒ€ì²´)
    // - estimateCameraAngle() â†’ CameraAngleDetector ì‚¬ìš©
    // - comparePoseKeypoints() â†’ AdaptivePoseComparator ì‚¬ìš©
    // - calculateAngle() â†’ AdaptivePoseComparator ë‚´ë¶€ ì‚¬ìš©
}