# ğŸ¤– ONNX ëª¨ë¸ íŒŒì¼ ì •ë³´

## ğŸ“¦ ëª¨ë¸ íŒŒì¼ ëª©ë¡

### 1. RTMPose (í•„ìˆ˜ â­â­â­)

**íŒŒì¼ëª…:** `rtmpose_int8.onnx`
**í¬ê¸°:** 218 MB
**ìœ„ì¹˜:** `ios/TryAngleApp/Models/ONNX/rtmpose_int8.onnx`

**ìš©ë„:**
- 133ê°œ í‚¤í¬ì¸íŠ¸ ê²€ì¶œ (Body 17 + Feet 6 + Face 68 + Left Hand 21 + Right Hand 21)
- ì „ì‹  í¬ì¦ˆ ì¶”ì •

**ì…ë ¥:**
- í˜•ì‹: `float32`
- Shape: `[1, 3, 288, 384]` (NCHW)
- ë²”ìœ„: 0.0 ~ 1.0 (ì •ê·œí™”ëœ RGB)
- ì „ì²˜ë¦¬:
  ```
  mean = [0.485, 0.456, 0.406]
  std = [0.229, 0.224, 0.225]
  normalized_pixel = (pixel / 255.0 - mean) / std
  ```

**ì¶œë ¥:**
- `simcc_x`: Shape `[1, 133, 384]` - xì¢Œí‘œ íˆíŠ¸ë§µ
- `simcc_y`: Shape `[1, 133, 288]` - yì¢Œí‘œ íˆíŠ¸ë§µ
- í›„ì²˜ë¦¬: argmaxë¡œ ìµœëŒ€ê°’ ì¸ë±ìŠ¤ ì¶”ì¶œ â†’ ì¢Œí‘œ ë³€í™˜

**Android ì½”ë“œ ì˜ˆì‹œ:**
```kotlin
// 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
fun preprocessImage(bitmap: Bitmap): FloatArray {
    val resized = Bitmap.createScaledBitmap(bitmap, 384, 288, true)
    val input = FloatArray(1 * 3 * 288 * 384)

    val mean = floatArrayOf(0.485f, 0.456f, 0.406f)
    val std = floatArrayOf(0.229f, 0.224f, 0.225f)

    var idx = 0
    for (c in 0..2) {  // RGB ì±„ë„
        for (h in 0 until 288) {
            for (w in 0 until 384) {
                val pixel = resized.getPixel(w, h)
                val value = when (c) {
                    0 -> Color.red(pixel)
                    1 -> Color.green(pixel)
                    else -> Color.blue(pixel)
                } / 255.0f

                input[idx++] = (value - mean[c]) / std[c]
            }
        }
    }
    return input
}

// 2. ONNX ì¶”ë¡ 
fun detectKeypoints(bitmap: Bitmap): List<Keypoint> {
    val inputTensor = OnnxTensor.createTensor(
        env,
        preprocessImage(bitmap),
        longArrayOf(1, 3, 288, 384)
    )

    val outputs = session.run(mapOf("input" to inputTensor))
    val simccX = outputs[0].value as Array<Array<FloatArray>>  // [1, 133, 384]
    val simccY = outputs[1].value as Array<Array<FloatArray>>  // [1, 133, 288]

    val keypoints = mutableListOf<Keypoint>()
    for (i in 0 until 133) {
        val x = simccX[0][i].argMax() / 384.0f
        val y = simccY[0][i].argMax() / 288.0f
        val conf = (simccX[0][i].max() + simccY[0][i].max()) / 2.0f

        keypoints.add(Keypoint(x, y, conf))
    }

    return keypoints
}

// Helper
fun FloatArray.argMax(): Int {
    var maxIdx = 0
    var maxVal = this[0]
    for (i in 1 until size) {
        if (this[i] > maxVal) {
            maxVal = this[i]
            maxIdx = i
        }
    }
    return maxIdx
}
```

---

### 2. YOLOX (ì˜µì…˜)

**íŒŒì¼ëª…:** `yolox_int8.onnx`
**í¬ê¸°:** 97 MB
**ìœ„ì¹˜:** `ios/TryAngleApp/Models/ONNX/yolox_int8.onnx`

**ìš©ë„:**
- ì‚¬ëŒ ê²€ì¶œ (Person Detection)
- RTMPose ì „ì— ì‚¬ëŒ ì˜ì—­ í¬ë¡­ (ì„±ëŠ¥ ìµœì í™”ìš©)

**ì…ë ¥:**
- í˜•ì‹: `int8` (ì–‘ìí™”ë¨)
- Shape: `[1, 3, 416, 416]`
- ë²”ìœ„: -128 ~ 127

**ì¶œë ¥:**
- Bounding boxes: `[N, 4]` (x1, y1, x2, y2)
- Confidence scores: `[N]`
- Class IDs: `[N]` (0 = person)

**ì‚¬ìš© ì—¬ë¶€:**
- âœ… **ì„±ëŠ¥ ìµœì í™”ê°€ í•„ìš”í•˜ë©´** ì‚¬ìš© (ì‚¬ëŒ ì˜ì—­ë§Œ RTMPoseì— ì „ë‹¬)
- âŒ **ë‹¨ìˆœí™”í•˜ë ¤ë©´** ìƒëµ ê°€ëŠ¥ (ì „ì²´ ì´ë¯¸ì§€ë¥¼ RTMPoseì— ì „ë‹¬)

---

## ğŸš€ Androidì—ì„œ ONNX Runtime ì„¤ì •

### Gradle ì˜ì¡´ì„± ì¶”ê°€

```gradle
// app/build.gradle
android {
    // ...
    packagingOptions {
        pickFirst 'lib/arm64-v8a/libc++_shared.so'
        pickFirst 'lib/armeabi-v7a/libc++_shared.so'
    }
}

dependencies {
    // ONNX Runtime
    implementation 'com.microsoft.onnxruntime:onnxruntime-android:1.17.0'

    // ì´ë¯¸ì§€ ì²˜ë¦¬ (ì˜µì…˜)
    implementation 'org.tensorflow:tensorflow-lite:2.14.0'
    implementation 'org.tensorflow:tensorflow-lite-support:0.4.4'
}
```

### ëª¨ë¸ íŒŒì¼ ë°°ì¹˜

```
app/src/main/
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ rtmpose_int8.onnx    (218MB)
â”‚   â””â”€â”€ yolox_int8.onnx      (97MB, ì˜µì…˜)
â””â”€â”€ java/
    â””â”€â”€ com/yourapp/
        â””â”€â”€ ml/
            â”œâ”€â”€ RTMPoseRunner.kt
            â””â”€â”€ YOLOXDetector.kt
```

### ëª¨ë¸ ë¡œë“œ

```kotlin
class RTMPoseRunner(context: Context) {
    private val env = OrtEnvironment.getEnvironment()
    private val session: OrtSession

    init {
        // assetsì—ì„œ ëª¨ë¸ ë¡œë“œ
        val modelBytes = context.assets.open("rtmpose_int8.onnx").readBytes()
        val sessionOptions = OrtSession.SessionOptions()
        sessionOptions.setIntraOpNumThreads(4)  // CPU ì½”ì–´ ìˆ˜

        session = env.createSession(modelBytes, sessionOptions)
    }

    fun detectPose(bitmap: Bitmap): List<Keypoint> {
        // (ìœ„ì˜ ì½”ë“œ ì°¸ê³ )
    }

    fun close() {
        session.close()
    }
}
```

---

## ğŸ“Š í‚¤í¬ì¸íŠ¸ ì¸ë±ìŠ¤ ë§µ

### Body Keypoints (0-16)
```
0: Nose (ì½”)
1-2: Left/Right Eye (ëˆˆ)
3-4: Left/Right Ear (ê·€)
5-6: Left/Right Shoulder (ì–´ê¹¨)
7-8: Left/Right Elbow (íŒ”ê¿ˆì¹˜)
9-10: Left/Right Wrist (ì†ëª©)
11-12: Left/Right Hip (ì—‰ë©ì´)
13-14: Left/Right Knee (ë¬´ë¦)
15-16: Left/Right Ankle (ë°œëª©)
```

### Feet Keypoints (17-22)
```
17-19: Left Foot (ì™¼ë°œ ë°œê°€ë½ 3ê°œ)
20-22: Right Foot (ì˜¤ë¥¸ë°œ ë°œê°€ë½ 3ê°œ)
```

### Face Keypoints (23-90)
68ê°œ ì–¼êµ´ ëœë“œë§ˆí¬ (ëˆˆì¹, ëˆˆ, ì½”, ì…, ìœ¤ê³½)

### Hand Keypoints (91-132)
```
91-111: Left Hand (ì™¼ì† 21ê°œ ê´€ì ˆ)
112-132: Right Hand (ì˜¤ë¥¸ì† 21ê°œ ê´€ì ˆ)
```

**ì† ê´€ì ˆ êµ¬ì¡°:**
```
ì†ëª©(0) â†’ ì—„ì§€(1-4) â†’ ê²€ì§€(5-8) â†’ ì¤‘ì§€(9-12) â†’ ì•½ì§€(13-16) â†’ ìƒˆë¼(17-20)
```

---

## ğŸ¯ ìƒ· íƒ€ì…ë³„ ì‚¬ìš© í‚¤í¬ì¸íŠ¸

| ìƒ· íƒ€ì… | ì‚¬ìš© í‚¤í¬ì¸íŠ¸ | ì¸ë±ìŠ¤ |
|---------|--------------|--------|
| Extreme Close Up | ì–¼êµ´ + ì† | 0-4, 23-132 |
| Close Up | ë¨¸ë¦¬ + ì–´ê¹¨ + ì–¼êµ´ + ì† | 0-6, 23-132 |
| Medium Shot | ìƒë°˜ì‹  + ì–¼êµ´ + ì† | 0-12, 23-132 |
| American Shot | ë¬´ë¦ ìœ„ + ì–¼êµ´ + ì† | 0-14, 23-132 |
| Full Shot | ì „ì‹  | 0-132 (ì „ë¶€) |

**ì´ìœ :**
- ìƒë°˜ì‹  ìƒ·ì—ì„œ í•˜ë°˜ì‹  í‚¤í¬ì¸íŠ¸ëŠ” ë³´ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ì œì™¸
- ì† ì œìŠ¤ì²˜ê°€ ì¤‘ìš”í•˜ë¯€ë¡œ ì† í‚¤í¬ì¸íŠ¸ëŠ” í•­ìƒ í¬í•¨
- ì–¼êµ´ ë°©í–¥ ë¶„ì„ì„ ìœ„í•´ ì–¼êµ´ í‚¤í¬ì¸íŠ¸ í¬í•¨

---

## âš¡ ì„±ëŠ¥ ìµœì í™” íŒ

### 1. ëª¨ë¸ ì–‘ìí™”
- ì´ë¯¸ `int8` ì–‘ìí™” ì ìš©ë¨
- ì›ë³¸ ëª¨ë¸ ëŒ€ë¹„ **4ë°° ì‘ê³  2~3ë°° ë¹ ë¦„**

### 2. CPU ìµœì í™”
```kotlin
val sessionOptions = OrtSession.SessionOptions()
sessionOptions.setIntraOpNumThreads(4)  // CPU ì½”ì–´ ìˆ˜ë§Œí¼
sessionOptions.setInterOpNumThreads(1)
sessionOptions.setExecutionMode(OrtSession.SessionOptions.ExecutionMode.SEQUENTIAL)
```

### 3. GPU ê°€ì† (ì˜µì…˜)
```kotlin
// NNAPI (Android Neural Networks API)
sessionOptions.addNnapi()

// ë˜ëŠ” GPU Delegate (TensorFlow Liteì™€ í˜¸í™˜)
// ì¶”ê°€ ì˜ì¡´ì„± í•„ìš”
```

### 4. ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ìµœì í™”
```kotlin
// Bitmap.createScaledBitmap() ëŒ€ì‹ 
val matrix = Matrix()
matrix.postScale(384f / bitmap.width, 288f / bitmap.height)
val resized = Bitmap.createBitmap(bitmap, 0, 0, bitmap.width, bitmap.height, matrix, true)
```

### 5. í”„ë ˆì„ ìŠ¤í‚µ
```kotlin
// 30fps â†’ 10fps (3í”„ë ˆì„ë§ˆë‹¤ 1ë²ˆ ë¶„ì„)
var frameCount = 0
fun onCameraFrame(bitmap: Bitmap) {
    if (frameCount++ % 3 == 0) {
        analyzeFrame(bitmap)
    }
}
```

---

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Q1: "Model file too large" ì˜¤ë¥˜
**A:** APK í¬ê¸° ì œí•œ. í•´ê²° ë°©ë²•:
1. Android App Bundle (AAB) ì‚¬ìš©
2. ëª¨ë¸ì„ ì„œë²„ì—ì„œ ë‹¤ìš´ë¡œë“œ
3. ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš© (yolox ì œì™¸)

### Q2: "Out of memory" ì˜¤ë¥˜
**A:** ë©”ëª¨ë¦¬ ë¶€ì¡±. í•´ê²° ë°©ë²•:
```kotlin
// ì¶”ë¡  í›„ ëª…ì‹œì ìœ¼ë¡œ í•´ì œ
inputTensor.close()
outputs.forEach { it.value.close() }

// ë˜ëŠ” use ë¸”ë¡ ì‚¬ìš©
inputTensor.use { tensor ->
    session.run(mapOf("input" to tensor)).use { outputs ->
        // ì²˜ë¦¬
    }
}
```

### Q3: "Inference too slow" (ì¶”ë¡ ì´ ë„ˆë¬´ ëŠë¦¼)
**A:**
1. CPU ìŠ¤ë ˆë“œ ìˆ˜ ì¦ê°€: `setIntraOpNumThreads(4)`
2. ì´ë¯¸ì§€ í¬ê¸° ì¶•ì†Œ: 288Ã—384 â†’ 192Ã—256
3. í”„ë ˆì„ ìŠ¤í‚µ ì ìš© (ìœ„ ì°¸ê³ )
4. NNAPI ì‚¬ìš©

### Q4: í‚¤í¬ì¸íŠ¸ ì¢Œí‘œê°€ ì´ìƒí•¨
**A:** ì¢Œí‘œ ì •ê·œí™” í™•ì¸:
```kotlin
// ì˜¬ë°”ë¥¸ ì •ê·œí™”
val x = xIndex / 384.0f  // 0.0 ~ 1.0
val y = yIndex / 288.0f  // 0.0 ~ 1.0

// í™”ë©´ ì¢Œí‘œë¡œ ë³€í™˜
val screenX = x * screenWidth
val screenY = y * screenHeight
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- **ONNX Runtime Android**: https://onnxruntime.ai/docs/get-started/with-android.html
- **RTMPose ë…¼ë¬¸**: https://arxiv.org/abs/2303.07399
- **iOS êµ¬í˜„**: `ios/TryAngleApp/Services/Analysis/RTMPoseRunner.swift`

---

**ìµœì¢… ì—…ë°ì´íŠ¸:** 2025-11-27
