# ============================================================
# ğŸ”„ TryAngle - Image Comparator
# ë ˆí¼ëŸ°ìŠ¤ vs ì‚¬ìš©ì ì´ë¯¸ì§€ ë¹„êµ + í”¼ë“œë°± ìƒì„±
# ============================================================

import numpy as np
from typing import List, Dict

# ImageAnalyzer import
import sys
from pathlib import Path

ANALYSIS_DIR = Path(__file__).resolve().parent
VERSION3_DIR = ANALYSIS_DIR.parent
PROJECT_ROOT = VERSION3_DIR
while PROJECT_ROOT != PROJECT_ROOT.parent and not ((PROJECT_ROOT / "data").exists() and (PROJECT_ROOT / "src").exists()):
    PROJECT_ROOT = PROJECT_ROOT.parent

if str(VERSION3_DIR) not in sys.path:
    sys.path.append(str(VERSION3_DIR))
if str(ANALYSIS_DIR) not in sys.path:
    sys.path.append(str(ANALYSIS_DIR))

from image_analyzer import ImageAnalyzer

# Pose comparison
try:
    from analysis.pose_analyzer import compare_poses
    POSE_COMPARE_AVAILABLE = True
except ImportError:
    POSE_COMPARE_AVAILABLE = False
    print("âš ï¸ Pose comparison not available")

# EXIF comparison
try:
    from analysis.exif_analyzer import compare_exif
    EXIF_COMPARE_AVAILABLE = True
except ImportError:
    EXIF_COMPARE_AVAILABLE = False
    print("âš ï¸ EXIF comparison not available")

# Quality comparison
try:
    from analysis.quality_analyzer import compare_quality
    QUALITY_COMPARE_AVAILABLE = True
except ImportError:
    QUALITY_COMPARE_AVAILABLE = False
    print("âš ï¸ Quality comparison not available")

# Lighting comparison
try:
    from analysis.lighting_analyzer import compare_lighting
    LIGHTING_COMPARE_AVAILABLE = True
except ImportError:
    LIGHTING_COMPARE_AVAILABLE = False
    print("âš ï¸ Lighting comparison not available")


class ImageComparator:
    """
    ë ˆí¼ëŸ°ìŠ¤ vs ì‚¬ìš©ì ì´ë¯¸ì§€ ë¹„êµ
    í´ëŸ¬ìŠ¤í„° ì •ë³´ + í”½ì…€ ë¶„ì„ ëª¨ë‘ í™œìš©
    """
    
    def __init__(self, reference_path: str, user_path: str):
        print("\n" + "="*60)
        print("ğŸ“¸ ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ë¶„ì„")
        print("="*60)
        self.ref_analyzer = ImageAnalyzer(reference_path)
        self.ref_data = self.ref_analyzer.analyze()
        
        print("\n" + "="*60)
        print("ğŸ“¸ ì‚¬ìš©ì ì´ë¯¸ì§€ ë¶„ì„")
        print("="*60)
        self.user_analyzer = ImageAnalyzer(user_path)
        self.user_data = self.user_analyzer.analyze()
        
    def compare(self) -> Dict:
        """
        ëª¨ë“  ì°¨ì›ì—ì„œ ë¹„êµ
        """

        return {
            "cluster_comparison": self._compare_clusters(),
            "pose_comparison": self._compare_pose(),
            "exif_comparison": self._compare_exif(),
            "quality_comparison": self._compare_quality(),
            "lighting_comparison": self._compare_lighting(),
            "depth_comparison": self._compare_depth(),
            "brightness_comparison": self._compare_brightness(),
            "color_comparison": self._compare_color(),
            "composition_comparison": self._compare_composition(),
        }
    
    def _compare_clusters(self) -> Dict:
        """í´ëŸ¬ìŠ¤í„° ë¹„êµ (ìŠ¤íƒ€ì¼ DNA)"""
        ref_cluster = self.ref_data["cluster"]["cluster_id"]
        user_cluster = self.user_data["cluster"]["cluster_id"]
        
        same_style = (ref_cluster == user_cluster)
        
        # ì„ë² ë”© ê±°ë¦¬ ê³„ì‚° (128D)
        ref_emb = self.ref_data["cluster"]["embedding_128d"]
        user_emb = self.user_data["cluster"]["embedding_128d"]
        embedding_distance = float(np.linalg.norm(ref_emb - user_emb))
        
        return {
            "same_cluster": same_style,
            "reference_cluster": ref_cluster,
            "user_cluster": user_cluster,
            "reference_label": self.ref_data["cluster"]["cluster_label"],
            "user_label": self.user_data["cluster"]["cluster_label"],
            "embedding_distance": embedding_distance,
            "style_match": "similar" if embedding_distance < 0.5 else "different"
        }
    
    def _compare_depth(self) -> Dict:
        """ê±°ë¦¬ ë¹„êµ (MiDaS)"""
        ref_depth = self.ref_data["depth"]["depth_mean"]
        user_depth = self.user_data["depth"]["depth_mean"]

        depth_ratio = user_depth / (ref_depth + 1e-8)

        # í”¼ë“œë°± ê³„ì‚° (êµ¬ì²´ì ì¸ ê±¸ìŒìˆ˜ í¬í•¨)
        if depth_ratio > 1.15:  # 15% ì´ìƒ ì°¨ì´
            percent_diff = int((depth_ratio - 1) * 100)

            # ê±¸ìŒìˆ˜ ê³„ì‚° (í‰ê·  ê±¸ìŒ 70cm, ì¼ë°˜ ì´¬ì˜ê±°ë¦¬ 2-3m ê°€ì •)
            estimated_distance_m = 2.5  # í‰ê·  ì´¬ì˜ ê±°ë¦¬
            distance_change_m = estimated_distance_m * (depth_ratio - 1)
            steps = max(1, round(distance_change_m / 0.7))  # 0.7m per step

            feedback = f"í”¼ì‚¬ì²´ì— ì•½ {steps}ê±¸ìŒ ë” ê°€ê¹Œì´ ê°€ì„¸ìš” (ì•½ {percent_diff}% ë” ê°€ê¹Œì´)"
            action = "move_closer"
        elif depth_ratio < 0.85:
            percent_diff = int((1 - depth_ratio) * 100)

            # ê±¸ìŒìˆ˜ ê³„ì‚°
            estimated_distance_m = 2.5
            distance_change_m = estimated_distance_m * (1 - depth_ratio)
            steps = max(1, round(distance_change_m / 0.7))

            feedback = f"í”¼ì‚¬ì²´ì—ì„œ ì•½ {steps}ê±¸ìŒ ë’¤ë¡œ ê°€ì„¸ìš” (ì•½ {percent_diff}% ë” ë©€ë¦¬)"
            action = "move_away"
        else:
            feedback = "ê±°ë¦¬ëŠ” ì ì ˆí•©ë‹ˆë‹¤"
            action = "none"

        return {
            "ref_depth": ref_depth,
            "user_depth": user_depth,
            "ratio": depth_ratio,
            "feedback": feedback,
            "action": action,
            "steps": steps if action != "none" else 0
        }
    
    def _compare_brightness(self) -> Dict:
        """ë°ê¸° ë¹„êµ"""
        ref_brightness = self.ref_data["pixels"]["brightness"]
        user_brightness = self.user_data["pixels"]["brightness"]
        
        diff = user_brightness - ref_brightness
        ev_adjustment = diff / 25.0 * 0.3  # ëŒ€ëµ ë³€í™˜ (ì•½ 25ë°ê¸° = 0.3 EV)
        
        if abs(diff) > 15:
            feedback = f"ë…¸ì¶œì„ {abs(ev_adjustment):.1f} EV {'ì˜¬ë¦¬ì„¸ìš”' if diff < 0 else 'ë‚®ì¶”ì„¸ìš”'}"
            action = "increase_exposure" if diff < 0 else "decrease_exposure"
        else:
            feedback = "ë°ê¸°ëŠ” ì ì ˆí•©ë‹ˆë‹¤"
            action = "none"
        
        return {
            "ref_brightness": ref_brightness,
            "user_brightness": user_brightness,
            "difference": diff,
            "ev_adjustment": ev_adjustment,
            "feedback": feedback,
            "action": action
        }
    
    def _compare_color(self) -> Dict:
        """ìƒ‰ê° ë¹„êµ"""
        ref_saturation = self.ref_data["pixels"]["saturation"]
        user_saturation = self.user_data["pixels"]["saturation"]
        
        ref_temp = self.ref_data["pixels"]["color_temperature"]
        user_temp = self.user_data["pixels"]["color_temperature"]
        
        sat_diff = user_saturation - ref_saturation
        
        feedback_list = []
        
        # ì±„ë„
        if abs(sat_diff) > 0.1:
            percent = abs(sat_diff) * 100
            feedback_list.append(
                f"ì±„ë„ë¥¼ {'ë†’ì´ì„¸ìš”' if sat_diff < 0 else 'ë‚®ì¶”ì„¸ìš”'} (ì•½ {percent:.0f}%)"
            )
        
        # ìƒ‰ì˜¨ë„
        if ref_temp != user_temp:
            if ref_temp == "warm" and user_temp != "warm":
                feedback_list.append("ìƒ‰ê°ì„ ë” ë”°ëœ»í•˜ê²Œ ì¡°ì •í•˜ì„¸ìš” (í™”ì´íŠ¸ë°¸ëŸ°ìŠ¤ ì¡°ì •)")
            elif ref_temp == "cool" and user_temp != "cool":
                feedback_list.append("ìƒ‰ê°ì„ ë” ì°¨ê°‘ê²Œ ì¡°ì •í•˜ì„¸ìš” (í™”ì´íŠ¸ë°¸ëŸ°ìŠ¤ ì¡°ì •)")
        
        if not feedback_list:
            feedback_list = ["ìƒ‰ê°ì€ ì ì ˆí•©ë‹ˆë‹¤"]
        
        return {
            "ref_saturation": ref_saturation,
            "user_saturation": user_saturation,
            "saturation_diff": sat_diff,
            "ref_temperature": ref_temp,
            "user_temperature": user_temp,
            "feedback": feedback_list
        }
    
    def _compare_composition(self) -> Dict:
        """êµ¬ë„ ë¹„êµ (í”„ë ˆì´ë° í¬í•¨)"""
        ref_comp = self.ref_data["composition"]
        user_comp = self.user_data["composition"]

        tilt_diff = user_comp["tilt_angle"] - ref_comp["tilt_angle"]

        feedback_list = []

        # í”„ë ˆì´ë°/ì¤Œ ë¹„êµ (í¬ì¦ˆ bbox í™œìš©)
        if self.ref_data.get("pose") and self.user_data.get("pose"):
            ref_pose = self.ref_data["pose"]
            user_pose = self.user_data["pose"]

            if ref_pose.get("bbox") and user_pose.get("bbox"):
                ref_bbox = ref_pose["bbox"]  # [x1, y1, x2, y2] normalized
                user_bbox = user_pose["bbox"]

                # bbox í¬ê¸° ê³„ì‚°
                ref_width = ref_bbox[2] - ref_bbox[0]
                ref_height = ref_bbox[3] - ref_bbox[1]
                ref_area = ref_width * ref_height

                user_width = user_bbox[2] - user_bbox[0]
                user_height = user_bbox[3] - user_bbox[1]
                user_area = user_width * user_height

                # ì¤Œ ë¹„ìœ¨ ê³„ì‚°
                zoom_ratio = user_area / (ref_area + 1e-8)

                if zoom_ratio < 0.7:  # ì‚¬ìš©ìê°€ ë„ˆë¬´ ì¤Œì•„ì›ƒ
                    zoom_needed = 1 / zoom_ratio
                    percent = int((zoom_needed - 1) * 100)
                    feedback_list.append(f"í™”ë©´ì„ {zoom_needed:.1f}ë°° í™•ëŒ€í•˜ì„¸ìš” (ì¤Œ {percent}% ëŠ˜ë¦¬ê¸°)")

                elif zoom_ratio > 1.4:  # ì‚¬ìš©ìê°€ ë„ˆë¬´ ì¤Œì¸
                    zoom_needed = zoom_ratio
                    percent = int((zoom_needed - 1) * 100)
                    feedback_list.append(f"í™”ë©´ì„ {1/zoom_needed:.1f}ë°° ì¶•ì†Œí•˜ì„¸ìš” (ì¤Œ {percent}% ì¤„ì´ê¸°)")

                # í¬ë¡­ ì œì•ˆ (bbox ìœ„ì¹˜ ë¹„êµ)
                ref_center_x = (ref_bbox[0] + ref_bbox[2]) / 2
                ref_center_y = (ref_bbox[1] + ref_bbox[3]) / 2
                user_center_x = (user_bbox[0] + user_bbox[2]) / 2
                user_center_y = (user_bbox[1] + user_bbox[3]) / 2

                x_shift = user_center_x - ref_center_x
                y_shift = user_center_y - ref_center_y

                if abs(y_shift) > 0.1:
                    percent = abs(int(y_shift * 100))
                    if y_shift > 0:
                        feedback_list.append(f"í”„ë ˆì´ë°: í™”ë©´ ìœ„ìª½ {percent}% ë” í¬í•¨í•˜ì„¸ìš”")
                    else:
                        feedback_list.append(f"í”„ë ˆì´ë°: í™”ë©´ ì•„ë˜ìª½ {percent}% ë” í¬í•¨í•˜ì„¸ìš”")

                if abs(x_shift) > 0.1:
                    percent = abs(int(x_shift * 100))
                    if x_shift > 0:
                        feedback_list.append(f"í”„ë ˆì´ë°: í™”ë©´ ì™¼ìª½ {percent}% ë” í¬í•¨í•˜ì„¸ìš”")
                    else:
                        feedback_list.append(f"í”„ë ˆì´ë°: í™”ë©´ ì˜¤ë¥¸ìª½ {percent}% ë” í¬í•¨í•˜ì„¸ìš”")

        # ê¸°ìš¸ê¸°
        if abs(tilt_diff) > 3:
            feedback_list.append(
                f"ì¹´ë©”ë¼ë¥¼ {'ì™¼ìª½' if tilt_diff > 0 else 'ì˜¤ë¥¸ìª½'}ìœ¼ë¡œ {abs(tilt_diff):.1f}ë„ ê¸°ìš¸ì´ì„¸ìš”"
            )

        # ë¬´ê²Œì¤‘ì‹¬ ë¹„êµ
        ref_center = ref_comp["center_of_mass"]
        user_center = user_comp["center_of_mass"]

        x_diff = user_center["x"] - ref_center["x"]
        y_diff = user_center["y"] - ref_center["y"]

        if abs(x_diff) > 0.15:
            feedback_list.append(
                f"í”¼ì‚¬ì²´ë¥¼ í™”ë©´ì˜ {'ì™¼ìª½' if x_diff > 0 else 'ì˜¤ë¥¸ìª½'}ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”"
            )

        if abs(y_diff) > 0.15:
            feedback_list.append(
                f"í”¼ì‚¬ì²´ë¥¼ í™”ë©´ì˜ {'ìœ„ìª½' if y_diff > 0 else 'ì•„ë˜ìª½'}ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”"
            )

        if not feedback_list:
            feedback_list = ["êµ¬ë„ëŠ” ì ì ˆí•©ë‹ˆë‹¤"]

        return {
            "ref_tilt": ref_comp["tilt_angle"],
            "user_tilt": user_comp["tilt_angle"],
            "tilt_diff": tilt_diff,
            "ref_center": ref_center,
            "user_center": user_center,
            "feedback": feedback_list
        }

    def _compare_pose(self) -> Dict:
        """í¬ì¦ˆ ë¹„êµ (YOLO + MediaPipe)"""
        if not POSE_COMPARE_AVAILABLE:
            return {
                "available": False,
                "feedback": []
            }

        ref_pose = self.ref_data.get("pose")
        user_pose = self.user_data.get("pose")

        if ref_pose is None or user_pose is None:
            return {
                "available": False,
                "feedback": ["í¬ì¦ˆ ë¶„ì„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"]
            }

        # í¬ì¦ˆ ë¹„êµ ì‹¤í–‰
        try:
            comparison = compare_poses(ref_pose, user_pose)
            return {
                "available": True,
                "similarity": comparison["similarity"],
                "angle_differences": comparison.get("angle_differences", {}),
                "position_differences": comparison.get("position_differences", {}),
                "feedback": comparison["feedback"]
            }
        except Exception as e:
            print(f"  âš ï¸ Pose comparison failed: {e}")
            return {
                "available": False,
                "feedback": [f"í¬ì¦ˆ ë¹„êµ ì‹¤íŒ¨: {str(e)}"]
            }

    def _compare_exif(self) -> Dict:
        """EXIF ë¹„êµ (ì¹´ë©”ë¼ ì„¤ì •)"""
        if not EXIF_COMPARE_AVAILABLE:
            return {
                "available": False,
                "feedback": []
            }

        ref_exif_data = self.ref_data.get("exif")
        user_exif_data = self.user_data.get("exif")

        if ref_exif_data is None or user_exif_data is None:
            return {
                "available": False,
                "feedback": ["EXIF ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"]
            }

        ref_settings = ref_exif_data["camera_settings"]
        user_settings = user_exif_data["camera_settings"]

        # EXIF ë¹„êµ ì‹¤í–‰
        try:
            comparison = compare_exif(ref_settings, user_settings)
            return {
                "available": True,
                "has_differences": comparison.get("has_differences", False),
                "iso_diff": comparison.get("iso_diff"),
                "f_number_diff": comparison.get("f_number_diff"),
                "shutter_speed_ratio": comparison.get("shutter_speed_ratio"),
                "focal_length_diff": comparison.get("focal_length_diff"),
                "white_balance_match": comparison.get("white_balance_match"),
                "feedback": comparison["feedback"],
                "ref_settings": ref_settings,
                "user_settings": user_settings
            }
        except Exception as e:
            print(f"  âš ï¸ EXIF comparison failed: {e}")
            return {
                "available": False,
                "feedback": [f"EXIF ë¹„êµ ì‹¤íŒ¨: {str(e)}"]
            }

    def _compare_quality(self) -> Dict:
        """Quality ë¹„êµ (ë…¸ì´ì¦ˆ, ë¸”ëŸ¬, ì„ ëª…ë„, ëŒ€ë¹„)"""
        if not QUALITY_COMPARE_AVAILABLE:
            return {
                "available": False,
                "feedback": []
            }

        ref_quality = self.ref_data.get("quality")
        user_quality = self.user_data.get("quality")

        if ref_quality is None or user_quality is None:
            return {
                "available": False,
                "feedback": []
            }

        # Quality ë¹„êµ ì‹¤í–‰ (ìƒëŒ€ì  í‰ê°€ ê¸°ë°˜)
        try:
            comparison = compare_quality(ref_quality, user_quality)
            return comparison
        except Exception as e:
            print(f"  âš ï¸ Quality comparison failed: {e}")
            return {
                "available": False,
                "feedback": []
            }

    def _compare_lighting(self) -> Dict:
        """Lighting ë¹„êµ (ì¡°ëª… ë°©í–¥, ì—­ê´‘, HDR)"""
        if not LIGHTING_COMPARE_AVAILABLE:
            return {
                "available": False,
                "feedback": []
            }

        ref_lighting = self.ref_data.get("lighting")
        user_lighting = self.user_data.get("lighting")

        if ref_lighting is None or user_lighting is None:
            return {
                "available": False,
                "feedback": []
            }

        # Lighting ë¹„êµ ì‹¤í–‰
        try:
            comparison = compare_lighting(ref_lighting, user_lighting)
            return comparison
        except Exception as e:
            print(f"  âš ï¸ Lighting comparison failed: {e}")
            return {
                "available": False,
                "feedback": []
            }

    def get_prioritized_feedback(self) -> List[Dict]:
        """
        ìš°ì„ ìˆœìœ„ì— ë”°ë¼ í”¼ë“œë°± ì •ë ¬
        0ìˆœìœ„: í´ëŸ¬ìŠ¤í„° (ì •ë³´ì„±)
        0.5ìˆœìœ„: í¬ì¦ˆ (ë§¤ìš° ì¤‘ìš”!)
        1ìˆœìœ„: ì¹´ë©”ë¼ ì„¤ì • (EXIF)
        2ìˆœìœ„: ê±°ë¦¬ (depth)
        3ìˆœìœ„: ë°ê¸°
        4ìˆœìœ„: ìƒ‰ê°
        5ìˆœìœ„: êµ¬ë„
        """
        comparison = self.compare()

        feedback_list = []

        # 0ìˆœìœ„: í´ëŸ¬ìŠ¤í„° (ì •ë³´ì„±)
        cluster_comp = comparison["cluster_comparison"]
        if not cluster_comp["same_cluster"]:
            feedback_list.append({
                "priority": 0,
                "category": "style",
                "message": f"âš ï¸ ìŠ¤íƒ€ì¼ì´ ë‹¤ë¦…ë‹ˆë‹¤",
                "detail": (
                    f"ë ˆí¼ëŸ°ìŠ¤: Cluster {cluster_comp['reference_cluster']} - {cluster_comp['reference_label']}\n"
                    f"     ì‚¬ìš©ì: Cluster {cluster_comp['user_cluster']} - {cluster_comp['user_label']}"
                )
            })
        else:
            feedback_list.append({
                "priority": 0,
                "category": "style",
                "message": f"âœ… ê°™ì€ ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤ (Cluster {cluster_comp['reference_cluster']})",
                "detail": f"{cluster_comp['reference_label']}"
            })

        # 0.5ìˆœìœ„: í¬ì¦ˆ (ë§¤ìš° ì¤‘ìš”!)
        pose_comp = comparison["pose_comparison"]
        if pose_comp["available"] and pose_comp["feedback"]:
            if pose_comp["feedback"][0] != "âœ… í¬ì¦ˆê°€ ì ì ˆí•©ë‹ˆë‹¤":
                for fb in pose_comp["feedback"]:
                    similarity = pose_comp.get("similarity", 0.0)
                    feedback_list.append({
                        "priority": 0.5,
                        "category": "pose",
                        "message": fb,
                        "detail": f"í¬ì¦ˆ ìœ ì‚¬ë„: {similarity:.2%}"
                    })
            else:
                # í¬ì¦ˆê°€ ì ì ˆí•œ ê²½ìš°
                similarity = pose_comp.get("similarity", 1.0)
                feedback_list.append({
                    "priority": 0.5,
                    "category": "pose",
                    "message": "âœ… í¬ì¦ˆê°€ ì ì ˆí•©ë‹ˆë‹¤",
                    "detail": f"ìœ ì‚¬ë„: {similarity:.2%}"
                })

        # 1ìˆœìœ„: ì¹´ë©”ë¼ ì„¤ì • (EXIF)
        exif_comp = comparison["exif_comparison"]
        if exif_comp["available"] and exif_comp.get("has_differences", False):
            for fb in exif_comp["feedback"]:
                feedback_list.append({
                    "priority": 1,
                    "category": "camera_settings",
                    "message": fb,
                    "detail": "ì¹´ë©”ë¼ ì„¤ì •ì„ ì¡°ì •í•˜ì„¸ìš”"
                })

        # Quality: ë™ì  ìš°ì„ ìˆœìœ„ (0.5~8.0)
        quality_comp = comparison["quality_comparison"]
        if quality_comp["available"] and quality_comp["feedback"]:
            for fb_item in quality_comp["feedback"]:
                # fb_item = {category, ref_value, user_value, difference_percent,
                #           direction, is_critical, is_style, message, adjustment,
                #           adjustment_numeric, priority}
                feedback_list.append({
                    "priority": fb_item["priority"],
                    "category": fb_item["category"],
                    "message": fb_item["message"],
                    "detail": fb_item["adjustment"]
                })

        # Lighting: ë™ì  ìš°ì„ ìˆœìœ„ (4~8)
        lighting_comp = comparison["lighting_comparison"]
        if lighting_comp.get("available", False) and lighting_comp.get("has_issues", False):
            for fb_item in lighting_comp["feedback"]:
                # fb_item = {category, priority, message, detail, adjustment, adjustment_numeric}
                feedback_list.append({
                    "priority": fb_item["priority"],
                    "category": fb_item["category"],
                    "message": fb_item["message"],
                    "detail": fb_item["adjustment"]
                })

        # 2ìˆœìœ„: ê±°ë¦¬
        depth_comp = comparison["depth_comparison"]
        if depth_comp["action"] != "none":
            feedback_list.append({
                "priority": 2,
                "category": "distance",
                "message": depth_comp["feedback"],
                "detail": f"ë ˆí¼ëŸ°ìŠ¤ depth={depth_comp['ref_depth']:.1f}, í˜„ì¬={depth_comp['user_depth']:.1f} (ë¹„ìœ¨: {depth_comp['ratio']:.2f})"
            })

        # 3ìˆœìœ„: ë°ê¸°
        brightness_comp = comparison["brightness_comparison"]
        if brightness_comp["action"] != "none":
            feedback_list.append({
                "priority": 3,
                "category": "exposure",
                "message": brightness_comp["feedback"],
                "detail": f"ë ˆí¼ëŸ°ìŠ¤ ë°ê¸°={brightness_comp['ref_brightness']:.1f}, í˜„ì¬={brightness_comp['user_brightness']:.1f} (ì°¨ì´: {brightness_comp['difference']:.1f})"
            })

        # 4ìˆœìœ„: ìƒ‰ê°
        color_comp = comparison["color_comparison"]
        if color_comp["feedback"][0] != "ìƒ‰ê°ì€ ì ì ˆí•©ë‹ˆë‹¤":
            for fb in color_comp["feedback"]:
                feedback_list.append({
                    "priority": 4,
                    "category": "color",
                    "message": fb,
                    "detail": f"ë ˆí¼ëŸ°ìŠ¤ ì±„ë„={color_comp['ref_saturation']:.2f}, í˜„ì¬={color_comp['user_saturation']:.2f} (ì°¨ì´: {color_comp['saturation_diff']:.2f})"
                })

        # 5ìˆœìœ„: êµ¬ë„
        comp_comp = comparison["composition_comparison"]
        if comp_comp["feedback"][0] != "êµ¬ë„ëŠ” ì ì ˆí•©ë‹ˆë‹¤":
            for fb in comp_comp["feedback"]:
                feedback_list.append({
                    "priority": 5,
                    "category": "composition",
                    "message": fb,
                    "detail": f"ê¸°ìš¸ê¸° ì°¨ì´={comp_comp['tilt_diff']:.1f}ë„"
                })
        
        # ìš°ì„ ìˆœìœ„ ì •ë ¬
        feedback_list.sort(key=lambda x: x["priority"])
        
        return feedback_list


# ============================================================
# í…ŒìŠ¤íŠ¸
# ============================================================
if __name__ == "__main__":
    ref_path = PROJECT_ROOT / "data" / "test_images" / "test1.jpg"
    user_path = PROJECT_ROOT / "data" / "test_images" / "test1.jpg"  # ê°™ì€ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
    
    try:
        comparator = ImageComparator(str(ref_path), str(user_path))
        feedback = comparator.get_prioritized_feedback()
        
        print("\n" + "="*60)
        print("ğŸ“‹ ì´¬ì˜ ê°€ì´ë“œ")
        print("="*60)
        
        for i, fb in enumerate(feedback, 1):
            print(f"\n{i}. [{fb['category'].upper()}]")
            print(f"   {fb['message']}")
            print(f"   â”” {fb['detail']}")
        
        print("\n" + "="*60)
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
