# ============================================================
# ğŸ¯ TryAngle - Image Analyzer
# ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„: í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ + ì¸¡ì • ê°€ëŠ¥í•œ ê°’ ì¶”ì¶œ
# ============================================================

import os
import json
import cv2
import numpy as np
from pathlib import Path

# ê¸°ì¡´ ì‹œìŠ¤í…œ import
import sys

VERSION3_DIR = Path(__file__).resolve().parents[1]
PROJECT_ROOT = VERSION3_DIR
while PROJECT_ROOT != PROJECT_ROOT.parent and not ((PROJECT_ROOT / "data").exists() and (PROJECT_ROOT / "src").exists()):
    PROJECT_ROOT = PROJECT_ROOT.parent

if str(VERSION3_DIR) not in sys.path:
    sys.path.append(str(VERSION3_DIR))

from feature_extraction.feature_extractor_v2 import extract_features_v2 as extract_features_full
from matching.cluster_matcher import match_cluster_from_features

# Phase 1.3: Feature Cache
try:
    utils_dir = VERSION3_DIR / "utils"
    if str(utils_dir) not in sys.path:
        sys.path.append(str(utils_dir))
    from feature_cache import CachedFeatureExtractor
    FEATURE_CACHE_AVAILABLE = True
except ImportError:
    FEATURE_CACHE_AVAILABLE = False
    print("âš ï¸ Feature Cache not available (Phase 1.3)")

# í¬ì¦ˆ ë¶„ì„
try:
    from analysis.pose_analyzer import PoseAnalyzer
    POSE_AVAILABLE = True
except ImportError:
    print("âš ï¸ PoseAnalyzer not available. Install: pip install ultralytics mediapipe")
    POSE_AVAILABLE = False

# EXIF ë¶„ì„
try:
    from analysis.exif_analyzer import ExifAnalyzer
    EXIF_AVAILABLE = True
except ImportError:
    print("âš ï¸ ExifAnalyzer not available")
    EXIF_AVAILABLE = False

# í’ˆì§ˆ ë¶„ì„
try:
    from analysis.quality_analyzer import QualityAnalyzer
    QUALITY_AVAILABLE = True
except ImportError:
    print("âš ï¸ QualityAnalyzer not available")
    QUALITY_AVAILABLE = False

# ì¡°ëª… ë¶„ì„
try:
    from analysis.lighting_analyzer import LightingAnalyzer
    LIGHTING_AVAILABLE = True
except ImportError:
    print("âš ï¸ LightingAnalyzer not available")
    LIGHTING_AVAILABLE = False


class ImageAnalyzer:
    """
    í•œ ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì„œ:
    1) í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ (ìŠ¤íƒ€ì¼ DNA)
    2) ì¸¡ì • ê°€ëŠ¥í•œ ê°’ë“¤ ì¶”ì¶œ (ë¹„êµìš©)
    """
    
    def __init__(self, image_path: str, enable_pose: bool = True, enable_exif: bool = True, enable_quality: bool = True, enable_lighting: bool = True, use_movenet: bool = False):
        """
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            enable_pose: í¬ì¦ˆ ë¶„ì„ í™œì„±í™”
            enable_exif: EXIF ë¶„ì„ í™œì„±í™”
            enable_quality: í’ˆì§ˆ ë¶„ì„ í™œì„±í™”
            enable_lighting: ì¡°ëª… ë¶„ì„ í™œì„±í™”
            use_movenet: Trueë©´ MoveNet ì‚¬ìš©, Falseë©´ YOLO11 ì‚¬ìš© (Phase 2-4)
        """
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"âŒ Image not found: {image_path}")

        self.image_path = image_path
        self.enable_pose = enable_pose and POSE_AVAILABLE
        self.enable_exif = enable_exif and EXIF_AVAILABLE
        self.enable_quality = enable_quality and QUALITY_AVAILABLE
        self.enable_lighting = enable_lighting and LIGHTING_AVAILABLE
        self.use_movenet = use_movenet  # Phase 2-4: MoveNet ì˜µì…˜

        # ==========================================
        # Step 1: Feature ì¶”ì¶œ (ëª¨ë“  ëª¨ë¸ ì‚¬ìš©)
        # ==========================================
        print(f"  ğŸ”§ Extracting features from {os.path.basename(image_path)}...")

        # Phase 1.3: Feature Cache ì‚¬ìš©
        if FEATURE_CACHE_AVAILABLE:
            cache_dir = VERSION3_DIR / "cache" / "features"
            cached_extractor = CachedFeatureExtractor(cache_dir=str(cache_dir))
            self.features = cached_extractor.extract(image_path)
        else:
            # Fallback: ì§ì ‘ ì¶”ì¶œ
            self.features = extract_features_full(image_path)

        if self.features is None:
            raise RuntimeError("âŒ Feature extraction failed!")

        # ==========================================
        # Step 2: í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ (ìŠ¤íƒ€ì¼ DNA ì°¾ê¸°)
        # ==========================================
        self.cluster_result = match_cluster_from_features(self.features)

        # ==========================================
        # Step 3: í´ëŸ¬ìŠ¤í„° íŠ¹ì„± ë¡œë“œ (ì§‘ë‹¨ì§€ì„±)
        # ==========================================
        cluster_info_path = PROJECT_ROOT / "features" / "cluster_interpretation.json"
        with open(cluster_info_path, "r", encoding="utf-8") as f:
            cluster_info = json.load(f)

        self.cluster_data = cluster_info[str(self.cluster_result["cluster_id"])]

        print(f"  âœ… Cluster {self.cluster_result['cluster_id']}: {self.cluster_data['auto_label']}")

        # ==========================================
        # Step 4: PoseAnalyzer ì´ˆê¸°í™” (lazy loading)
        # ==========================================
        self.pose_analyzer = None
        if self.enable_pose:
            try:
                # Phase 2-4: MoveNet ì˜µì…˜ ì „ë‹¬
                self.pose_analyzer = PoseAnalyzer(use_movenet=self.use_movenet)
                model_name = "MoveNet" if self.use_movenet else "YOLO11"
                print(f"  âœ… PoseAnalyzer ready (using {model_name})")
            except Exception as e:
                print(f"  âš ï¸ PoseAnalyzer initialization failed: {e}")
                self.enable_pose = False

        # ==========================================
        # Step 5: EXIF Analyzer ì´ˆê¸°í™”
        # ==========================================
        self.exif_analyzer = None
        if self.enable_exif:
            try:
                self.exif_analyzer = ExifAnalyzer(image_path)
                if self.exif_analyzer.has_exif():
                    print(f"  âœ… EXIF: {len(self.exif_analyzer.exif_data)} fields")
                else:
                    print(f"  âš ï¸ No EXIF data")
            except Exception as e:
                print(f"  âš ï¸ EXIF extraction failed: {e}")
                self.enable_exif = False

        # ==========================================
        # Step 6: Quality Analyzer ì´ˆê¸°í™”
        # ==========================================
        self.quality_analyzer = None
        if self.enable_quality:
            try:
                self.quality_analyzer = QualityAnalyzer(image_path)
                print(f"  âœ… Quality analysis ready")
            except Exception as e:
                print(f"  âš ï¸ Quality analysis failed: {e}")
                self.enable_quality = False

        # ==========================================
        # Step 7: Lighting Analyzer ì´ˆê¸°í™”
        # ==========================================
        self.lighting_analyzer = None
        if self.enable_lighting:
            try:
                # pose_dataì™€ depth_dataëŠ” ë‚˜ì¤‘ì— analyze()ì—ì„œ ì „ë‹¬
                self.lighting_analyzer = LightingAnalyzer(image_path)
                print(f"  âœ… Lighting analysis ready")
            except Exception as e:
                print(f"  âš ï¸ Lighting analysis failed: {e}")
                self.enable_lighting = False
    
    def analyze(self) -> dict:
        """
        ë¹„êµ ê°€ëŠ¥í•œ ëª¨ë“  ì •ë³´ ë°˜í™˜
        """
        
        # ==========================================
        # 1) í´ëŸ¬ìŠ¤í„° ì •ë³´ (ìŠ¤íƒ€ì¼ DNA)
        # ==========================================
        cluster_info = {
            "cluster_id": self.cluster_result["cluster_id"],
            "cluster_label": self.cluster_data["auto_label"],
            "cluster_distance": self.cluster_result["distance"],
            "sample_count": self.cluster_data["sample_count"],
            "embedding_128d": self.cluster_result["raw_embedding"]
        }
        
        # ==========================================
        # 2) MiDaS Depth (ìƒëŒ€ì  ê±°ë¦¬)
        # ==========================================
        # MiDaS featureëŠ” 20Dì§€ë§Œ, depth_meanì€ ì²« ë²ˆì§¸ ê°’ (global mean)
        depth_info = {
            "depth_mean": float(self.features["midas"][0]),  # global mean
            "depth_std": float(self.features["midas"][1]),   # global std
            "cluster_typical_depth": self.cluster_data["depth_mean"],
            "depth_deviation": float(self.features["midas"][0]) - self.cluster_data["depth_mean"]
        }
        
        # ==========================================
        # 3) í”½ì…€ ê¸°ë°˜ ë¶„ì„ (ì§ì ‘ ì¸¡ì •)
        # ==========================================
        pixel_analysis = self._analyze_pixels()
        
        # ==========================================
        # 4) êµ¬ë„ ë¶„ì„
        # ==========================================
        composition_info = self._analyze_composition()

        # ==========================================
        # 5) í¬ì¦ˆ ë¶„ì„ (YOLO + MediaPipe)
        # ==========================================
        pose_info = None
        if self.enable_pose and self.pose_analyzer is not None:
            try:
                pose_info = self.pose_analyzer.analyze(self.image_path)
                print(f"  âœ… Pose: {pose_info['scenario']} (conf={pose_info['confidence']:.2f})")
            except Exception as e:
                print(f"  âš ï¸ Pose analysis failed: {e}")
                pose_info = None

        # ==========================================
        # 6) EXIF ë¶„ì„ (ì¹´ë©”ë¼ ì„¤ì •)
        # ==========================================
        exif_info = None
        if self.enable_exif and self.exif_analyzer is not None and self.exif_analyzer.has_exif():
            exif_info = {
                "camera_settings": self.exif_analyzer.get_camera_settings(),
                "shooting_info": self.exif_analyzer.get_shooting_info()
            }

        # ==========================================
        # 7) Quality ë¶„ì„ (ë…¸ì´ì¦ˆ, ë¸”ëŸ¬, ì„ ëª…ë„, ëŒ€ë¹„)
        # ==========================================
        quality_info = None
        if self.enable_quality and self.quality_analyzer is not None:
            try:
                quality_info = self.quality_analyzer.analyze_all()
                print(f"  âœ… Quality: blur={quality_info['blur']['blur_score']:.1f}, noise={quality_info['noise']['noise_level']:.2f}")
            except Exception as e:
                print(f"  âš ï¸ Quality analysis failed: {e}")
                quality_info = None

        # ==========================================
        # 8) Lighting ë¶„ì„ (ì¡°ëª… ë°©í–¥, ì—­ê´‘, HDR)
        # ==========================================
        lighting_info = None
        if self.enable_lighting and self.lighting_analyzer is not None:
            try:
                # pose_dataì™€ depth_data ì „ë‹¬ (ìˆìœ¼ë©´)
                if pose_info is not None:
                    self.lighting_analyzer.pose_data = pose_info
                if depth_info is not None:
                    # depth_meanì„ depth mapìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ëŠ” ì—†ìœ¼ë¯€ë¡œ, ì¼ë‹¨ None
                    # ì‹¤ì œë¡œëŠ” MiDaSë¡œ depth mapì„ ìƒì„±í•´ì•¼ í•¨
                    pass

                lighting_info = self.lighting_analyzer.analyze_all()
                light_dir = lighting_info['light_direction']['direction']
                backlight = 'ìˆìŒ' if lighting_info['backlight']['is_backlight'] else 'ì—†ìŒ'
                hdr = 'ìˆìŒ' if lighting_info['hdr']['is_hdr'] else 'ì—†ìŒ'
                print(f"  âœ… Lighting: {light_dir} ì¡°ëª…, ì—­ê´‘={backlight}, HDR={hdr}")
            except Exception as e:
                print(f"  âš ï¸ Lighting analysis failed: {e}")
                lighting_info = None

        return {
            "cluster": cluster_info,
            "depth": depth_info,
            "pixels": pixel_analysis,
            "composition": composition_info,
            "pose": pose_info,
            "exif": exif_info,
            "quality": quality_info,
            "lighting": lighting_info,
            "raw_features": self.features
        }
    
    def _analyze_pixels(self) -> dict:
        """í”½ì…€ ì§ì ‘ ë¶„ì„"""
        img = cv2.imread(self.image_path)
        
        # ë°ê¸°
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        brightness = float(np.mean(gray))
        
        # ì±„ë„
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        saturation = float(np.mean(hsv[:,:,1]) / 255.0)
        
        # ì½˜íŠ¸ë¼ìŠ¤íŠ¸
        contrast = float(np.std(gray) / 128.0)
        
        # ìƒ‰ì˜¨ë„
        b, g, r = cv2.split(img)
        r_mean, g_mean, b_mean = np.mean(r), np.mean(g), np.mean(b)
        warm_score = (r_mean + g_mean) / 2
        cool_score = b_mean
        
        if warm_score > cool_score * 1.05:
            color_temp = "warm"
        elif cool_score > warm_score * 1.05:
            color_temp = "cool"
        else:
            color_temp = "neutral"
        
        # íˆìŠ¤í† ê·¸ë¨ ë¶„ì„ (í´ë¦¬í•‘ ê²€ì‚¬)
        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
        total_pixels = gray.shape[0] * gray.shape[1]
        
        highlight_clipping = float(np.sum(hist[250:]) / total_pixels)
        shadow_clipping = float(np.sum(hist[:5]) / total_pixels)
        
        return {
            "brightness": brightness,  # 0~255
            "saturation": saturation,  # 0~1
            "contrast": contrast,      # 0~1
            "color_temperature": color_temp,
            "rgb_ratio": {
                "r": float(r_mean / (g_mean + 1e-8)),
                "g": 1.0,
                "b": float(b_mean / (g_mean + 1e-8))
            },
            "histogram": {
                "highlight_clipping": highlight_clipping,
                "shadow_clipping": shadow_clipping
            }
        }
    
    def _analyze_composition(self) -> dict:
        """êµ¬ë„ ë¶„ì„"""
        img = cv2.imread(self.image_path)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # ê¸°ìš¸ê¸° (ê°„ë‹¨í•œ Hough ë³€í™˜)
        edges = cv2.Canny(gray, 50, 150)
        lines = cv2.HoughLines(edges, 1, np.pi/180, 100)
        
        if lines is not None and len(lines) > 0:
            angles = []
            for line in lines[:10]:  # ìƒìœ„ 10ê°œë§Œ
                rho, theta = line[0]
                angle = np.degrees(theta) - 90
                if -45 <= angle <= 45:  # ìœ íš¨í•œ ë²”ìœ„ë§Œ
                    angles.append(angle)
            
            if angles:
                tilt_angle = float(np.median(angles))
            else:
                tilt_angle = 0.0
        else:
            tilt_angle = 0.0
        
        # ëŒ€ì¹­ì„±
        h, w = gray.shape
        left = gray[:, :w//2]
        right = cv2.flip(gray[:, w//2:], 1)
        
        # í¬ê¸° ë§ì¶”ê¸°
        min_w = min(left.shape[1], right.shape[1])
        left = cv2.resize(left, (min_w, h))
        right = cv2.resize(right, (min_w, h))
        
        mse = np.mean((left.astype(float) - right.astype(float)) ** 2)
        symmetry = float(max(0, 1 - mse / (255**2)))
        
        # ë¬´ê²Œì¤‘ì‹¬
        M = cv2.moments(gray)
        if M["m00"] != 0:
            cx = M["m10"] / M["m00"] / w
            cy = M["m01"] / M["m00"] / h
        else:
            cx, cy = 0.5, 0.5
        
        return {
            "tilt_angle": tilt_angle,
            "symmetry": symmetry,
            "center_of_mass": {"x": float(cx), "y": float(cy)}
        }


# ============================================================
# í…ŒìŠ¤íŠ¸
# ============================================================
if __name__ == "__main__":
    test_img = PROJECT_ROOT / "data" / "test_images" / "test1.jpg"
    
    try:
        analyzer = ImageAnalyzer(str(test_img))
        result = analyzer.analyze()
        
        print("\n" + "="*60)
        print("ğŸ“Š IMAGE ANALYSIS RESULT")
        print("="*60)
        
        print(f"\nğŸ¯ Cluster: {result['cluster']['cluster_label']}")
        print(f"   â”” ID: {result['cluster']['cluster_id']}")
        print(f"   â”” Distance: {result['cluster']['cluster_distance']:.4f}")
        print(f"   â”” Sample count: {result['cluster']['sample_count']} ì¥")
        
        print(f"\nğŸ“ Depth:")
        print(f"   â”” Current: {result['depth']['depth_mean']:.1f}")
        print(f"   â”” Cluster typical: {result['depth']['cluster_typical_depth']:.1f}")
        print(f"   â”” Deviation: {result['depth']['depth_deviation']:.1f}")
        
        print(f"\nğŸ¨ Pixels:")
        print(f"   â”” Brightness: {result['pixels']['brightness']:.1f}")
        print(f"   â”” Saturation: {result['pixels']['saturation']:.2f}")
        print(f"   â”” Color temp: {result['pixels']['color_temperature']}")
        
        print(f"\nğŸ“ Composition:")
        print(f"   â”” Tilt angle: {result['composition']['tilt_angle']:.1f}Â°")
        print(f"   â”” Symmetry: {result['composition']['symmetry']:.2f}")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
