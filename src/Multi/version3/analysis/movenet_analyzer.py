# ============================================================
# ğŸƒ TryAngle MoveNet Analyzer
# Phase 2-2: MoveNet Thunder ê¸°ë°˜ í¬ì¦ˆ ë¶„ì„
# ============================================================

import os
import sys
import cv2
import numpy as np
from typing import Dict, List, Optional
from pathlib import Path

# Project root ì„¤ì •
VERSION3_DIR = Path(__file__).resolve().parents[1]
PROJECT_ROOT = VERSION3_DIR
while PROJECT_ROOT != PROJECT_ROOT.parent and not ((PROJECT_ROOT / "data").exists() and (PROJECT_ROOT / "src").exists()):
    PROJECT_ROOT = PROJECT_ROOT.parent

if str(VERSION3_DIR) not in sys.path:
    sys.path.append(str(VERSION3_DIR))

from utils.model_cache import model_cache

# TensorFlow Lite ê°€ì ¸ì˜¤ê¸°
try:
    import tensorflow as tf
    TFLITE_AVAILABLE = True
except ImportError:
    print("âš ï¸ TensorFlow not installed. Install: pip install tensorflow==2.15.0")
    TFLITE_AVAILABLE = False


class MoveNetAnalyzer:
    """
    MoveNet Thunder í¬ì¦ˆ ë¶„ì„ê¸°

    YOLO11 ëŒ€ì²´ìš© - í¬ì¦ˆ ì „ë¬¸ ëª¨ë¸
    - ì •í™•ë„: 77.6% mAP (YOLO11: 62.5%)
    - ì†ë„: 30fps (YOLO11: 45fps)
    - í¬ê¸°: 12MB (YOLO11: 22MB)
    """

    # MoveNet 17ê°œ í‚¤í¬ì¸íŠ¸ (COCO format, YOLO11ê³¼ ë™ì¼)
    KEYPOINTS = [
        'nose',           # 0
        'left_eye',       # 1
        'right_eye',      # 2
        'left_ear',       # 3
        'right_ear',      # 4
        'left_shoulder',  # 5
        'right_shoulder', # 6
        'left_elbow',     # 7
        'right_elbow',    # 8
        'left_wrist',     # 9
        'right_wrist',    # 10
        'left_hip',       # 11
        'right_hip',      # 12
        'left_knee',      # 13
        'right_knee',     # 14
        'left_ankle',     # 15
        'right_ankle'     # 16
    ]

    def __init__(self, model_path: Optional[str] = None):
        """
        MoveNet ëª¨ë¸ ì´ˆê¸°í™”

        Args:
            model_path: TFLite ëª¨ë¸ ê²½ë¡œ. Noneì´ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
        """
        if not TFLITE_AVAILABLE:
            raise ImportError("TensorFlow required. Install: pip install tensorflow==2.15.0")

        # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        if model_path is None:
            model_path = VERSION3_DIR / "models" / "movenet_thunder.tflite"

        if not os.path.exists(model_path):
            raise FileNotFoundError(
                f"MoveNet model not found: {model_path}\n"
                f"Run: python scripts/download_movenet.py"
            )

        self.model_path = str(model_path)

        # Singleton íŒ¨í„´ìœ¼ë¡œ ëª¨ë¸ ë¡œë“œ
        def load_interpreter():
            print(f"  ğŸ”§ Loading MoveNet from {os.path.basename(self.model_path)}...")
            interpreter = tf.lite.Interpreter(model_path=self.model_path)
            interpreter.allocate_tensors()
            return interpreter

        self.interpreter = model_cache.get_or_load("movenet_interpreter", load_interpreter)

        # Input/Output details
        self.input_details = self.interpreter.get_input_details()
        self.output_details = self.interpreter.get_output_details()

        # Input size (MoveNet: 256x256)
        self.input_size = self.input_details[0]['shape'][1]

        print(f"  âœ… MoveNet loaded (input size: {self.input_size}x{self.input_size})")

    def analyze(self, image_path: str) -> Dict:
        """
        ì´ë¯¸ì§€ì—ì„œ í¬ì¦ˆ ì¶”ì¶œ

        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ

        Returns:
            {
                'keypoints': [{name, x, y, confidence}, ...],
                'confidence': float (ì „ì²´ í‰ê· ),
                'bbox': [x1, y1, x2, y2] (ì •ê·œí™” ì¢Œí‘œ)
            }
        """
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image not found: {image_path}")

        # ì´ë¯¸ì§€ ë¡œë“œ
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"Failed to load image: {image_path}")

        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        h, w = img.shape[:2]

        # ì „ì²˜ë¦¬: 256x256 ë¦¬ì‚¬ì´ì¦ˆ
        img_resized = cv2.resize(img_rgb, (self.input_size, self.input_size))

        # UINT8ë¡œ ë³€í™˜ (0~255, MoveNetì€ ì •ê·œí™” í•„ìš” ì—†ìŒ)
        img_input = np.expand_dims(img_resized, axis=0).astype(np.uint8)

        # ì¶”ë¡ 
        self.interpreter.set_tensor(self.input_details[0]['index'], img_input)
        self.interpreter.invoke()

        # ê²°ê³¼: [1, 1, 17, 3] (batch, person, keypoints, [y, x, confidence])
        keypoints_with_scores = self.interpreter.get_tensor(
            self.output_details[0]['index']
        )[0, 0]  # (17, 3)

        # í‚¤í¬ì¸íŠ¸ íŒŒì‹±
        keypoints = []
        for i, kp_name in enumerate(self.KEYPOINTS):
            y, x, conf = keypoints_with_scores[i]
            keypoints.append({
                'name': kp_name,
                'x': float(x),  # ì´ë¯¸ ì •ê·œí™”ë¨ (0~1)
                'y': float(y),
                'confidence': float(conf)
            })

        # ì „ì²´ confidence (í‰ê· )
        avg_confidence = float(np.mean([kp['confidence'] for kp in keypoints]))

        # BBox ê³„ì‚° (confidence > 0.3ì¸ í‚¤í¬ì¸íŠ¸ë§Œ)
        valid_kps = [kp for kp in keypoints if kp['confidence'] > 0.3]
        if valid_kps:
            xs = [kp['x'] for kp in valid_kps]
            ys = [kp['y'] for kp in valid_kps]
            bbox = [min(xs), min(ys), max(xs), max(ys)]
        else:
            bbox = None

        return {
            'keypoints': keypoints,
            'confidence': avg_confidence,
            'bbox': bbox
        }

    def analyze_batch(self, image_paths: List[str]) -> List[Dict]:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ë°°ì¹˜ë¡œ ë¶„ì„

        Args:
            image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸

        Returns:
            ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        for img_path in image_paths:
            try:
                result = self.analyze(img_path)
                results.append(result)
            except Exception as e:
                print(f"âš ï¸ Failed to analyze {img_path}: {e}")
                results.append(None)

        return results


# ============================================================
# YOLO11ê³¼ í˜¸í™˜ë˜ëŠ” ë˜í¼ í•¨ìˆ˜
# ============================================================

def analyze_pose_movenet(image_path: str) -> Dict:
    """
    MoveNetìœ¼ë¡œ í¬ì¦ˆ ë¶„ì„ (YOLO11ê³¼ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤)

    Returns:
        YOLO11 analyze()ì™€ ë™ì¼í•œ í¬ë§·
        {
            'scenario': str,
            'yolo_keypoints': List[Dict],  # í˜¸í™˜ì„± ìœ„í•´ ì´ë¦„ ìœ ì§€
            'merged_keypoints': Dict,
            'confidence': float,
            'bbox': List[float]
        }
    """
    analyzer = MoveNetAnalyzer()
    result = analyzer.analyze(image_path)

    # ì‹œë‚˜ë¦¬ì˜¤ íŒë‹¨ (ê°„ë‹¨ ë²„ì „)
    scenario = _detect_scenario_simple(result)

    # YOLO11 í¬ë§·ìœ¼ë¡œ ë³€í™˜
    return {
        'scenario': scenario,
        'yolo_keypoints': result['keypoints'],  # í˜¸í™˜ì„± ìœ„í•´ ì´ë¦„ ìœ ì§€
        'merged_keypoints': {
            'base': {
                kp['name']: {
                    'x': kp['x'],
                    'y': kp['y'],
                    'confidence': kp['confidence']
                }
                for kp in result['keypoints']
            }
        },
        'confidence': result['confidence'],
        'bbox': result['bbox']
    }


def _detect_scenario_simple(result: Dict) -> str:
    """
    ê°„ë‹¨í•œ ì‹œë‚˜ë¦¬ì˜¤ íŒë‹¨

    Args:
        result: MoveNet analyze() ê²°ê³¼

    Returns:
        'full_body' | 'upper_body' | 'face_closeup' | 'no_person'
    """
    if result['confidence'] < 0.15:
        return 'no_person'

    keypoints = result['keypoints']
    kp_dict = {kp['name']: kp for kp in keypoints}

    # í•˜ì²´ í‚¤í¬ì¸íŠ¸ í™•ì¸
    lower_body_conf = np.mean([
        kp_dict['left_knee']['confidence'],
        kp_dict['right_knee']['confidence'],
        kp_dict['left_ankle']['confidence'],
        kp_dict['right_ankle']['confidence']
    ])

    # ì–¼êµ´ í‚¤í¬ì¸íŠ¸ í™•ì¸
    face_conf = np.mean([
        kp_dict['nose']['confidence'],
        kp_dict['left_eye']['confidence'],
        kp_dict['right_eye']['confidence']
    ])

    # BBox í¬ê¸° í™•ì¸
    if result['bbox']:
        bbox_width = result['bbox'][2] - result['bbox'][0]
        bbox_height = result['bbox'][3] - result['bbox'][1]
        bbox_area = bbox_width * bbox_height
    else:
        bbox_area = 0

    # íŒë‹¨
    if bbox_area > 0.4 and face_conf > 0.7:
        return 'face_closeup'
    elif lower_body_conf > 0.5:
        return 'full_body'
    else:
        return 'upper_body'


# ============================================================
# í…ŒìŠ¤íŠ¸
# ============================================================

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
    test_img = PROJECT_ROOT / "data" / "test_images" / "test1.jpg"

    if not test_img.exists():
        print(f"âŒ Test image not found: {test_img}")
        print("Please provide a test image.")
        sys.exit(1)

    print("\n" + "="*60)
    print("ğŸƒ MoveNet Analyzer Test")
    print("="*60)

    try:
        # MoveNet ë¶„ì„
        analyzer = MoveNetAnalyzer()
        result = analyzer.analyze(str(test_img))

        print(f"\nğŸ“‹ Analysis Result:")
        print(f"  Image: {test_img.name}")
        print(f"  Confidence: {result['confidence']:.2%}")
        print(f"  BBox: {result['bbox']}")

        print(f"\nğŸ¦´ Keypoints (top 10):")
        for kp in result['keypoints'][:10]:
            print(f"  {kp['name']:<15} ({kp['x']:.3f}, {kp['y']:.3f}) conf={kp['confidence']:.2f}")

        print("\n" + "="*60)
        print("âœ… Test Completed!")
        print("="*60)

    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
