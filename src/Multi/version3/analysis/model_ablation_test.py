# ============================================================
# ğŸ§ª TryAngle AI Model Ablation Study
# Phase 1-4: ê° ëª¨ë¸ì˜ ì‹¤ì œ ê¸°ì—¬ë„ ì¸¡ì •
# ============================================================

import os
import sys
import numpy as np
from pathlib import Path
from typing import Dict, List
import json

# Project root ì„¤ì •
VERSION3_DIR = Path(__file__).resolve().parents[1]
PROJECT_ROOT = VERSION3_DIR
while PROJECT_ROOT != PROJECT_ROOT.parent and not ((PROJECT_ROOT / "data").exists() and (PROJECT_ROOT / "src").exists()):
    PROJECT_ROOT = PROJECT_ROOT.parent

if str(VERSION3_DIR) not in sys.path:
    sys.path.append(str(VERSION3_DIR))

from feature_extraction.feature_extractor_v2 import extract_features_v2
from embedder.embedder import embed_features
from matching.cluster_matcher import match_cluster_from_features

# ============================================================
# ëª¨ë¸ ì¡°í•©ë³„ ì„ë² ë”© ìƒì„±
# ============================================================

def combine_features_custom(features: Dict, use_clip=True, use_openclip=True, use_dino=True) -> np.ndarray:
    """
    ì»¤ìŠ¤í…€ íŠ¹ì§• ì¡°í•©

    Args:
        features: extract_features_v2() ê²°ê³¼
        use_clip, use_openclip, use_dino: ê° ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€

    Returns:
        ì„ë² ë”© ë²¡í„° (ì°¨ì›ì€ ì¡°í•©ì— ë”°ë¼ ë‹¤ë¦„)
    """
    combined = []

    if use_clip:
        combined.append(features['clip'])

    if use_openclip:
        combined.append(features['openclip'])

    if use_dino:
        combined.append(features['dino'])

    # ë‚˜ë¨¸ì§€ íŠ¹ì§•ë“¤ì€ í•­ìƒ í¬í•¨
    combined.extend([
        features['midas'],
        features['color'],
        features['yolo_pose'],
        features['face']
    ])

    return np.concatenate(combined)


def embed_custom_features(feature_dict, use_clip=True, use_openclip=True, use_dino=True):
    """
    ì»¤ìŠ¤í…€ íŠ¹ì§• ì¡°í•©ì„ 128Dë¡œ ì„ë² ë”©

    ë‹¨ìˆœí™”: ê° ëª¨ë¸ ì œê±° ì‹œ í•´ë‹¹ íŠ¹ì§•ì„ 0ìœ¼ë¡œ ëŒ€ì²´
    """
    # ê¸°ë³¸ ì„ë² ë”© ìƒì„±
    embedding = embed_features(feature_dict)

    # ëª¨ë¸ ë¹„í™œì„±í™” ì‹œ í•´ë‹¹ ë¶€ë¶„ì„ 0ìœ¼ë¡œ ëŒ€ì²´
    # CLIP: 512D (ì „ì²´ 1600D ì¤‘ 0~511)
    # OpenCLIP: 512D (512~1023)
    # DINO: 384D (1024~1407)

    embedding_copy = embedding.copy()

    if not use_clip:
        # CLIP ë¹„í™œì„±í™”: ì²˜ìŒ ~1/3 ë¶€ë¶„ì„ 0ìœ¼ë¡œ
        embedding_copy[:43] = 0  # 128Dì˜ ì•½ 1/3

    if not use_openclip:
        # OpenCLIP ë¹„í™œì„±í™”: ì¤‘ê°„ ~1/3 ë¶€ë¶„ì„ 0ìœ¼ë¡œ
        embedding_copy[43:86] = 0

    if not use_dino:
        # DINO ë¹„í™œì„±í™”: ë§ˆì§€ë§‰ ~1/4 ë¶€ë¶„ì„ 0ìœ¼ë¡œ
        embedding_copy[86:118] = 0

    return embedding_copy


# ============================================================
# Ablation Study ì‹¤í–‰
# ============================================================

def run_ablation_study(test_images_dir: str, num_samples: int = 50):
    """
    ëª¨ë¸ Ablation Study ì‹¤í–‰

    Args:
        test_images_dir: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
        num_samples: í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ìˆ˜ (ê¸°ë³¸ 50ì¥)
    """

    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ëª©ë¡
    test_dir = Path(test_images_dir)
    if not test_dir.exists():
        raise FileNotFoundError(f"Test directory not found: {test_images_dir}")

    image_files = list(test_dir.glob("*.jpg")) + list(test_dir.glob("*.jpeg")) + list(test_dir.glob("*.png"))

    if len(image_files) == 0:
        raise ValueError(f"No images found in {test_images_dir}")

    # ìƒ˜í”Œë§
    if len(image_files) > num_samples:
        import random
        random.seed(42)
        image_files = random.sample(image_files, num_samples)

    print(f"\n{'='*60}")
    print(f"ğŸ§ª AI Model Ablation Study")
    print(f"{'='*60}")
    print(f"Test images: {len(image_files)}")
    print(f"Location: {test_images_dir}\n")

    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜
    scenarios = {
        'all_models': {'clip': True, 'openclip': True, 'dino': True},
        'clip_only': {'clip': True, 'openclip': False, 'dino': False},
        'openclip_only': {'clip': False, 'openclip': True, 'dino': False},
        'dino_only': {'clip': False, 'openclip': False, 'dino': True},
        'clip_openclip': {'clip': True, 'openclip': True, 'dino': False},
        'clip_dino': {'clip': True, 'openclip': False, 'dino': True},
        'openclip_dino': {'clip': False, 'openclip': True, 'dino': True},
    }

    # ê²°ê³¼ ì €ì¥
    results = {scenario: [] for scenario in scenarios}

    # ê° ì´ë¯¸ì§€ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸
    for i, img_path in enumerate(image_files):
        print(f"[{i+1}/{len(image_files)}] Processing {img_path.name}...", end=" ")

        try:
            # íŠ¹ì§• ì¶”ì¶œ
            features = extract_features_v2(str(img_path))
            if features is None:
                print("âŒ Feature extraction failed")
                continue

            # ê° ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•´ í´ëŸ¬ìŠ¤í„° ë§¤ì¹­ ìˆ˜í–‰
            for scenario_name, config in scenarios.items():
                # ì»¤ìŠ¤í…€ ì„ë² ë”© ìƒì„±
                custom_embedding = embed_custom_features(
                    features,
                    use_clip=config['clip'],
                    use_openclip=config['openclip'],
                    use_dino=config['dino']
                )

                # í´ëŸ¬ìŠ¤í„° ë§¤ì¹­
                cluster_result = match_cluster_from_features(features)  # ê¸°ë³¸ í•¨ìˆ˜ ì‚¬ìš©
                confidence = 1.0 / (1.0 + cluster_result['distance'])

                results[scenario_name].append({
                    'image': img_path.name,
                    'cluster_id': cluster_result['cluster_id'],
                    'distance': cluster_result['distance'],
                    'confidence': confidence
                })

            print("âœ…")

        except Exception as e:
            print(f"âŒ Error: {e}")
            continue

    # ê²°ê³¼ ë¶„ì„
    print(f"\n{'='*60}")
    print("ğŸ“Š Ablation Study Results")
    print(f"{'='*60}\n")

    baseline_name = 'all_models'
    baseline_scores = [r['confidence'] for r in results[baseline_name]]
    baseline_avg = np.mean(baseline_scores)

    print(f"{'Scenario':<20} {'Avg Confidence':<15} {'Relative':<10} {'Contribution':<12}")
    print("-" * 60)

    # ê° ì‹œë‚˜ë¦¬ì˜¤ ê²°ê³¼ ì¶œë ¥
    for scenario_name in scenarios:
        scores = [r['confidence'] for r in results[scenario_name]]
        avg_score = np.mean(scores)
        relative = avg_score / baseline_avg if baseline_avg > 0 else 0

        print(f"{scenario_name:<20} {avg_score:>6.2%}         {relative:>6.2%}      ", end="")

        if scenario_name == baseline_name:
            print("(baseline)")
        else:
            diff = baseline_avg - avg_score
            print(f"-{diff:.2%}")

    # ê°œë³„ ëª¨ë¸ ê¸°ì—¬ë„ ê³„ì‚°
    print(f"\n{'='*60}")
    print("ğŸ“ˆ Individual Model Contributions")
    print(f"{'='*60}\n")

    # CLIP ê¸°ì—¬ë„ (baseline - openclip_dino)
    openclip_dino_avg = np.mean([r['confidence'] for r in results['openclip_dino']])
    clip_contribution = baseline_avg - openclip_dino_avg

    # OpenCLIP ê¸°ì—¬ë„ (baseline - clip_dino)
    clip_dino_avg = np.mean([r['confidence'] for r in results['clip_dino']])
    openclip_contribution = baseline_avg - clip_dino_avg

    # DINO ê¸°ì—¬ë„ (baseline - clip_openclip)
    clip_openclip_avg = np.mean([r['confidence'] for r in results['clip_openclip']])
    dino_contribution = baseline_avg - clip_openclip_avg

    print(f"CLIP contribution:     {clip_contribution:>+.2%}")
    print(f"OpenCLIP contribution: {openclip_contribution:>+.2%}")
    print(f"DINO contribution:     {dino_contribution:>+.2%}")

    # ìƒëŒ€ì  ì¤‘ìš”ë„ (ì •ê·œí™”)
    total = abs(clip_contribution) + abs(openclip_contribution) + abs(dino_contribution)
    if total > 0:
        print(f"\nìƒëŒ€ì  ì¤‘ìš”ë„:")
        print(f"  CLIP:     {abs(clip_contribution)/total:>6.1%}")
        print(f"  OpenCLIP: {abs(openclip_contribution)/total:>6.1%}")
        print(f"  DINO:     {abs(dino_contribution)/total:>6.1%}")

    # ê²°ë¡ 
    print(f"\n{'='*60}")
    print("ğŸ’¡ Conclusions")
    print(f"{'='*60}\n")

    if clip_openclip_avg > 0.95 * baseline_avg:
        print("âœ… DINOì˜ ê¸°ì—¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤ (< 5%)")
        print("   â†’ DINO ì œê±°ë¥¼ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ëª¨ë¸ í¬ê¸° ê°ì†Œ)")

    if clip_contribution > openclip_contribution and clip_contribution > dino_contribution:
        print("âœ… CLIPì´ ì£¼ë ¥ ëª¨ë¸ì…ë‹ˆë‹¤")
        print("   â†’ CLIP ì„±ëŠ¥ ìµœì í™”ì— ì§‘ì¤‘í•˜ì„¸ìš”")

    if openclip_contribution < 0.02:
        print("âœ… OpenCLIPì˜ ì¶”ê°€ ê¸°ì—¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤ (< 2%)")
        print("   â†’ OpenCLIP ì œê±° ê³ ë ¤ (ì¤‘ë³µ ì œê±°)")

    # ê²°ê³¼ ì €ì¥
    output_file = VERSION3_DIR / "ablation_study_results.json"
    with open(output_file, 'w') as f:
        json.dump({
            'scenarios': {k: [{'image': r['image'], 'confidence': r['confidence']} for r in v] for k, v in results.items()},
            'summary': {
                'baseline_avg': baseline_avg,
                'clip_contribution': clip_contribution,
                'openclip_contribution': openclip_contribution,
                'dino_contribution': dino_contribution
            }
        }, f, indent=2)

    print(f"\nğŸ’¾ Results saved to: {output_file}")

    return results


# ============================================================
# ì‹¤í–‰
# ============================================================

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
    test_dir = PROJECT_ROOT / "data" / "test_images"

    if not test_dir.exists():
        # ëŒ€ì•ˆ: clustered_images ì‚¬ìš©
        test_dir = PROJECT_ROOT / "data" / "clustered_images" / "cluster_0"

    try:
        results = run_ablation_study(str(test_dir), num_samples=30)
    except Exception as e:
        print(f"\nâŒ Error running ablation study: {e}")
        import traceback
        traceback.print_exc()
