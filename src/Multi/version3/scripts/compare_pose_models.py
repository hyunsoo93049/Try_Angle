# ============================================================
# ğŸ“Š YOLO11 vs MoveNet Performance Comparison
# Phase 2-5: í¬ì¦ˆ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
# ============================================================

import os
import sys
import time
import numpy as np
from pathlib import Path
from typing import Dict, List
import json

# Project root ì„¤ì •
VERSION3_DIR = Path(__file__).resolve().parents[1]
PROJECT_ROOT = VERSION3_DIR
while PROJECT_ROOT != PROJECT_ROOT.parent and not ((PROJECT_ROOT / "data").exists() and (PROJECT_ROOT / "src").exists()):
    PROJECT_ROOT = PROJECT_ROOT.parent

if str(VERSION3_DIR) not in sys.path:
    sys.path.append(str(VERSION3_DIR))

from analysis.pose_analyzer import PoseAnalyzer


# ============================================================
# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
# ============================================================

def benchmark_model(analyzer: PoseAnalyzer, image_paths: List[str], model_name: str) -> Dict:
    """
    ë‹¨ì¼ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬

    Args:
        analyzer: PoseAnalyzer ì¸ìŠ¤í„´ìŠ¤
        image_paths: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        model_name: ëª¨ë¸ ì´ë¦„ (YOLO11 ë˜ëŠ” MoveNet)

    Returns:
        ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print(f"\n{'='*60}")
    print(f"ğŸƒ Testing {model_name}")
    print(f"{'='*60}")

    results = []
    inference_times = []
    confidences = []
    scenarios = {
        'full_body': 0,
        'upper_body': 0,
        'face_closeup': 0,
        'hand_gesture': 0,
        'back_view': 0,
        'no_person': 0
    }

    for i, img_path in enumerate(image_paths):
        print(f"[{i+1}/{len(image_paths)}] Testing {Path(img_path).name}...", end=" ")

        try:
            # ì¶”ë¡  ì‹œê°„ ì¸¡ì •
            start_time = time.time()
            result = analyzer.analyze(str(img_path))
            inference_time = (time.time() - start_time) * 1000  # ms

            inference_times.append(inference_time)

            # ì‹œë‚˜ë¦¬ì˜¤ ì¹´ìš´íŠ¸
            scenario = result.get('scenario', 'no_person')
            scenarios[scenario] += 1

            # Confidence ìˆ˜ì§‘
            if result['confidence'] > 0:
                confidences.append(result['confidence'])

            results.append({
                'image': Path(img_path).name,
                'scenario': scenario,
                'confidence': result['confidence'],
                'inference_time_ms': inference_time,
                'keypoints_detected': len([kp for kp in result.get('yolo_keypoints', []) if kp['confidence'] > 0.3])
            })

            print(f"âœ… ({inference_time:.1f}ms, conf={result['confidence']:.2f})")

        except Exception as e:
            print(f"âŒ Error: {e}")
            results.append({
                'image': Path(img_path).name,
                'error': str(e)
            })

    # í†µê³„ ê³„ì‚°
    avg_time = np.mean(inference_times) if inference_times else 0
    std_time = np.std(inference_times) if inference_times else 0
    avg_conf = np.mean(confidences) if confidences else 0
    std_conf = np.std(confidences) if confidences else 0

    return {
        'model': model_name,
        'total_images': len(image_paths),
        'successful_detections': len([r for r in results if 'error' not in r and r.get('confidence', 0) > 0.15]),
        'avg_inference_time_ms': avg_time,
        'std_inference_time_ms': std_time,
        'avg_confidence': avg_conf,
        'std_confidence': std_conf,
        'scenarios': scenarios,
        'detailed_results': results
    }


def compare_models(test_images_dir: str, num_samples: int = 30):
    """
    YOLO11 vs MoveNet ë¹„êµ

    Args:
        test_images_dir: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
        num_samples: í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ìˆ˜ (ê¸°ë³¸ 30ì¥)
    """
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ëª©ë¡
    test_dir = Path(test_images_dir)
    if not test_dir.exists():
        raise FileNotFoundError(f"Test directory not found: {test_images_dir}")

    image_files = list(test_dir.glob("*.jpg")) + list(test_dir.glob("*.jpeg")) + list(test_dir.glob("*.png"))

    if len(image_files) == 0:
        raise ValueError(f"No images found in {test_images_dir}")

    # ìƒ˜í”Œë§
    if len(image_files) > num_samples:
        import random
        random.seed(42)
        image_files = random.sample(image_files, num_samples)

    print(f"\n{'='*60}")
    print(f"ğŸ“Š YOLO11 vs MoveNet Performance Comparison")
    print(f"{'='*60}")
    print(f"Test images: {len(image_files)}")
    print(f"Location: {test_images_dir}\n")

    # YOLO11 í…ŒìŠ¤íŠ¸
    print("\nğŸ”· Phase 1: YOLO11 Benchmark")
    yolo_analyzer = PoseAnalyzer(use_movenet=False)
    yolo_results = benchmark_model(yolo_analyzer, image_files, "YOLO11-pose")

    # MoveNet í…ŒìŠ¤íŠ¸
    print("\nğŸ”¶ Phase 2: MoveNet Benchmark")
    movenet_analyzer = PoseAnalyzer(use_movenet=True)
    movenet_results = benchmark_model(movenet_analyzer, image_files, "MoveNet-Thunder")

    # ê²°ê³¼ ë¹„êµ
    print(f"\n{'='*60}")
    print(f"ğŸ“Š Comparison Results")
    print(f"{'='*60}\n")

    # í‘œ í˜•ì‹ ì¶œë ¥
    print(f"{'Metric':<30} {'YOLO11-pose':<20} {'MoveNet-Thunder':<20} {'Winner':<10}")
    print("-" * 80)

    # 1. Detection Rate
    yolo_rate = yolo_results['successful_detections'] / yolo_results['total_images']
    movenet_rate = movenet_results['successful_detections'] / movenet_results['total_images']
    winner = "MoveNet" if movenet_rate > yolo_rate else "YOLO11" if yolo_rate > movenet_rate else "Tie"
    print(f"{'Detection Rate':<30} {yolo_rate:>6.1%}              {movenet_rate:>6.1%}              {winner:<10}")

    # 2. Inference Speed
    yolo_fps = 1000 / yolo_results['avg_inference_time_ms'] if yolo_results['avg_inference_time_ms'] > 0 else 0
    movenet_fps = 1000 / movenet_results['avg_inference_time_ms'] if movenet_results['avg_inference_time_ms'] > 0 else 0
    winner = "YOLO11" if yolo_fps > movenet_fps else "MoveNet" if movenet_fps > yolo_fps else "Tie"
    print(f"{'Avg Inference Time (ms)':<30} {yolo_results['avg_inference_time_ms']:>6.1f}              {movenet_results['avg_inference_time_ms']:>6.1f}              {winner:<10}")
    print(f"{'FPS':<30} {yolo_fps:>6.1f}              {movenet_fps:>6.1f}              {winner:<10}")

    # 3. Confidence
    winner = "MoveNet" if movenet_results['avg_confidence'] > yolo_results['avg_confidence'] else "YOLO11" if yolo_results['avg_confidence'] > movenet_results['avg_confidence'] else "Tie"
    print(f"{'Avg Confidence':<30} {yolo_results['avg_confidence']:>6.2%}              {movenet_results['avg_confidence']:>6.2%}              {winner:<10}")

    # ì‹œë‚˜ë¦¬ì˜¤ë³„ ë¹„êµ
    print(f"\n{'='*60}")
    print(f"ğŸ“‹ Scenario Detection Breakdown")
    print(f"{'='*60}\n")

    print(f"{'Scenario':<20} {'YOLO11':<15} {'MoveNet':<15}")
    print("-" * 50)
    for scenario in ['full_body', 'upper_body', 'face_closeup', 'hand_gesture', 'back_view', 'no_person']:
        yolo_count = yolo_results['scenarios'][scenario]
        movenet_count = movenet_results['scenarios'][scenario]
        print(f"{scenario:<20} {yolo_count:<15} {movenet_count:<15}")

    # ê²°ë¡ 
    print(f"\n{'='*60}")
    print(f"ğŸ’¡ Conclusions")
    print(f"{'='*60}\n")

    # ìŠ¹ì ê²°ì •
    yolo_score = 0
    movenet_score = 0

    if yolo_rate > movenet_rate:
        yolo_score += 1
    elif movenet_rate > yolo_rate:
        movenet_score += 1

    if yolo_fps > movenet_fps:
        yolo_score += 1
    elif movenet_fps > yolo_fps:
        movenet_score += 1

    if yolo_results['avg_confidence'] > movenet_results['avg_confidence']:
        yolo_score += 1
    elif movenet_results['avg_confidence'] > yolo_results['avg_confidence']:
        movenet_score += 1

    print(f"Overall Score: YOLO11 ({yolo_score}/3) vs MoveNet ({movenet_score}/3)")

    if movenet_score > yolo_score:
        print("\nâœ… MoveNetì´ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•©ë‹ˆë‹¤!")
        print("   ê¶Œì¥: MoveNetìœ¼ë¡œ ì „í™˜ (íŠ¹íˆ í¬ì¦ˆ ì •í™•ë„ê°€ ì¤‘ìš”í•œ ê²½ìš°)")
    elif yolo_score > movenet_score:
        print("\nâœ… YOLO11ì´ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•©ë‹ˆë‹¤!")
        print("   ê¶Œì¥: YOLO11 ìœ ì§€ (íŠ¹íˆ ì†ë„ê°€ ì¤‘ìš”í•œ ê²½ìš°)")
    else:
        print("\nâœ… ë‘ ëª¨ë¸ì´ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤!")
        print("   ê¶Œì¥: ì‚¬ìš© ëª©ì ì— ë”°ë¼ ì„ íƒ")
        print("   - ì •í™•ë„ ìš°ì„ : MoveNet")
        print("   - ì†ë„ ìš°ì„ : YOLO11")

    # ìƒì„¸ ê¶Œì¥ì‚¬í•­
    if movenet_rate > yolo_rate * 1.1:
        print("\nğŸ“Œ MoveNetì˜ ê²€ì¶œë¥ ì´ 10% ì´ìƒ ë†’ìŠµë‹ˆë‹¤")
        print("   â†’ ì¸¡ë©´ í¬ì¦ˆ, ì–¼êµ´ ê°€ë¦° í¬ì¦ˆ ë“± ì–´ë ¤ìš´ ì¼€ì´ìŠ¤ì— ê°•ì ")

    if yolo_fps > movenet_fps * 1.2:
        print("\nğŸ“Œ YOLO11ì˜ ì†ë„ê°€ 20% ì´ìƒ ë¹ ë¦…ë‹ˆë‹¤")
        print("   â†’ ì‹¤ì‹œê°„ ì²˜ë¦¬ê°€ ì¤‘ìš”í•œ ê²½ìš° YOLO11 ì„ íƒ")

    # ê²°ê³¼ ì €ì¥
    output_file = VERSION3_DIR / "pose_model_comparison_results.json"
    with open(output_file, 'w') as f:
        json.dump({
            'yolo11': yolo_results,
            'movenet': movenet_results,
            'summary': {
                'yolo11_score': yolo_score,
                'movenet_score': movenet_score,
                'yolo11_detection_rate': yolo_rate,
                'movenet_detection_rate': movenet_rate,
                'yolo11_fps': yolo_fps,
                'movenet_fps': movenet_fps,
                'yolo11_avg_confidence': yolo_results['avg_confidence'],
                'movenet_avg_confidence': movenet_results['avg_confidence']
            }
        }, f, indent=2)

    print(f"\nğŸ’¾ Results saved to: {output_file}")

    return {
        'yolo11': yolo_results,
        'movenet': movenet_results
    }


# ============================================================
# ì‹¤í–‰
# ============================================================

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
    test_dir = PROJECT_ROOT / "data" / "test_images"

    if not test_dir.exists():
        # ëŒ€ì•ˆ: clustered_images ì‚¬ìš©
        test_dir = PROJECT_ROOT / "data" / "clustered_images" / "cluster_0"

    if not test_dir.exists():
        print(f"âŒ Test directory not found: {test_dir}")
        print("Please provide test images in data/test_images/")
        sys.exit(1)

    try:
        results = compare_models(str(test_dir), num_samples=30)
    except Exception as e:
        print(f"\nâŒ Error running comparison: {e}")
        import traceback
        traceback.print_exc()
