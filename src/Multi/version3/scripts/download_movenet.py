# ============================================================
# ğŸ“¥ MoveNet Thunder Model Downloader
# Phase 2-1: MoveNet ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° TFLite ë³€í™˜
# ============================================================

import os
import sys
from pathlib import Path

print("="*60)
print("ğŸ“¥ MoveNet Thunder Downloader")
print("="*60)

# TensorFlow ì„¤ì¹˜ í™•ì¸
try:
    import tensorflow as tf
    import tensorflow_hub as hub
    print(f"âœ… TensorFlow version: {tf.__version__}")
except ImportError:
    print("\nâŒ TensorFlow not installed!")
    print("\nì„¤ì¹˜ ëª…ë ¹ì–´:")
    print("  pip install tensorflow==2.15.0")
    print("  pip install tensorflow-hub")
    sys.exit(1)

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
VERSION3_DIR = Path(__file__).resolve().parents[1]
MODELS_DIR = VERSION3_DIR / "models"
MODELS_DIR.mkdir(exist_ok=True)

# MoveNet ëª¨ë¸ URL
MOVENET_THUNDER_URL = "https://tfhub.dev/google/movenet/singlepose/thunder/4"
MOVENET_LIGHTNING_URL = "https://tfhub.dev/google/movenet/singlepose/lightning/4"

print(f"\nModels will be saved to: {MODELS_DIR}\n")

def download_and_convert(model_url, model_name):
    """
    MoveNet ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° TFLite ë³€í™˜

    Args:
        model_url: TensorFlow Hub URL
        model_name: ì €ì¥í•  ëª¨ë¸ ì´ë¦„ (ì˜ˆ: "movenet_thunder")
    """
    print(f"\n{'='*60}")
    print(f"ğŸ“¦ Downloading {model_name}...")
    print(f"{'='*60}\n")

    try:
        # Step 1: TensorFlow Hubì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        print(f"1/4 Loading model from TensorFlow Hub...")
        print(f"    URL: {model_url}")

        model = hub.load(model_url)
        movenet = model.signatures['serving_default']

        print(f"âœ… Model loaded successfully")

        # Step 2: ëª¨ë¸ ì •ë³´ í™•ì¸
        print(f"\n2/4 Model Information:")
        print(f"    Input shape: {movenet.inputs[0].shape}")
        print(f"    Output shape: {movenet.outputs[0].shape}")

        # Step 3: SavedModel í˜•ì‹ìœ¼ë¡œ ì €ì¥
        saved_model_dir = MODELS_DIR / f"{model_name}_saved_model"
        print(f"\n3/4 Saving as SavedModel format...")
        print(f"    Location: {saved_model_dir}")

        tf.saved_model.save(model, str(saved_model_dir))
        print(f"âœ… SavedModel saved")

        # Step 4: TFLite ë³€í™˜
        print(f"\n4/4 Converting to TFLite...")

        converter = tf.lite.TFLiteConverter.from_saved_model(str(saved_model_dir))

        # ìµœì í™” ì˜µì…˜
        converter.optimizations = [tf.lite.Optimize.DEFAULT]

        # ë³€í™˜ ì‹¤í–‰
        tflite_model = converter.convert()

        # ì €ì¥
        tflite_path = MODELS_DIR / f"{model_name}.tflite"
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)

        model_size_mb = len(tflite_model) / (1024 * 1024)
        print(f"âœ… TFLite model saved")
        print(f"    Location: {tflite_path}")
        print(f"    Size: {model_size_mb:.1f} MB")

        return tflite_path

    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_model(tflite_path):
    """
    TFLite ëª¨ë¸ í…ŒìŠ¤íŠ¸

    Args:
        tflite_path: TFLite ëª¨ë¸ ê²½ë¡œ
    """
    print(f"\n{'='*60}")
    print(f"ğŸ§ª Testing TFLite Model")
    print(f"{'='*60}\n")

    try:
        import numpy as np

        # Interpreter ë¡œë“œ
        interpreter = tf.lite.Interpreter(model_path=str(tflite_path))
        interpreter.allocate_tensors()

        # Input/Output ì •ë³´
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()

        print(f"Input Details:")
        print(f"  Shape: {input_details[0]['shape']}")
        print(f"  Type: {input_details[0]['dtype']}")

        print(f"\nOutput Details:")
        print(f"  Shape: {output_details[0]['shape']}")
        print(f"  Type: {output_details[0]['dtype']}")

        # ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        input_shape = input_details[0]['shape']
        input_data = np.random.rand(*input_shape).astype(np.float32)

        print(f"\nRunning inference with dummy input...")
        interpreter.set_tensor(input_details[0]['index'], input_data)
        interpreter.invoke()

        # ê²°ê³¼
        output_data = interpreter.get_tensor(output_details[0]['index'])
        print(f"âœ… Inference successful!")
        print(f"   Output shape: {output_data.shape}")
        print(f"   First keypoint: {output_data[0, 0, 0]}")  # [y, x, confidence]

        return True

    except Exception as e:
        print(f"âŒ Test failed: {e}")
        return False


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print("\nWhich model do you want to download?")
    print("1. MoveNet Thunder (ì •í™•ë„ ìš°ì„ , 12MB, 30fps)")
    print("2. MoveNet Lightning (ì†ë„ ìš°ì„ , 3MB, 60fps)")
    print("3. Both")

    choice = input("\nEnter your choice (1/2/3) [default: 1]: ").strip()

    if not choice:
        choice = "1"

    models_to_download = []

    if choice == "1":
        models_to_download = [
            (MOVENET_THUNDER_URL, "movenet_thunder")
        ]
    elif choice == "2":
        models_to_download = [
            (MOVENET_LIGHTNING_URL, "movenet_lightning")
        ]
    elif choice == "3":
        models_to_download = [
            (MOVENET_THUNDER_URL, "movenet_thunder"),
            (MOVENET_LIGHTNING_URL, "movenet_lightning")
        ]
    else:
        print("Invalid choice!")
        return

    # ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜
    for model_url, model_name in models_to_download:
        tflite_path = download_and_convert(model_url, model_name)

        if tflite_path:
            # í…ŒìŠ¤íŠ¸
            test_model(tflite_path)

    print(f"\n{'='*60}")
    print(f"âœ… All Done!")
    print(f"{'='*60}")
    print(f"\nModels saved in: {MODELS_DIR}")
    print(f"\nNext steps:")
    print(f"  1. Pythonì—ì„œ ì‚¬ìš©: movenet_analyzer.py ì°¸ì¡°")
    print(f"  2. iOSì—ì„œ ì‚¬ìš©: TFLite ëª¨ë¸ì„ Xcode í”„ë¡œì íŠ¸ì— ì¶”ê°€")


if __name__ == "__main__":
    main()
