import os
import shutil
import json
import numpy as np
import polars as pl
from collections import Counter
from colorsys import rgb_to_hsv

# ============================
# ì„¤ì •
# ============================
FEATURE_PARQUET = r"C:\try_angle\feature_models\features\fusion_features_v2.parquet"
CLUSTER_LABELS_NPY = r"C:\try_angle\feature_models\feature_models_v3\cluster_labels.npy"
IMAGE_DIR = r"C:\try_angle\data\train_images"
OUTPUT_CLUSTER_DIR = r"C:\try_angle\clusters"

# ğŸ”¥ ìµœì  ì„¤ì • (Auto Optimizer ê²°ê³¼)
K = 20
WEIGHTS = {
    "clip": 0.30,
    "openclip": 0.30,
    "dino": 0.25,
    "color": 0.12,
    "midas": 0.03,
    "pose": 0.00,  # Pose ì œì™¸
}

# ğŸ—‘ï¸ ê¸°ì¡´ clusters í´ë” ì™„ì „ ì‚­ì œ í›„ ì¬ìƒì„±
if os.path.exists(OUTPUT_CLUSTER_DIR):
    print(f"ğŸ—‘ï¸ Removing old clusters: {OUTPUT_CLUSTER_DIR}")
    shutil.rmtree(OUTPUT_CLUSTER_DIR)
    print("âœ… Old clusters removed\n")

os.makedirs(OUTPUT_CLUSTER_DIR, exist_ok=True)


# ============================
# 1) ë°ì´í„° ë¡œë“œ
# ============================
print("="*60)
print("ğŸ·ï¸ TryAngle Auto Cluster Labeling")
print("="*60)
print("\nğŸ“‚ Loading data...")

if not os.path.exists(FEATURE_PARQUET):
    raise FileNotFoundError(f"âŒ Feature file not found: {FEATURE_PARQUET}")
    
if not os.path.exists(CLUSTER_LABELS_NPY):
    raise FileNotFoundError(f"âŒ Cluster labels not found: {CLUSTER_LABELS_NPY}")

df = pl.read_parquet(FEATURE_PARQUET)
cluster_labels = np.load(CLUSTER_LABELS_NPY)
df = df.with_columns(pl.Series("cluster", cluster_labels))

filenames = df["filename"].to_list()
n_clusters = int(df["cluster"].max() + 1)

print(f"âœ… Loaded {len(df)} samples")
print(f"âœ… Number of clusters: {n_clusters}")

# K ê²€ì¦
if n_clusters != K:
    print(f"âš ï¸ WARNING: Expected K={K}, but found {n_clusters} clusters")


# ============================
# Helper: ìƒ‰ìƒ ì¶”ì¶œ í•¨ìˆ˜
# ============================
def extract_mean_color(color_hist):
    """
    119D ë˜ëŠ” 150D color histë¥¼ mean RGB â†’ HSVë¡œ ë³€í™˜
    
    êµ¬ì¡°:
    - HSV histogram (3 channels Ã— 32 bins = 96D)
    - LAB stats (3 channels Ã— 4 stats = 12D)
    - LBP texture (10D)
    - Edge density (1D)
    Total: 96 + 12 + 10 + 1 = 119D
    """
    arr = np.array(color_hist)
    
    # HSV histogram ë¶€ë¶„ë§Œ ì‚¬ìš© (ì• 96D)
    hsv_hist = arr[:96] if len(arr) >= 96 else arr[:min(96, len(arr))]
    
    # 3ê°œ ì±„ë„ë¡œ ë¶„ë¦¬
    n_bins = len(hsv_hist) // 3
    h_hist = hsv_hist[:n_bins]
    s_hist = hsv_hist[n_bins:2*n_bins]
    v_hist = hsv_hist[2*n_bins:3*n_bins]
    
    # ê°€ì¤‘ í‰ê·  (histogram bin index Ã— ê°’)
    h = np.average(np.arange(len(h_hist)), weights=h_hist + 1e-6)
    s = np.average(np.arange(len(s_hist)), weights=s_hist + 1e-6)
    v = np.average(np.arange(len(v_hist)), weights=v_hist + 1e-6)
    
    # ì •ê·œí™” [0, 1]
    h = h / len(h_hist)
    s = s / len(s_hist)
    v = v / len(v_hist)
    
    return h, s, v


# ============================
# Helper: ìë™ ë¼ë²¨ ìƒì„±
# ============================
def generate_cluster_label(cluster_df):
    """
    í´ëŸ¬ìŠ¤í„° í‰ê·  íŠ¹ì§•ìœ¼ë¡œ ìë™ ë¼ë²¨ë§
    
    ìµœì  ê°€ì¤‘ì¹˜ ë°˜ì˜:
    - CLIP/OpenCLIP/DINO: ì£¼ìš” ìŠ¤íƒ€ì¼ ê²°ì • (85%)
    - Color: ë³´ì¡° (12%)
    - MiDaS: ìµœì†Œ (3%)
    - Pose: ì œì™¸ (0%)
    """
    
    # -------------------------
    # 1) ìƒ‰ê° ë¶„ì„ (Color 12%)
    # -------------------------
    color_vec = cluster_df["color"].to_list()
    color_mean = np.mean(np.vstack(color_vec), axis=0)
    h, s, v = extract_mean_color(color_mean)
    
    # -------------------------
    # 2) DINO êµ¬ë„ ë¶„ì„ (25%)
    # -------------------------
    dino_vec = np.vstack(cluster_df["dino"].to_list())
    dino_mean = np.mean(dino_vec, axis=0)
    dino_std = np.std(dino_vec, axis=0)
    
    # ì¤‘ì‹¬ì„±: ë²¡í„°ì˜ í‰ê·  í¬ê¸°
    dino_center_energy = np.linalg.norm(dino_mean)
    
    # ë¶„ì‚°ë„: í‘œì¤€í¸ì°¨ì˜ í‰ê· 
    dino_variance = np.mean(dino_std)
    
    # -------------------------
    # 3) MiDaS ê¹Šì´/ì•µê¸€ (3%) - ê±°ì˜ ë¬´ì‹œ
    # -------------------------
    midas_vec = np.vstack(cluster_df["midas"].to_list())
    
    # MiDaS ì°¨ì› í™•ì¸
    if midas_vec.shape[1] >= 2:
        # depth_mean, depth_std, ... ë“± ì—¬ëŸ¬ í†µê³„ëŸ‰
        depth_mean = midas_vec[:, 0].mean()
        depth_grad_y = midas_vec[:, 1].mean() if midas_vec.shape[1] > 1 else 0
    else:
        depth_mean = midas_vec[:, 0].mean()
        depth_grad_y = 0
    
    # -------------------------
    # 4) Pose ì¡´ì¬ ì—¬ë¶€ (0% ê°€ì¤‘ì¹˜ì§€ë§Œ ì •ë³´ë¡œ í™œìš©)
    # -------------------------
    pose_vec = np.vstack(cluster_df["yolo_pose"].to_list())
    person_ratio = np.mean(np.sum(np.abs(pose_vec), axis=1) > 0.1)
    
    # -------------------------
    # 5) CLIP ê¸°ë°˜ ë¶„ìœ„ê¸° ì¶”ì • (ê°„ì ‘)
    # -------------------------
    # CLIP ìì²´ëŠ” í•´ì„ ì–´ë ¤ìš°ë¯€ë¡œ, ë‹¤ë¥¸ íŠ¹ì§•ë“¤ê³¼ ì¡°í•©ìœ¼ë¡œ ì¶”ì •
    
    # -------------------------
    # ê·œì¹™ ê¸°ë°˜ ë¼ë²¨ë§
    # -------------------------
    tags = []
    
    # === ìƒ‰ê° (Color 12%) ===
    if s < 0.3:  # ì±„ë„ ë‚®ìŒ
        if v > 0.6:
            tags.append("ë°ê³  ì°¨ë¶„í•œ")
        else:
            tags.append("ì–´ë‘ìš´ ë¬´ì±„ìƒ‰")
    else:  # ì±„ë„ ë†’ìŒ
        if h < 0.1 or h > 0.85:  # ë¹¨ê°•~ì£¼í™©
            tags.append("ë”°ëœ»í•œ ê°ì„±")
        elif 0.15 < h < 0.45:  # ì´ˆë¡~ë…¸ë‘
            tags.append("ìƒê¸°ìˆëŠ”")
        elif 0.45 < h < 0.7:  # íŒŒë‘~ì²­ë¡
            tags.append("ì°¨ê°€ìš´ ê°ì„±")
        else:
            tags.append("ë‰´íŠ¸ëŸ´ í†¤")
    
    # === ë°ê¸° ===
    if v > 0.65:
        tags.append("ë°ì€ ë¶„ìœ„ê¸°")
    elif v < 0.35:
        tags.append("ì–´ë‘ìš´ ë¬´ë“œ")
    else:
        tags.append("ì¤‘ê°„ ë°ê¸°")
    
    # === DINO êµ¬ë„ (25%) ===
    if dino_center_energy > 0.3:
        tags.append("ì¤‘ì•™ ì§‘ì¤‘")
    elif dino_center_energy < 0.15:
        tags.append("ë¶„ì‚° ë°°ì¹˜")
    
    if dino_variance > 0.25:
        tags.append("ë³µì¡í•œ êµ¬ì„±")
    elif dino_variance < 0.12:
        tags.append("ë‹¨ìˆœ êµ¬ë„")
    
    # === ì‚¬ëŒ/í’ê²½ (ì°¸ê³ ìš©) ===
    if person_ratio > 0.7:
        tags.append("ì¸ë¬¼ ì¤‘ì‹¬")
    elif person_ratio < 0.2:
        tags.append("í’ê²½/ì‚¬ë¬¼")
    else:
        tags.append("ì¸ë¬¼+ë°°ê²½")
    
    # === ì•µê¸€ (MiDaS 3%, ê±°ì˜ ë¬´ì‹œ) ===
    if abs(depth_grad_y) > 0.1:  # ì„ê³„ê°’ ë†’ì„
        if depth_grad_y < 0:
            tags.append("ë¡œìš°ì•µê¸€")
        else:
            tags.append("í•˜ì´ì•µê¸€")
    
    return " / ".join(tags)


# ============================
# 2) í´ëŸ¬ìŠ¤í„°ë³„ í´ë” ìƒì„± + íŒŒì¼ ë³µì‚¬
# ============================
print("\nğŸ“ Splitting images into cluster folders...")

cluster_info = {}

for c in range(n_clusters):
    cluster_folder = os.path.join(OUTPUT_CLUSTER_DIR, f"cluster_{c:02d}")
    os.makedirs(cluster_folder, exist_ok=True)
    
    cluster_df = df.filter(pl.col("cluster") == c)
    cluster_files = cluster_df["filename"].to_list()
    
    # ìë™ ë¼ë²¨ ìƒì„±
    label = generate_cluster_label(cluster_df)
    cluster_info[str(c)] = {
        "label": label,
        "count": len(cluster_files),
        "percentage": round(len(cluster_files) / len(df) * 100, 2)
    }
    
    # ì„¤ëª… íŒŒì¼ ì €ì¥
    desc_file = os.path.join(cluster_folder, "cluster_description.txt")
    with open(desc_file, "w", encoding="utf-8") as f:
        f.write(f"Cluster {c}\n")
        f.write(f"="*40 + "\n")
        f.write(f"Image Count: {len(cluster_files)}\n")
        f.write(f"Percentage: {cluster_info[str(c)]['percentage']}%\n")
        f.write(f"Auto Label: {label}\n")
        f.write(f"\n")
        f.write(f"Optimal Settings:\n")
        f.write(f"  K = {K}\n")
        f.write(f"  Silhouette = 0.3988\n")
        f.write(f"  Weights: {WEIGHTS}\n")
    
    # ì´ë¯¸ì§€ ë³µì‚¬
    copied = 0
    for fname in cluster_files:
        src = os.path.join(IMAGE_DIR, fname)
        dst = os.path.join(cluster_folder, fname)
        
        if os.path.exists(src):
            shutil.copyfile(src, dst)
            copied += 1
    
    print(f"âœ”ï¸ Cluster {c:02d}: {copied}/{len(cluster_files)} images | {label}")


# ============================
# 3) ì „ì²´ summary ì €ì¥
# ============================
summary_path = os.path.join(OUTPUT_CLUSTER_DIR, "cluster_summary.json")

summary_data = {
    "metadata": {
        "total_images": len(df),
        "n_clusters": n_clusters,
        "K": K,
        "silhouette_score": 0.3988,
        "weights": WEIGHTS,
        "optimization_method": "Grid Search (60 combinations)",
    },
    "clusters": cluster_info
}

with open(summary_path, "w", encoding="utf-8") as f:
    json.dump(summary_data, f, indent=2, ensure_ascii=False)

print("\n" + "="*60)
print("ğŸ‰ Auto Labeling Complete!")
print("="*60)
print(f"\nğŸ“Œ Output directory: {OUTPUT_CLUSTER_DIR}")
print(f"ğŸ“Œ Summary file: {summary_path}")
print("\nğŸ“Š Cluster Distribution:")
for c in range(min(5, n_clusters)):  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
    info = cluster_info[str(c)]
    print(f"   Cluster {c:02d}: {info['count']:4d} ({info['percentage']:5.2f}%) - {info['label']}")
if n_clusters > 5:
    print(f"   ... and {n_clusters - 5} more clusters")
print("="*60)