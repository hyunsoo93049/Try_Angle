# ============================================================
# ğŸ“¹ TryAngle - Realtime Camera Feedback System
# ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì´¬ì˜ ê°€ì´ë“œ (í¬ë¡œìŠ¤ í”Œë«í¼ í˜¸í™˜)
# ============================================================

import cv2
import numpy as np
import time
import sys
from typing import Dict, List, Optional
import tempfile
import threading
from queue import Queue, Empty
from pathlib import Path
import yaml
from PIL import Image, ImageDraw, ImageFont

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ìë™ ì„¤ì •
PROJECT_ROOT = Path(__file__).resolve().parent
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(PROJECT_ROOT / "analysis"))
sys.path.insert(0, str(PROJECT_ROOT / "utils"))

from analysis.image_analyzer import ImageAnalyzer
from analysis.image_comparator import ImageComparator

# Phase 3.3: Visual Guide Overlay
try:
    from utils.visual_guide import VisualGuideOverlay
    VISUAL_GUIDE_AVAILABLE = True
except ImportError:
    print("âš ï¸ Visual Guide Overlay not available")
    VISUAL_GUIDE_AVAILABLE = False


class Config:
    """ì„¤ì • íŒŒì¼ ë¡œë”"""

    def __init__(self, config_path: Optional[Path] = None):
        if config_path is None:
            config_path = PROJECT_ROOT / "config.yaml"

        with open(config_path, 'r', encoding='utf-8') as f:
            self.data = yaml.safe_load(f)

        # ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        self.project_root = PROJECT_ROOT
        self._resolve_paths()

    def _resolve_paths(self):
        """ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜"""
        for key, value in self.data['paths'].items():
            if key != 'default_reference':
                abs_path = (self.project_root / value).resolve()
                self.data['paths'][key] = abs_path

    def get(self, *keys, default=None):
        """ì¤‘ì²©ëœ í‚¤ ì ‘ê·¼: config.get('camera', 'width')"""
        result = self.data
        for key in keys:
            if isinstance(result, dict) and key in result:
                result = result[key]
            else:
                return default
        return result

    def get_path(self, *keys) -> Path:
        """ê²½ë¡œ ë°˜í™˜"""
        return Path(self.get(*keys))


class RealtimeCameraAnalyzer:
    """
    ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”¼ë“œë°± ì‹œìŠ¤í…œ
    - ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ì™€ ì‹¤ì‹œê°„ ë¹„êµ
    - í™”ë©´ì— í”¼ë“œë°± ì˜¤ë²„ë ˆì´ í‘œì‹œ
    """

    def __init__(
        self,
        reference_path: Path,
        camera_index: Optional[int] = None,
        config: Optional[Config] = None
    ):
        """
        Args:
            reference_path: ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ê²½ë¡œ
            camera_index: ì¹´ë©”ë¼ ì¸ë±ìŠ¤ (Noneì´ë©´ configì—ì„œ ì½ìŒ)
            config: ì„¤ì • ê°ì²´
        """

        # ì„¤ì • ë¡œë“œ
        self.config = config if config else Config()

        # ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ í™•ì¸
        if not reference_path.exists():
            raise FileNotFoundError(f"ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_path}")

        self.reference_path = reference_path
        self.camera_index = camera_index if camera_index is not None else self.config.get('camera', 'default_index')

        # ì¹´ë©”ë¼ ì„¤ì •
        self.frame_width = self.config.get('camera', 'width')
        self.frame_height = self.config.get('camera', 'height')
        self.analysis_interval = self.config.get('camera', 'analysis_interval')

        # ìƒíƒœ ë³€ìˆ˜
        self.last_analysis_time = 0
        self.current_feedback = []
        self.is_analyzing = False
        self.fps = 0
        self.analysis_count = 0

        # ë¹„ë™ê¸° ë¶„ì„ì„ ìœ„í•œ íì™€ ìŠ¤ë ˆë“œ
        self.analysis_queue = Queue(maxsize=2)
        self.result_queue = Queue()
        self.analysis_thread = None
        self.stop_analysis = False

        # ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ë¶„ì„ (í•œ ë²ˆë§Œ)
        print("\n" + "="*60)
        print("ğŸ“¸ ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
        print("="*60)
        self.ref_analyzer = ImageAnalyzer(str(reference_path))
        self.ref_data = self.ref_analyzer.analyze()
        print("âœ… ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„ ì™„ë£Œ!")

        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        self.cap = None

        # UI ì„¤ì • (configì—ì„œ ë¡œë“œ)
        self.font = cv2.FONT_HERSHEY_SIMPLEX
        self.font_scale = self.config.get('ui', 'font_scale')
        self.font_thickness = self.config.get('ui', 'font_thickness')
        self.line_height = self.config.get('ui', 'line_height')

        # ìƒ‰ìƒ (BGR) - configì—ì„œ ë¡œë“œ
        colors = self.config.get('ui', 'colors')
        self.color_bg = tuple(colors['background'])
        self.color_text = tuple(colors['text'])
        self.color_priority_high = tuple(colors['priority_high'])
        self.color_priority_mid = tuple(colors['priority_mid'])
        self.color_priority_low = tuple(colors['priority_low'])
        self.color_info = tuple(colors['info'])
        self.color_success = tuple(colors['success'])

        # í…ìŠ¤íŠ¸ ë Œë”ë§ (PIL ì‚¬ìš©: í•œê¸€ ì§€ì›)
        self.base_font_size = self.config.get('ui', 'base_font_size', default=36) or 36
        self._init_text_renderer()

        # ì„ê³„ê°’ (configì—ì„œ ë¡œë“œ)
        self.thresholds = self.config.get('thresholds')

        # Phase 3.3: ì‹œê°ì  ê°€ì´ë“œ ì˜¤ë²„ë ˆì´
        if VISUAL_GUIDE_AVAILABLE:
            self.visual_guide = VisualGuideOverlay()
            self.show_visual_guides = True  # í† ê¸€ ê°€ëŠ¥
        else:
            self.visual_guide = None
            self.show_visual_guides = False

    def _init_camera(self) -> bool:
        """ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
        self.cap = cv2.VideoCapture(self.camera_index)

        if not self.cap.isOpened():
            print(f"âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (index={self.camera_index})")
            return False

        # í•´ìƒë„ ì„¤ì •
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.frame_width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.frame_height)

        # ì‹¤ì œ í•´ìƒë„ í™•ì¸
        actual_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        print(f"âœ… ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ: {actual_width}x{actual_height}")

        return True

    def _analyze_frame(self, frame: np.ndarray) -> List[Dict]:
        """
        í”„ë ˆì„ ë¶„ì„ ë° í”¼ë“œë°± ìƒì„±

        Args:
            frame: OpenCV ì´ë¯¸ì§€ (BGR)

        Returns:
            í”¼ë“œë°± ë¦¬ìŠ¤íŠ¸
        """
        try:
            # í”„ë ˆì„ì„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp:
                tmp_path = tmp.name
                cv2.imwrite(tmp_path, frame)

            # ì‚¬ìš©ì ì´ë¯¸ì§€ ë¶„ì„
            user_analyzer = ImageAnalyzer(tmp_path)
            user_data = user_analyzer.analyze()

            # ë¹„êµ
            feedback = self._generate_feedback(self.ref_data, user_data)

            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            Path(tmp_path).unlink()

            self.analysis_count += 1

            return feedback

        except Exception as e:
            print(f"âš ï¸ í”„ë ˆì„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []

    def _analysis_worker(self):
        """ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ë˜ëŠ” ë¶„ì„ ì›Œì»¤"""
        while not self.stop_analysis:
            try:
                frame = self.analysis_queue.get(timeout=0.1)
                feedback = self._analyze_frame(frame)

                try:
                    self.result_queue.put(feedback, block=False)
                except:
                    pass

            except Empty:
                continue
            except Exception as e:
                print(f"âš ï¸ ë¶„ì„ ì›Œì»¤ ì˜¤ë¥˜: {e}")

    def _start_analysis_thread(self):
        """ë¶„ì„ ìŠ¤ë ˆë“œ ì‹œì‘"""
        if self.analysis_thread is None or not self.analysis_thread.is_alive():
            self.stop_analysis = False
            self.analysis_thread = threading.Thread(target=self._analysis_worker, daemon=True)
            self.analysis_thread.start()
            print("âœ… ë¶„ì„ ìŠ¤ë ˆë“œ ì‹œì‘")

    def _stop_analysis_thread(self):
        """ë¶„ì„ ìŠ¤ë ˆë“œ ì¢…ë£Œ"""
        self.stop_analysis = True
        if self.analysis_thread is not None:
            self.analysis_thread.join(timeout=2.0)
            print("âœ… ë¶„ì„ ìŠ¤ë ˆë“œ ì¢…ë£Œ")

    def _generate_feedback(self, ref_data: Dict, user_data: Dict) -> List[Dict]:
        """
        í”¼ë“œë°± ìƒì„± (ImageComparatorì˜ ë¡œì§ ê°„ì†Œí™” ë²„ì „)

        Returns:
            ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬ëœ í”¼ë“œë°± ë¦¬ìŠ¤íŠ¸
        """
        feedback = []

        # 1. í´ëŸ¬ìŠ¤í„° ë¹„êµ (ì •ë³´ì„±)
        ref_cluster = ref_data["cluster"]["cluster_id"]
        user_cluster = user_data["cluster"]["cluster_id"]

        if ref_cluster != user_cluster:
            feedback.append({
                "priority": 0,
                "category": "STYLE",
                "message": f"ìŠ¤íƒ€ì¼: {ref_data['cluster']['cluster_label']} â†’ {user_data['cluster']['cluster_label']}",
                "detail": "ìŠ¤íƒ€ì¼ì´ ë‹¤ë¦…ë‹ˆë‹¤"
            })
        else:
            feedback.append({
                "priority": 0,
                "category": "STYLE",
                "message": f"ìŠ¤íƒ€ì¼: {ref_data['cluster']['cluster_label']} âœ“",
                "detail": "ìŠ¤íƒ€ì¼ì´ ì¼ì¹˜í•©ë‹ˆë‹¤"
            })

        # 2. ê±°ë¦¬ ë¹„êµ
        ref_depth = ref_data["depth"]["depth_mean"]
        user_depth = user_data["depth"]["depth_mean"]
        depth_ratio = user_depth / ref_depth if ref_depth > 0 else 1.0

        if abs(depth_ratio - 1.0) > self.thresholds['depth_ratio']:
            steps = round((depth_ratio - 1.0) * 3)
            direction = "ë’¤ë¡œ" if steps > 0 else "ì•ìœ¼ë¡œ"
            steps = abs(steps)

            feedback.append({
                "priority": 2.0,
                "category": "DISTANCE",
                "message": f"{steps}ê±¸ìŒ {direction}",
                "detail": f"ê±°ë¦¬ ë¹„ìœ¨: {depth_ratio:.2f}"
            })

        # 3. ë°ê¸° ë¹„êµ
        ref_brightness = ref_data["pixels"]["brightness"]
        user_brightness = user_data["pixels"]["brightness"]
        brightness_diff = user_brightness - ref_brightness

        if abs(brightness_diff) > self.thresholds['brightness_diff']:
            ev_adjustment = brightness_diff / 30
            direction = "ì–´ë‘¡ê²Œ" if brightness_diff > 0 else "ë°ê²Œ"

            feedback.append({
                "priority": 3.0,
                "category": "BRIGHTNESS",
                "message": f"EV {ev_adjustment:+.1f} ({direction})",
                "detail": f"ë°ê¸° ì°¨ì´: {brightness_diff:+.1f}"
            })

        # 4. ìƒ‰ê° ë¹„êµ
        ref_saturation = ref_data["pixels"]["saturation"]
        user_saturation = user_data["pixels"]["saturation"]
        saturation_diff = user_saturation - ref_saturation

        if abs(saturation_diff) > self.thresholds['saturation_diff']:
            direction = "ì±„ë„ ë‚®ì¶”ê¸°" if saturation_diff > 0 else "ì±„ë„ ë†’ì´ê¸°"

            feedback.append({
                "priority": 4.0,
                "category": "COLOR",
                "message": direction,
                "detail": f"ì±„ë„ ì°¨ì´: {saturation_diff:+.2f}"
            })

        # 5. êµ¬ë„ ë¹„êµ (ê¸°ìš¸ê¸°)
        ref_tilt = ref_data["composition"]["tilt_angle"]
        user_tilt = user_data["composition"]["tilt_angle"]
        tilt_diff = user_tilt - ref_tilt

        if abs(tilt_diff) > self.thresholds['tilt_diff']:
            direction = "ì‹œê³„ë°©í–¥" if tilt_diff > 0 else "ë°˜ì‹œê³„ë°©í–¥"

            feedback.append({
                "priority": 5.0,
                "category": "COMPOSITION",
                "message": f"{abs(tilt_diff):.1f}Â° {direction} íšŒì „",
                "detail": f"ê¸°ìš¸ê¸° ì°¨ì´: {tilt_diff:+.1f}Â°"
            })

        # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬
        feedback.sort(key=lambda x: x["priority"])

        return feedback

    def _draw_overlay(self, frame: np.ndarray) -> np.ndarray:
        """í”„ë ˆì„ì— í”¼ë“œë°± ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸° (Phase 3.3 í†µí•©)"""
        h, w = frame.shape[:2]

        # ==========================================
        # Phase 3.3: ì‹œê°ì  ê°€ì´ë“œ ì˜¤ë²„ë ˆì´
        # ==========================================
        if self.show_visual_guides and self.visual_guide is not None:
            # 1. ì‚¼ë¶„í• ì„  (Rule of Thirds)
            frame = self.visual_guide.draw_rule_of_thirds(frame, thickness=1)

            # 2. ìˆ˜í‰ì„  ê°€ì´ë“œ (ê¸°ìš¸ê¸° í”¼ë“œë°±ì´ ìˆìœ¼ë©´)
            tilt_feedback = [fb for fb in self.current_feedback if fb.get('category') == 'COMPOSITION']
            if tilt_feedback:
                # í˜„ì¬ ê¸°ìš¸ê¸° ì •ë³´ ì¶”ì¶œ (ê°„ë‹¨íˆ 0ë„ë¡œ ê°€ì •, ì‹¤ì œë¡œëŠ” ë¶„ì„ ë°ì´í„°ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
                current_tilt = 0.0  # TODO: ì‹¤ì œ ê¸°ìš¸ê¸° ê°’ìœ¼ë¡œ ëŒ€ì²´
                target_tilt = 0.0
                frame = self.visual_guide.draw_horizon_line(frame, current_tilt, target_tilt)

            # 3. í”¼ë“œë°± íŒ¨ë„ (ìƒë‹¨)
            feedback_messages = [fb['message'] for fb in self.current_feedback if fb.get('priority', 99) > 0]
            if feedback_messages:
                frame = self.visual_guide.draw_feedback_panel(
                    frame,
                    feedback_messages[:3],  # ìµœëŒ€ 3ê°œ
                    position='top'
                )
                # í”¼ë“œë°± íŒ¨ë„ì´ ìˆìœ¼ë©´ ê¸°ì¡´ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ëŠ” ìŠ¤í‚µ
                # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜ (í•œê¸€ ë Œë”ë§ìš©)
                pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                draw = ImageDraw.Draw(pil_image)

                # ê°„ë‹¨í•œ í—¤ë”ë§Œ í•˜ë‹¨ì— í‘œì‹œ
                self._put_text(
                    draw,
                    f"FPS: {self.fps:.1f} | Analysis: {self.analysis_count}",
                    (10, h - 40),
                    self.color_text,
                    scale=self.font_scale * 0.7,
                    thickness=max(1, self.font_thickness - 1)
                )

                # PIL â†’ OpenCV ë³€í™˜
                return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

        # ==========================================
        # ê¸°ì¡´ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ (ì‹œê°ì  ê°€ì´ë“œ ì—†ì„ ë•Œ)
        # ==========================================
        overlay = frame.copy()

        # ë°˜íˆ¬ëª… ë°°ê²½
        overlay_height = 50 + len(self.current_feedback) * self.line_height
        cv2.rectangle(overlay, (0, 0), (w, overlay_height), self.color_bg, -1)
        frame = cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)

        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜ (í•œê¸€ ë Œë”ë§ìš©)
        pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_image)

        # í—¤ë”
        self._put_text(
            draw,
            f"TryAngle - Realtime Guide | FPS: {self.fps:.1f} | Analysis: {self.analysis_count}",
            (10, 20),
            self.color_text,
            scale=self.font_scale,
            thickness=self.font_thickness
        )

        # í”¼ë“œë°± í‘œì‹œ
        if self.current_feedback:
            info_messages = [fb for fb in self.current_feedback if fb["priority"] == 0]
            actionable_messages = [fb for fb in self.current_feedback if fb["priority"] > 0]

            y_offset = 60

            # ì •ë³´ì„± ë©”ì‹œì§€
            if info_messages:
                for fb in info_messages:
                    self._put_text(
                        draw,
                        f"  {fb['message']}",
                        (10, y_offset),
                        self.color_info,
                        scale=self.font_scale * 0.9,
                        thickness=max(1, self.font_thickness - 1)
                    )
                    y_offset += self.line_height

            # ì‹¤í–‰ ê°€ëŠ¥í•œ ë©”ì‹œì§€
            if actionable_messages:
                for i, fb in enumerate(actionable_messages, 1):
                    if fb["priority"] <= 2.0:
                        color = self.color_priority_high
                    elif fb["priority"] <= 4.0:
                        color = self.color_priority_mid
                    else:
                        color = self.color_priority_low

                    self._put_text(
                        draw,
                        f"  {i}. [{fb['category']}] {fb['message']}",
                        (10, y_offset),
                        color,
                        scale=self.font_scale,
                        thickness=self.font_thickness
                    )
                    y_offset += self.line_height
            else:
                self._put_text(
                    draw,
                    "  Perfect! No adjustments needed.",
                    (10, y_offset),
                    self.color_success,
                    scale=self.font_scale,
                    thickness=self.font_thickness
                )
        else:
            self._put_text(
                draw,
                "  Analyzing...",
                (10, 60),
                self.color_info,
                scale=self.font_scale,
                thickness=self.font_thickness
            )

        # PIL â†’ OpenCV ë³€í™˜
        frame = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

        # ë¶„ì„ ì¤‘ í‘œì‹œ
        if self.is_analyzing:
            cv2.circle(frame, (w - 30, 30), 10, (0, 0, 255), -1)

        return frame

    def _init_text_renderer(self):
        """í•œê¸€ ì§€ì›ì„ ìœ„í•œ í°íŠ¸ ë¡œë”©"""
        config_font = self.config.get('ui', 'font_path', default=None)
        font_candidates = []

        if config_font:
            font_candidates.append(config_font)

        # OSë³„ ê¸°ë³¸ í°íŠ¸ í›„ë³´
        if sys.platform == "darwin":
            font_candidates.extend([
                "/System/Library/Fonts/AppleSDGothicNeo.ttc",
                "/System/Library/Fonts/Supplemental/AppleGothic.ttf",
                "/Library/Fonts/Apple SD Gothic Neo.ttc"
            ])
        elif sys.platform.startswith("win"):
            font_candidates.extend([
                r"C:\Windows\Fonts\malgun.ttf",
                r"C:\Windows\Fonts\malgunsl.ttf",
                r"C:\Windows\Fonts\gulim.ttc"
            ])
        else:
            font_candidates.extend([
                "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
                "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
                "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
            ])

        self._font_cache = {}
        self._font_path = None

        for path in font_candidates:
            if not path:
                continue
            font_path = Path(path).expanduser()
            if font_path.exists():
                self._font_path = str(font_path)
                break

        if self._font_path is None:
            print("âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í•´ ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. (config.yamlì˜ ui.font_path ì„¤ì • ê°€ëŠ¥)")

    def _get_pil_font(self, scale: float = 1.0):
        """ìŠ¤ì¼€ì¼ì— ë§ëŠ” PIL í°íŠ¸ ìºì‹œ"""
        scale_key = round(scale, 2)
        if scale_key in self._font_cache:
            return self._font_cache[scale_key]

        font_size = max(12, int(self.base_font_size * scale))
        try:
            if self._font_path:
                font = ImageFont.truetype(self._font_path, font_size)
            else:
                font = ImageFont.load_default()
        except Exception:
            font = ImageFont.load_default()

        self._font_cache[scale_key] = font
        return font

    def _put_text(self, draw: ImageDraw.ImageDraw, text: str, position, color_bgr, scale: float = 1.0, thickness: Optional[int] = None):
        """PIL ê¸°ë°˜ í…ìŠ¤íŠ¸ ì¶œë ¥ (OpenCV ì»¬ëŸ¬ â†’ RGB ë³€í™˜)"""
        font = self._get_pil_font(scale)
        rgb_color = (int(color_bgr[2]), int(color_bgr[1]), int(color_bgr[0]))
        # PIL strokeê°€ ë‘êº¼ìš´ ê²½ìš° ë²ˆì§ì´ ìƒê¸°ë¯€ë¡œ ì‚´ì§ ì¤„ì—¬ì„œ ì‚¬ìš©
        base_thickness = self.font_thickness if thickness is None else thickness
        stroke_width = max(0, base_thickness - 2)
        stroke_kwargs = {}
        if stroke_width > 0:
            stroke_kwargs = {
                "stroke_width": stroke_width,
                "stroke_fill": rgb_color
            }

        draw.text(
            position,
            text,
            font=font,
            fill=rgb_color,
            **stroke_kwargs
        )

    def run(self):
        """
        ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”¼ë“œë°± ì‹œìŠ¤í…œ ì‹¤í–‰

        Controls:
            - 'q': ì¢…ë£Œ
            - 'r': ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ì¬ë¶„ì„
            - 's': í˜„ì¬ í”„ë ˆì„ ì €ì¥
            - 'g': ì‹œê°ì  ê°€ì´ë“œ í† ê¸€ (Phase 3.3)
            - SPACE: ë¶„ì„ ì¼ì‹œì •ì§€/ì¬ê°œ
        """

        if not self._init_camera():
            return

        print("\n" + "="*60)
        print("ğŸ“¹ ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”¼ë“œë°± ì‹œì‘ (Phase 1-3 í†µí•©)")
        print("="*60)
        print("\nì¡°ì‘ë²•:")
        print("  - 'q': ì¢…ë£Œ")
        print("  - 'r': ë ˆí¼ëŸ°ìŠ¤ ì¬ë¶„ì„")
        print("  - 'g': ì‹œê°ì  ê°€ì´ë“œ ON/OFF")
        print("  - 's': í˜„ì¬ í”„ë ˆì„ ì €ì¥")
        print("  - SPACE: ë¶„ì„ ì¼ì‹œì •ì§€/ì¬ê°œ")
        print("\n" + "="*60 + "\n")

        paused = False
        frame_count = 0
        start_time = time.time()

        # ë¶„ì„ ìŠ¤ë ˆë“œ ì‹œì‘
        self._start_analysis_thread()

        try:
            while True:
                ret, frame = self.cap.read()

                if not ret:
                    print("âŒ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    break

                frame_count += 1
                current_time = time.time()

                # FPS ê³„ì‚°
                elapsed = current_time - start_time
                if elapsed > 0:
                    self.fps = frame_count / elapsed

                # ì£¼ê¸°ì  ë¶„ì„
                if not paused and (current_time - self.last_analysis_time >= self.analysis_interval):
                    try:
                        self.analysis_queue.put(frame.copy(), block=False)
                        self.is_analyzing = True
                        self.last_analysis_time = current_time
                    except:
                        pass

                # ë¶„ì„ ê²°ê³¼ í™•ì¸
                try:
                    feedback = self.result_queue.get(block=False)
                    self.current_feedback = feedback
                    self.is_analyzing = False
                except Empty:
                    pass

                # ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸°
                display_frame = self._draw_overlay(frame)

                # í™”ë©´ í‘œì‹œ
                cv2.imshow('TryAngle - Realtime Camera', display_frame)

                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF

                if key == ord('q'):
                    print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤")
                    break
                elif key == ord('r'):
                    print("\nğŸ”„ ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ì¬ë¶„ì„...")
                    self.ref_analyzer = ImageAnalyzer(str(self.reference_path))
                    self.ref_data = self.ref_analyzer.analyze()
                    print("âœ… ì¬ë¶„ì„ ì™„ë£Œ!")
                elif key == ord('s'):
                    save_path = Path(f"capture_{int(time.time())}.jpg")
                    cv2.imwrite(str(save_path), frame)
                    print(f"ğŸ’¾ í”„ë ˆì„ ì €ì¥: {save_path}")
                elif key == ord('g'):
                    # Phase 3.3: ì‹œê°ì  ê°€ì´ë“œ í† ê¸€
                    if self.visual_guide is not None:
                        self.show_visual_guides = not self.show_visual_guides
                        status = "ON" if self.show_visual_guides else "OFF"
                        print(f"ğŸ‘ï¸ ì‹œê°ì  ê°€ì´ë“œ: {status}")
                    else:
                        print("âš ï¸ ì‹œê°ì  ê°€ì´ë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                elif key == ord(' '):
                    paused = not paused
                    status = "ì¼ì‹œì •ì§€" if paused else "ì¬ê°œ"
                    print(f"â¸ï¸ ë¶„ì„ {status}")

        except KeyboardInterrupt:
            print("\nâš ï¸ ì‚¬ìš©ì ì¤‘ë‹¨")

        finally:
            self._stop_analysis_thread()
            self.cap.release()
            cv2.destroyAllWindows()
            print("\nâœ… ì¹´ë©”ë¼ ì¢…ë£Œ")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""

    # ì„¤ì • ë¡œë“œ
    config = Config()

    # ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ê²½ë¡œ
    test_images_dir = config.get_path('paths', 'test_images_dir')
    default_ref = config.get('paths', 'default_reference')
    reference_path = test_images_dir / default_ref

    # ê²½ë¡œ í™•ì¸
    if not reference_path.exists():
        print(f"âŒ ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_path}")
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {test_images_dir}")

        if test_images_dir.exists():
            print("\nì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¯¸ì§€:")
            for f in test_images_dir.iterdir():
                if f.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                    print(f"  - {f.name}")
        return

    try:
        # ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ë¶„ì„ê¸° ìƒì„±
        analyzer = RealtimeCameraAnalyzer(
            reference_path=reference_path,
            config=config
        )

        # ì‹¤í–‰
        analyzer.run()

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
