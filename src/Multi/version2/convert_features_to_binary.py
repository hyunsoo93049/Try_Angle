import os
import time
import glob
import gc
import numpy as np
import psutil
import polars as pl
from typing import Optional, Any
from pathlib import Path

# ---- ì„¤ì • ----
PROJECT_ROOT = Path(__file__).resolve().parent
while PROJECT_ROOT != PROJECT_ROOT.parent and not ((PROJECT_ROOT / "data").exists() and (PROJECT_ROOT / "src").exists()):
    PROJECT_ROOT = PROJECT_ROOT.parent

BASE_DIR = PROJECT_ROOT / "src" / "Multi" / "version2" / "features"
CSV_PATH = PROJECT_ROOT / "features" / "clip_dino_midas_features.csv"
TMP_PARQDIR = BASE_DIR / "tmp_parquet_chunks"
FINAL_PARQ = BASE_DIR / "clip_dino_midas_features.parquet"
NPZ_DIR = BASE_DIR / "npz_shards"
BATCH_SIZE = 50  # ğŸ’¡ ìë™ resume ì‹œ ì•ˆì „í•œ ë°°ì¹˜ í¬ê¸°


def get_csv_info(csv_path: str):
    """CSV í—¤ë”ì™€ ì´ í–‰ ìˆ˜ í™•ì¸"""
    print(f"\nğŸ“‚ CSV íŒŒì¼: {csv_path}")
    print("â³ íŒŒì¼ ë¶„ì„ ì¤‘...")
    with open(csv_path, "r", encoding="utf-8", errors="ignore") as f:
        header_line = f.readline().strip()
        if not header_line:
            raise ValueError("CSV íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ í—¤ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        headers = [h.strip() for h in header_line.split(",")]
        total_rows = sum(1 for line in f if line.strip())
    print(f"âœ… ì»¬ëŸ¼ ìˆ˜: {len(headers)}ê°œ")
    print(f"âœ… ì´ í–‰ ìˆ˜: {total_rows:,}í–‰ (í—¤ë” ì œì™¸)")
    return headers, total_rows


def infer_schema_minimal(csv_path: str):
    """ìµœì†Œí•œì˜ í–‰ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ì¶”ë¡ """
    print("â³ ìŠ¤í‚¤ë§ˆ ì¶”ë¡  ì¤‘...")
    sample = pl.read_csv(csv_path, n_rows=10, infer_schema_length=10, low_memory=True)
    schema = sample.schema
    del sample
    gc.collect()
    return schema


def get_numeric_cols(schema: dict) -> list[str]:
    """ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì„ ë³„"""
    numeric_types = (
        pl.Int8, pl.Int16, pl.Int32, pl.Int64,
        pl.UInt8, pl.UInt16, pl.UInt32, pl.UInt64,
        pl.Float32, pl.Float64
    )
    return [col for col, dtype in schema.items() if col != "filename" and dtype in numeric_types]


def save_chunk_atomic(df: pl.DataFrame, chunk_id: int, parquet_path: str, npz_path: str, numeric_cols: list[str]) -> bool:
    """ì›ìì  ì²­í¬ ì €ì¥"""
    temp_parquet = parquet_path + ".tmp"
    temp_npz = npz_path + ".tmp"
    try:
        df.write_parquet(temp_parquet, compression="snappy", use_pyarrow=False)
        filenames = df["filename"].to_numpy()
        X = df.select(numeric_cols).to_numpy().astype(np.float16, copy=False)
        with open(temp_npz, "wb") as f:
            np.savez_compressed(f, X=X, filenames=filenames)
            f.flush()
            os.fsync(f.fileno())
        os.replace(temp_parquet, parquet_path)
        os.replace(temp_npz, npz_path)
        return True
    except Exception as e:
        for tmp in (temp_parquet, temp_npz):
            if os.path.exists(tmp):
                try:
                    os.remove(tmp)
                except:
                    pass
        print(f"âŒ ì²­í¬ {chunk_id} ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def cleanup_temp_files():
    """ì„ì‹œíŒŒì¼ ì •ë¦¬"""
    for pattern in ["*.tmp", "*.tmp.npz"]:
        for p in glob.glob(os.path.join(str(NPZ_DIR), pattern)):
            try:
                os.remove(p)
            except:
                pass


def show_memory():
    """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰(MB) ì¶œë ¥"""
    mem = psutil.virtual_memory()
    return f"{mem.used / (1024**2):,.0f}MB / {mem.total / (1024**2):,.0f}MB"


def find_resume_point():
    """ë§ˆì§€ë§‰ìœ¼ë¡œ ì™„ì„±ëœ ì²­í¬ ë‹¤ìŒ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜"""
    npz_files = sorted(glob.glob(os.path.join(str(NPZ_DIR), "shard_*.npz")))
    if not npz_files:
        return 0
    last_file = npz_files[-1]
    last_idx = int(os.path.basename(last_file).split("_")[1].split(".")[0])
    return last_idx


def main():
    print("=" * 70)
    print("CSV â†’ Parquet + NPZ ë³€í™˜ (Auto-Resume + Memory Monitor)")
    print("=" * 70)

    os.makedirs(BASE_DIR, exist_ok=True)
    os.makedirs(TMP_PARQDIR, exist_ok=True)
    os.makedirs(NPZ_DIR, exist_ok=True)
    cleanup_temp_files()

    if not os.path.exists(CSV_PATH):
        raise FileNotFoundError(f"âŒ CSV íŒŒì¼ ì—†ìŒ: {CSV_PATH}")

    headers, total_rows = get_csv_info(CSV_PATH)
    schema = infer_schema_minimal(CSV_PATH)
    numeric_cols = get_numeric_cols(schema)
    expected_feature_count = len(numeric_cols)
    total_chunks = (total_rows + BATCH_SIZE - 1) // BATCH_SIZE

    print(f"âœ… ìˆ«ìí˜• ì»¬ëŸ¼ ìˆ˜: {expected_feature_count}")
    print(f"âœ… ì´ ì²­í¬ ìˆ˜: {total_chunks}")

    # ìë™ resume ìœ„ì¹˜ ì°¾ê¸°
    resume_from = find_resume_point()
    if resume_from >= total_chunks:
        print("\nâœ… ëª¨ë“  ì²­í¬ ì´ë¯¸ ì™„ë£Œë¨. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    print(f"\nğŸ” ì´ì–´ì„œ ì‹¤í–‰: {resume_from + 1}ë²ˆ ì²­í¬ë¶€í„° ì‹œì‘")
    start_time = time.time()

    for chunk_idx in range(resume_from, total_chunks):
        chunk_id = chunk_idx + 1
        skip_rows = chunk_idx * BATCH_SIZE
        parquet_path = os.path.join(TMP_PARQDIR, f"chunk_{chunk_id:05d}.parquet")
        npz_path = os.path.join(NPZ_DIR, f"shard_{chunk_id:05d}.npz")

        if os.path.exists(parquet_path) and os.path.exists(npz_path):
            print(f"â­ï¸ ì²­í¬ {chunk_id}/{total_chunks} - ì´ë¯¸ ì¡´ì¬ (ìŠ¤í‚µ)")
            continue

        try:
            df = pl.read_csv(
                CSV_PATH,
                skip_rows=skip_rows + (1 if chunk_idx > 0 else 0),
                n_rows=BATCH_SIZE,
                schema=schema if chunk_idx > 0 else None,
                has_header=(chunk_idx == 0),
                low_memory=True
            )
        except Exception as e:
            print(f"âŒ ì²­í¬ {chunk_id} ì½ê¸° ì‹¤íŒ¨: {e}")
            break

        if df.height == 0:
            print(f"âœ… ì²­í¬ {chunk_id}: ë°ì´í„° ì—†ìŒ â†’ ì¢…ë£Œ")
            break

        ok = save_chunk_atomic(df, chunk_id, parquet_path, npz_path, numeric_cols)
        del df
        gc.collect()

        mem_status = show_memory()
        if ok:
            print(f"âœ… ì²­í¬ {chunk_id:3d}/{total_chunks} ì™„ë£Œ | ë©”ëª¨ë¦¬: {mem_status}")
        else:
            print(f"âŒ ì²­í¬ {chunk_id:3d} ì‹¤íŒ¨ | ë©”ëª¨ë¦¬: {mem_status}")
            break

    print("\nğŸ‰ ëª¨ë“  ì²­í¬ ë³€í™˜ ì¢…ë£Œ")
    total_elapsed = time.time() - start_time
    H, rem = divmod(int(total_elapsed), 3600)
    M, S = divmod(rem, 60)
    print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {H:02d}:{M:02d}:{S:02d}")
    print("=" * 70)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ì ì¤‘ë‹¨ - ë‹¤ìŒ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ì´ì–´ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
