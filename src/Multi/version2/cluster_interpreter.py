# ======================================================
# ğŸ§  TryAngle Cluster Interpreter
# ê° í´ëŸ¬ìŠ¤í„°ì˜ ì˜ë¯¸ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ê³  ë¼ë²¨ë§
# ======================================================

import os
import numpy as np
import polars as pl
import cv2
from collections import Counter
from ultralytics import YOLO
from tqdm import tqdm
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parent
while PROJECT_ROOT != PROJECT_ROOT.parent and not ((PROJECT_ROOT / "data").exists() and (PROJECT_ROOT / "src").exists()):
    PROJECT_ROOT = PROJECT_ROOT.parent

# ------------------------------------------------------
# [1] ê²½ë¡œ ì„¤ì •
# ------------------------------------------------------
PARQUET_PATH = PROJECT_ROOT / "features" / "clustered_umap_v2_result.parquet"
IMG_DIR = PROJECT_ROOT / "data" / "train_images"
YOLO_WEIGHTS = "yolov8s-pose.pt"

# ------------------------------------------------------
# [2] ë°ì´í„° ë¡œë“œ
# ------------------------------------------------------
print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
df = pl.read_parquet(PARQUET_PATH)
print(f"âœ… ë¡œë“œ ì™„ë£Œ: {len(df)}ì¥")

# YOLO ëª¨ë¸ ë¡œë“œ
print("ğŸ”§ YOLO Pose ëª¨ë¸ ë¡œë“œ ì¤‘...")
yolo = YOLO(YOLO_WEIGHTS)

# ------------------------------------------------------
# [3] ìƒ‰ê° ë¶„ì„ í•¨ìˆ˜
# ------------------------------------------------------
def analyze_color_tone(image_paths, max_samples=50):
    """ì´ë¯¸ì§€ë“¤ì˜ í‰ê·  ìƒ‰ê° ë¶„ì„"""
    hues, sats, vals = [], [], []
    temps = []  # ìƒ‰ì˜¨ë„
    
    for path in image_paths[:max_samples]:
        img = cv2.imread(path)
        if img is None:
            continue
        
        # HSV ë¶„ì„
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        hues.append(hsv[:,:,0].mean())
        sats.append(hsv[:,:,1].mean())
        vals.append(hsv[:,:,2].mean())
        
        # ìƒ‰ì˜¨ë„ (R-B ë¹„ìœ¨)
        b, g, r = cv2.split(img)
        temp = (r.mean() - b.mean()) / 255.0
        temps.append(temp)
    
    if not hues:
        return None
    
    avg_hue = np.mean(hues)
    avg_sat = np.mean(sats)
    avg_val = np.mean(vals)
    avg_temp = np.mean(temps)
    
    # ìƒ‰ì˜¨ë„ íŒë‹¨
    if avg_temp > 0.15:
        tone = "ì›œí†¤"
    elif avg_temp < -0.15:
        tone = "ì¿¨í†¤"
    else:
        tone = "ì¤‘ê°„í†¤"
    
    # ë°ê¸° íŒë‹¨
    if avg_val > 160:
        brightness = "ë°ìŒ"
    elif avg_val > 100:
        brightness = "ë³´í†µ"
    else:
        brightness = "ì–´ë‘ì›€"
    
    # ì±„ë„ íŒë‹¨
    if avg_sat > 120:
        saturation = "ë†’ìŒ"
    elif avg_sat > 60:
        saturation = "ë³´í†µ"
    else:
        saturation = "ë‚®ìŒ"
    
    return {
        "tone": tone,
        "brightness": brightness,
        "saturation": saturation,
        "avg_hue": avg_hue,
        "avg_sat": avg_sat,
        "avg_val": avg_val,
        "avg_temp": avg_temp
    }

# ------------------------------------------------------
# [4] í¬ì¦ˆ ë¶„ì„ í•¨ìˆ˜
# ------------------------------------------------------
def analyze_pose_patterns(image_paths, yolo_model, max_samples=30):
    """í¬ì¦ˆ íŒ¨í„´ ë¶„ì„ (ì „ì‹ /ë°˜ì‹ /í´ë¡œì¦ˆì—…)"""
    pose_types = []
    pose_angles = []  # ìƒí•˜ ê°ë„
    
    for path in image_paths[:max_samples]:
        img = cv2.imread(path)
        if img is None:
            continue
        
        try:
            results = yolo_model(img, verbose=False)
            if not results or results[0].boxes is None or len(results[0].boxes) == 0:
                continue
            
            bbox = results[0].boxes.xyxy[0].cpu().numpy()
            x1, y1, x2, y2 = bbox
            
            # ì¸ë¬¼ ì„¸ë¡œ ë¹„ìœ¨
            h_ratio = (y2 - y1) / img.shape[0]
            
            if h_ratio > 0.65:
                pose_types.append("ì „ì‹ ")
            elif h_ratio > 0.35:
                pose_types.append("ë°˜ì‹ ")
            else:
                pose_types.append("í´ë¡œì¦ˆì—…")
            
            # ì¸ë¬¼ ìœ„ì¹˜ (ìƒë‹¨/ì¤‘ë‹¨/í•˜ë‹¨)
            center_y = (y1 + y2) / 2 / img.shape[0]
            pose_angles.append(center_y)
            
        except Exception as e:
            continue
    
    if not pose_types:
        return None
    
    # ìµœë¹ˆê°’
    pose_type = Counter(pose_types).most_common(1)[0][0]
    
    # í‰ê·  ìœ„ì¹˜
    avg_position = np.mean(pose_angles)
    if avg_position < 0.4:
        position = "ìƒë‹¨"
    elif avg_position < 0.6:
        position = "ì¤‘ì•™"
    else:
        position = "í•˜ë‹¨"
    
    return {
        "pose_type": pose_type,
        "position": position,
        "avg_position": avg_position,
        "distribution": Counter(pose_types)
    }

# ------------------------------------------------------
# [5] êµ¬ë„ ë¶„ì„ í•¨ìˆ˜
# ------------------------------------------------------
def analyze_composition(image_paths, max_samples=30):
    """êµ¬ë„ íŠ¹ì„± ë¶„ì„"""
    aspect_ratios = []
    
    for path in image_paths[:max_samples]:
        img = cv2.imread(path)
        if img is None:
            continue
        
        h, w = img.shape[:2]
        aspect_ratios.append(w / h)
    
    if not aspect_ratios:
        return None
    
    avg_aspect = np.mean(aspect_ratios)
    
    # ì¢…íš¡ë¹„ íŒë‹¨
    if avg_aspect > 1.4:
        aspect = "ê°€ë¡œí˜•"
    elif avg_aspect < 0.8:
        aspect = "ì„¸ë¡œí˜•"
    else:
        aspect = "ì •ë°©í˜•"
    
    return {
        "aspect": aspect,
        "avg_aspect_ratio": avg_aspect
    }

# ------------------------------------------------------
# [6] í´ëŸ¬ìŠ¤í„° ì¢…í•© ë¶„ì„
# ------------------------------------------------------
def analyze_cluster_comprehensive(cluster_id):
    """í´ëŸ¬ìŠ¤í„° ì¢…í•© ë¶„ì„"""
    print(f"\n{'='*70}")
    print(f"ğŸ” Cluster {cluster_id} ë¶„ì„ ì¤‘...")
    print(f"{'='*70}")
    
    # í´ëŸ¬ìŠ¤í„° ë°ì´í„° í•„í„°ë§
    cluster_df = df.filter(pl.col("cluster") == cluster_id)
    cluster_size = len(cluster_df)
    
    print(f"ğŸ“Š ì´ {cluster_size}ì¥")
    
    # íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    image_paths = [
        str(IMG_DIR / os.path.basename(fname))
        for fname in cluster_df["filename"].to_list()
    ]
    
    # 1. MiDaS Depth ë¶„ì„
    avg_depth = cluster_df["midas_mean"].mean()
    avg_depth_std = cluster_df["midas_std"].mean()
    
    if avg_depth > 1050:
        depth_class = "ì‹¤ì™¸/ì›ê±°ë¦¬"
    elif avg_depth > 950:
        depth_class = "í˜¼í•©"
    else:
        depth_class = "ì‹¤ë‚´/ê·¼ì ‘"
    
    print(f"\nğŸ“ [Depth ë¶„ì„]")
    print(f"  í‰ê·  Depth: {avg_depth:.1f}")
    print(f"  ë¶„ì‚°: {avg_depth_std:.1f}")
    print(f"  íŒë‹¨: {depth_class}")
    
    # 2. ìƒ‰ê° ë¶„ì„
    print(f"\nğŸ¨ [ìƒ‰ê° ë¶„ì„ ì¤‘...]")
    color_result = analyze_color_tone(image_paths, max_samples=50)
    
    if color_result:
        print(f"  ìƒ‰ì˜¨ë„: {color_result['tone']}")
        print(f"  ë°ê¸°: {color_result['brightness']}")
        print(f"  ì±„ë„: {color_result['saturation']}")
        print(f"  ì„¸ë¶€: H={color_result['avg_hue']:.1f}, S={color_result['avg_sat']:.1f}, V={color_result['avg_val']:.1f}")
    else:
        print("  âš ï¸ ìƒ‰ê° ë¶„ì„ ì‹¤íŒ¨")
        color_result = {"tone": "ì•Œ ìˆ˜ ì—†ìŒ", "brightness": "ì•Œ ìˆ˜ ì—†ìŒ", "saturation": "ì•Œ ìˆ˜ ì—†ìŒ"}
    
    # 3. í¬ì¦ˆ ë¶„ì„
    print(f"\nğŸ•º [í¬ì¦ˆ ë¶„ì„ ì¤‘...]")
    pose_result = analyze_pose_patterns(image_paths, yolo, max_samples=30)
    
    if pose_result:
        print(f"  í¬ì¦ˆ ìœ í˜•: {pose_result['pose_type']}")
        print(f"  ì¸ë¬¼ ìœ„ì¹˜: {pose_result['position']}")
        print(f"  ë¶„í¬: {dict(pose_result['distribution'])}")
    else:
        print("  âš ï¸ í¬ì¦ˆ ë¶„ì„ ì‹¤íŒ¨")
        pose_result = {"pose_type": "ì•Œ ìˆ˜ ì—†ìŒ", "position": "ì•Œ ìˆ˜ ì—†ìŒ"}
    
    # 4. êµ¬ë„ ë¶„ì„
    print(f"\nğŸ“¸ [êµ¬ë„ ë¶„ì„ ì¤‘...]")
    comp_result = analyze_composition(image_paths, max_samples=30)
    
    if comp_result:
        print(f"  í™”ë©´ ë¹„ìœ¨: {comp_result['aspect']} (í‰ê·  {comp_result['avg_aspect_ratio']:.2f})")
    else:
        print("  âš ï¸ êµ¬ë„ ë¶„ì„ ì‹¤íŒ¨")
        comp_result = {"aspect": "ì•Œ ìˆ˜ ì—†ìŒ"}
    
    # 5. ìë™ ë¼ë²¨ ìƒì„±
    label_parts = []
    
    if depth_class != "í˜¼í•©":
        label_parts.append(depth_class.split("/")[0])
    
    if color_result["tone"] != "ì¤‘ê°„í†¤":
        label_parts.append(color_result["tone"])
    
    if color_result["brightness"] in ["ë°ìŒ", "ì–´ë‘ì›€"]:
        label_parts.append(color_result["brightness"])
    
    if pose_result["pose_type"] != "ì•Œ ìˆ˜ ì—†ìŒ":
        label_parts.append(pose_result["pose_type"])
    
    auto_label = "_".join(label_parts) if label_parts else "ì¼ë°˜_ìŠ¤íƒ€ì¼"
    
    print(f"\nğŸ’¡ [ìë™ ë¼ë²¨]")
    print(f"  â†’ {auto_label}")
    
    # 6. ëŒ€í‘œ ì´ë¯¸ì§€ ì¶”ì²œ
    print(f"\nğŸ–¼ï¸ [ëŒ€í‘œ ì´ë¯¸ì§€ 3ì¥]")
    sample_files = cluster_df["filename"][:3].to_list()
    for i, fname in enumerate(sample_files, 1):
        print(f"  {i}. {fname}")
    
    return {
        "cluster_id": cluster_id,
        "size": cluster_size,
        "depth_class": depth_class,
        "avg_depth": avg_depth,
        "color": color_result,
        "pose": pose_result,
        "composition": comp_result,
        "auto_label": auto_label,
        "representative_images": sample_files
    }

# ------------------------------------------------------
# [7] ì „ì²´ í´ëŸ¬ìŠ¤í„° ë¶„ì„ ì‹¤í–‰
# ------------------------------------------------------
def main():
    print("\n" + "="*70)
    print("ğŸ§  TryAngle Cluster Interpreter")
    print("="*70)
    
    n_clusters = df["cluster"].n_unique()
    print(f"\nì´ {n_clusters}ê°œ í´ëŸ¬ìŠ¤í„° ë¶„ì„ ì‹œì‘\n")
    
    all_results = []
    
    for c in range(n_clusters):
        result = analyze_cluster_comprehensive(c)
        all_results.append(result)
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "="*70)
    print("ğŸ“‹ ì „ì²´ í´ëŸ¬ìŠ¤í„° ìš”ì•½")
    print("="*70)
    
    for result in all_results:
        print(f"\nCluster {result['cluster_id']}: {result['auto_label']} ({result['size']}ì¥)")
        print(f"  - {result['depth_class']}, {result['color']['tone']}, {result['pose']['pose_type']}")
    
    print("\nâœ… í´ëŸ¬ìŠ¤í„° í•´ì„ ì™„ë£Œ!")
    
    # ê²°ê³¼ ì €ì¥ (ì„ íƒì‚¬í•­)
    import json
    output_path = PROJECT_ROOT / "features" / "cluster_interpretation.json"
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")

# ------------------------------------------------------
# [8] ì‹¤í–‰
# ------------------------------------------------------
if __name__ == "__main__":
    main()


## ğŸ’¾ ì €ì¥ ë°©ë²•

#íŒŒì¼ëª…: cluster_interpreter.py
#ìœ„ì¹˜: <í”„ë¡œì íŠ¸ ë£¨íŠ¸>/src/Multi/version2/
