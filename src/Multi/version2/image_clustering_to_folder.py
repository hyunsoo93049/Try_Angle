# ======================================================
# ğŸ§  TryAngle Deep Cluster Analysis
# CLIP/OpenCLIP/DINO/MiDaS ê´€ì ë³„ ì‹¬ì¸µ ë¶„ì„
# ======================================================

import os
import numpy as np
import polars as pl
import cv2
import json
from collections import Counter
from ultralytics import YOLO
from tqdm import tqdm
from datetime import datetime
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parent
while PROJECT_ROOT != PROJECT_ROOT.parent and not ((PROJECT_ROOT / "data").exists() and (PROJECT_ROOT / "src").exists()):
    PROJECT_ROOT = PROJECT_ROOT.parent

# ------------------------------------------------------
# [1] ê²½ë¡œ ì„¤ì •
# ------------------------------------------------------
PARQUET_PATH = PROJECT_ROOT / "features" / "clustered_umap_v2_result.parquet"
IMG_DIR = PROJECT_ROOT / "data" / "train_images"
CLUSTER_DIR = PROJECT_ROOT / "data" / "clustered_images"
YOLO_WEIGHTS = "yolov8s-pose.pt"

# ------------------------------------------------------
# [2] ë°ì´í„° ë¡œë“œ
# ------------------------------------------------------
print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
df = pl.read_parquet(PARQUET_PATH)
print(f"âœ… ì´ {len(df)}ì¥ ë¡œë“œ")

print("ğŸ”§ YOLO ëª¨ë¸ ë¡œë“œ ì¤‘...")
yolo = YOLO(YOLO_WEIGHTS)

# ------------------------------------------------------
# [3] ëª¨ë¸ë³„ íŠ¹ì§• ë¶„ì„ í•¨ìˆ˜
# ------------------------------------------------------

def analyze_clip_features(cluster_df):
    """CLIP íŠ¹ì§• ë¶„ì„ (ê°ì„±/ì „ì²´ì  ë¶„ìœ„ê¸°)"""
    clip_cols = [c for c in cluster_df.columns if c.startswith("clip_")]
    if not clip_cols:
        return None
    
    clip_feats = cluster_df.select(clip_cols).to_numpy()
    
    # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ (í‰ê· )
    clip_center = clip_feats.mean(axis=0)
    
    # í´ëŸ¬ìŠ¤í„° ë‚´ ë¶„ì‚°
    clip_std = clip_feats.std(axis=0).mean()
    
    # íŠ¹ì§• í™œì„±í™” íŒ¨í„´ (ìƒìœ„ 10ê°œ ì°¨ì›)
    top_dims = np.argsort(np.abs(clip_center))[-10:][::-1]
    top_values = clip_center[top_dims]
    
    return {
        "model": "CLIP (ViT-B/32)",
        "purpose": "ì „ì²´ì  ê°ì„±/ë¶„ìœ„ê¸° ì¸ì‹",
        "dimensions": len(clip_cols),
        "cluster_cohesion": float(1.0 / (clip_std + 1e-6)),  # ë†’ì„ìˆ˜ë¡ ì‘ì§‘ë„ ë†’ìŒ
        "top_activated_dims": top_dims.tolist()[:5],
        "top_values": top_values.tolist()[:5],
        "interpretation": interpret_clip_pattern(clip_center)
    }

def interpret_clip_pattern(clip_center):
    """CLIP íŒ¨í„´ í•´ì„ (íœ´ë¦¬ìŠ¤í‹±)"""
    # ì ˆëŒ€ê°’ ìƒìœ„ ì°¨ì› ë¶„ì„
    strong_features = np.abs(clip_center) > 0.1
    activation_rate = strong_features.sum() / len(clip_center)
    
    if activation_rate > 0.3:
        return "ë³µì¡í•˜ê³  ë‹¤ì–‘í•œ ì‹œê°ì  ìš”ì†Œ í¬í•¨"
    elif activation_rate > 0.15:
        return "ì¤‘ê°„ ë³µì¡ë„ì˜ êµ¬ì„±"
    else:
        return "ë‹¨ìˆœí•˜ê³  ëª…í™•í•œ êµ¬ì„±"

def analyze_openclip_features(cluster_df):
    """OpenCLIP íŠ¹ì§• ë¶„ì„ (ì˜ë¯¸ì  ì´í•´)"""
    openclip_cols = [c for c in cluster_df.columns if c.startswith("openclip_")]
    if not openclip_cols:
        return None
    
    openclip_feats = cluster_df.select(openclip_cols).to_numpy()
    
    openclip_center = openclip_feats.mean(axis=0)
    openclip_std = openclip_feats.std(axis=0).mean()
    
    top_dims = np.argsort(np.abs(openclip_center))[-10:][::-1]
    top_values = openclip_center[top_dims]
    
    return {
        "model": "OpenCLIP (ViT-B/32, LAION-2B)",
        "purpose": "ì˜ë¯¸ì  ê°œë… ì´í•´",
        "dimensions": len(openclip_cols),
        "cluster_cohesion": float(1.0 / (openclip_std + 1e-6)),
        "top_activated_dims": top_dims.tolist()[:5],
        "top_values": top_values.tolist()[:5],
        "interpretation": interpret_openclip_pattern(openclip_center)
    }

def interpret_openclip_pattern(openclip_center):
    """OpenCLIP íŒ¨í„´ í•´ì„"""
    activation_strength = np.abs(openclip_center).mean()
    
    if activation_strength > 0.08:
        return "ê°•í•œ ê°œë…ì  íŠ¹ì§• (íŠ¹ì • ì¥ì†Œ/ì‚¬ë¬¼/ìŠ¤íƒ€ì¼)"
    elif activation_strength > 0.04:
        return "ì¤‘ê°„ ê°•ë„ì˜ ì˜ë¯¸ì  íŠ¹ì§•"
    else:
        return "ì¼ë°˜ì ì´ê³  ë³´í¸ì ì¸ íŠ¹ì§•"

def analyze_dino_features(cluster_df):
    """DINO íŠ¹ì§• ë¶„ì„ (êµ¬ì¡°/êµ¬ë„)"""
    dino_cols = [c for c in cluster_df.columns if c.startswith("dino_")]
    if not dino_cols:
        return None
    
    dino_feats = cluster_df.select(dino_cols).to_numpy()
    
    dino_center = dino_feats.mean(axis=0)
    dino_std = dino_feats.std(axis=0).mean()
    
    top_dims = np.argsort(np.abs(dino_center))[-10:][::-1]
    top_values = dino_center[top_dims]
    
    # DINOëŠ” êµ¬ì¡° ì •ë³´ ì¤‘ì‹¬
    spatial_consistency = 1.0 / (dino_std + 1e-6)
    
    return {
        "model": "DINOv2 (ViT-S/14)",
        "purpose": "êµ¬ì¡°ì  íŒ¨í„´/êµ¬ë„ ì¸ì‹",
        "dimensions": len(dino_cols),
        "spatial_consistency": float(spatial_consistency),
        "cluster_cohesion": float(spatial_consistency),
        "top_activated_dims": top_dims.tolist()[:5],
        "top_values": top_values.tolist()[:5],
        "interpretation": interpret_dino_pattern(dino_center, spatial_consistency)
    }

def interpret_dino_pattern(dino_center, consistency):
    """DINO íŒ¨í„´ í•´ì„"""
    if consistency > 20:
        return "ë§¤ìš° ì¼ê´€ëœ êµ¬ë„/ë ˆì´ì•„ì›ƒ (ìœ ì‚¬í•œ í”„ë ˆì´ë°)"
    elif consistency > 10:
        return "ì¤‘ê°„ ì •ë„ì˜ êµ¬ë„ ì¼ê´€ì„±"
    else:
        return "ë‹¤ì–‘í•œ êµ¬ë„ íŒ¨í„´ í˜¼ì¬"

def analyze_midas_features(cluster_df):
    """MiDaS íŠ¹ì§• ë¶„ì„ (ê¹Šì´/ê³µê°„)"""
    midas_mean = cluster_df["midas_mean"].to_numpy()
    midas_std = cluster_df["midas_std"].to_numpy()
    
    avg_depth = midas_mean.mean()
    depth_variance = midas_mean.std()
    avg_complexity = midas_std.mean()
    complexity_variance = midas_std.std()
    
    # ê¹Šì´ ë¶„ë¥˜
    if avg_depth > 1050:
        depth_class = "ì‹¤ì™¸/ì›ê±°ë¦¬"
        space_type = "ê°œë°©ëœ ê³µê°„"
    elif avg_depth > 950:
        depth_class = "ê²½ê³„ ê³µê°„"
        space_type = "ì‹¤ë‚´ì™¸ ê²½ê³„ (ì¹´í˜ ì°½ê°€, ë³µë„ ë“±)"
    else:
        depth_class = "ì‹¤ë‚´/ê·¼ì ‘"
        space_type = "íì‡„ëœ ê³µê°„"
    
    # ë³µì¡ë„ ë¶„ë¥˜
    if avg_complexity > 850:
        complexity = "ë†’ìŒ (ë³µì¡í•œ ë°°ê²½)"
    elif avg_complexity > 700:
        complexity = "ì¤‘ê°„"
    else:
        complexity = "ë‚®ìŒ (ë‹¨ìˆœí•œ ë°°ê²½)"
    
    # ì¼ê´€ì„±
    consistency_score = 1.0 / (depth_variance + 1e-6)
    
    return {
        "model": "MiDaS (DPT-Hybrid)",
        "purpose": "ê¹Šì´/ê³µê°„ êµ¬ì¡° ì¸ì‹",
        "avg_depth": float(avg_depth),
        "depth_variance": float(depth_variance),
        "avg_complexity": float(avg_complexity),
        "depth_class": depth_class,
        "space_type": space_type,
        "background_complexity": complexity,
        "depth_consistency": float(consistency_score),
        "interpretation": f"{space_type}, {complexity} ë°°ê²½ ë³µì¡ë„"
    }

# ------------------------------------------------------
# [4] ìƒ‰ê° ë¶„ì„ (ê¸°ì¡´)
# ------------------------------------------------------
def analyze_color_detailed(image_paths, max_samples=50):
    """ìƒì„¸ ìƒ‰ê° ë¶„ì„"""
    hues, sats, vals, temps = [], [], [], []
    contrasts, edges = [], []
    
    for path in image_paths[:max_samples]:
        img = cv2.imread(path)
        if img is None:
            continue
        
        # HSV
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        hues.append(hsv[:,:,0].mean())
        sats.append(hsv[:,:,1].mean())
        vals.append(hsv[:,:,2].mean())
        
        # ìƒ‰ì˜¨ë„
        b, g, r = cv2.split(img)
        temp = (r.mean() - b.mean()) / 255.0
        temps.append(temp)
        
        # ëŒ€ë¹„
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        contrasts.append(gray.std())
        
        # ì—£ì§€ ë°€ë„
        edge = cv2.Canny(gray, 50, 150)
        edges.append(edge.sum() / edge.size)
    
    if not hues:
        return None
    
    avg_hue = np.mean(hues)
    avg_sat = np.mean(sats)
    avg_val = np.mean(vals)
    avg_temp = np.mean(temps)
    avg_contrast = np.mean(contrasts)
    avg_edge = np.mean(edges)
    
    # ë¶„ë¥˜
    tone = "ì›œí†¤" if avg_temp > 0.15 else ("ì¿¨í†¤" if avg_temp < -0.15 else "ì¤‘ê°„í†¤")
    brightness = "ë°ìŒ" if avg_val > 160 else ("ë³´í†µ" if avg_val > 100 else "ì–´ë‘ì›€")
    saturation = "ë†’ìŒ" if avg_sat > 120 else ("ë³´í†µ" if avg_sat > 60 else "ë‚®ìŒ")
    contrast_level = "ë†’ìŒ" if avg_contrast > 50 else ("ë³´í†µ" if avg_contrast > 30 else "ë‚®ìŒ")
    edge_density = "ë³µì¡" if avg_edge > 0.15 else ("ë³´í†µ" if avg_edge > 0.08 else "ë‹¨ìˆœ")
    
    return {
        "tone": tone,
        "brightness": brightness,
        "saturation": saturation,
        "contrast": contrast_level,
        "edge_density": edge_density,
        "avg_hue": float(avg_hue),
        "avg_sat": float(avg_sat),
        "avg_val": float(avg_val),
        "avg_temp": float(avg_temp),
        "avg_contrast": float(avg_contrast),
        "avg_edge_density": float(avg_edge)
    }

# ------------------------------------------------------
# [5] í¬ì¦ˆ ë¶„ì„ (ê¸°ì¡´)
# ------------------------------------------------------
def analyze_pose_detailed(image_paths, yolo_model, max_samples=30):
    """ìƒì„¸ í¬ì¦ˆ ë¶„ì„"""
    pose_types = []
    pose_positions = []
    angles = []
    
    for path in image_paths[:max_samples]:
        img = cv2.imread(path)
        if img is None:
            continue
        
        try:
            results = yolo_model(img, verbose=False)
            if not results or results[0].boxes is None or len(results[0].boxes) == 0:
                continue
            
            bbox = results[0].boxes.xyxy[0].cpu().numpy()
            x1, y1, x2, y2 = bbox
            
            h_ratio = (y2 - y1) / img.shape[0]
            w_ratio = (x2 - x1) / img.shape[1]
            
            # í¬ì¦ˆ íƒ€ì…
            if h_ratio > 0.65:
                pose_types.append("ì „ì‹ ")
            elif h_ratio > 0.35:
                pose_types.append("ë°˜ì‹ ")
            else:
                pose_types.append("í´ë¡œì¦ˆì—…")
            
            # ìœ„ì¹˜
            center_y = (y1 + y2) / 2 / img.shape[0]
            pose_positions.append(center_y)
            
            # ê°€ë¡œ ì¤‘ì‹¬
            center_x = (x1 + x2) / 2 / img.shape[1]
            angles.append(center_x)
            
        except Exception:
            continue
    
    if not pose_types:
        return None
    
    pose_type = Counter(pose_types).most_common(1)[0][0]
    avg_y = np.mean(pose_positions)
    avg_x = np.mean(angles)
    
    position_y = "ìƒë‹¨" if avg_y < 0.4 else ("ì¤‘ì•™" if avg_y < 0.6 else "í•˜ë‹¨")
    position_x = "ì¢Œì¸¡" if avg_x < 0.4 else ("ì¤‘ì•™" if avg_x < 0.6 else "ìš°ì¸¡")
    
    return {
        "pose_type": pose_type,
        "position_vertical": position_y,
        "position_horizontal": position_x,
        "avg_vertical_pos": float(avg_y),
        "avg_horizontal_pos": float(avg_x),
        "distribution": dict(Counter(pose_types))
    }

# ------------------------------------------------------
# [6] ì¢…í•© ë¶„ì„
# ------------------------------------------------------
def analyze_cluster_deep(cluster_id):
    """í´ëŸ¬ìŠ¤í„° ì‹¬ì¸µ ë¶„ì„"""
    print(f"\n{'='*70}")
    print(f"ğŸ” Cluster {cluster_id} ì‹¬ì¸µ ë¶„ì„")
    print(f"{'='*70}")
    
    cluster_df = df.filter(pl.col("cluster") == cluster_id)
    cluster_size = len(cluster_df)
    
    image_paths = [
        str(IMG_DIR / os.path.basename(fname))
        for fname in cluster_df["filename"].to_list()
    ]
    
    # ê° ëª¨ë¸ë³„ ë¶„ì„
    print("  ğŸ“Š CLIP ë¶„ì„...")
    clip_analysis = analyze_clip_features(cluster_df)
    
    print("  ğŸ“Š OpenCLIP ë¶„ì„...")
    openclip_analysis = analyze_openclip_features(cluster_df)
    
    print("  ğŸ“Š DINO ë¶„ì„...")
    dino_analysis = analyze_dino_features(cluster_df)
    
    print("  ğŸ“Š MiDaS ë¶„ì„...")
    midas_analysis = analyze_midas_features(cluster_df)
    
    print("  ğŸ¨ ìƒ‰ê° ë¶„ì„...")
    color_analysis = analyze_color_detailed(image_paths, max_samples=50)
    
    print("  ğŸ•º í¬ì¦ˆ ë¶„ì„...")
    pose_analysis = analyze_pose_detailed(image_paths, yolo, max_samples=30)
    
    # ëŒ€í‘œ ì´ë¯¸ì§€
    sample_files = cluster_df["filename"][:5].to_list()
    
    return {
        "cluster_id": cluster_id,
        "size": cluster_size,
        "timestamp": datetime.now().isoformat(),
        "model_analyses": {
            "clip": clip_analysis,
            "openclip": openclip_analysis,
            "dino": dino_analysis,
            "midas": midas_analysis
        },
        "visual_analyses": {
            "color": color_analysis,
            "pose": pose_analysis
        },
        "representative_images": [os.path.basename(f) for f in sample_files]
    }

# ------------------------------------------------------
# [7] TXT ë¦¬í¬íŠ¸ ìƒì„±
# ------------------------------------------------------
def generate_txt_report(analysis, output_path):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ì½ê¸° ì‰¬ìš´ TXTë¡œ ì €ì¥"""
    
    with open(output_path, "w", encoding="utf-8") as f:
        f.write("="*70 + "\n")
        f.write(f"TryAngle í´ëŸ¬ìŠ¤í„° ì‹¬ì¸µ ë¶„ì„ ë¦¬í¬íŠ¸\n")
        f.write(f"Cluster {analysis['cluster_id']}\n")
        f.write("="*70 + "\n\n")
        
        f.write(f"ğŸ“Š ê¸°ë³¸ ì •ë³´\n")
        f.write(f"  ì´ ì´ë¯¸ì§€ ìˆ˜: {analysis['size']}ì¥\n")
        f.write(f"  ë¶„ì„ ì‹œê°: {analysis['timestamp']}\n\n")
        
        # AI ëª¨ë¸ë³„ ë¶„ì„
        f.write("="*70 + "\n")
        f.write("ğŸ¤– AI ëª¨ë¸ë³„ íŠ¹ì§• ë¶„ì„\n")
        f.write("="*70 + "\n\n")
        
        models = analysis['model_analyses']
        
        # CLIP
        if models['clip']:
            f.write("ğŸ“Œ CLIP (ViT-B/32)\n")
            f.write(f"  ì—­í• : {models['clip']['purpose']}\n")
            f.write(f"  íŠ¹ì§• ì°¨ì›: {models['clip']['dimensions']}ì°¨ì›\n")
            f.write(f"  í´ëŸ¬ìŠ¤í„° ì‘ì§‘ë„: {models['clip']['cluster_cohesion']:.2f}\n")
            f.write(f"  í•´ì„: {models['clip']['interpretation']}\n\n")
        
        # OpenCLIP
        if models['openclip']:
            f.write("ğŸ“Œ OpenCLIP (ViT-B/32, LAION-2B)\n")
            f.write(f"  ì—­í• : {models['openclip']['purpose']}\n")
            f.write(f"  íŠ¹ì§• ì°¨ì›: {models['openclip']['dimensions']}ì°¨ì›\n")
            f.write(f"  í´ëŸ¬ìŠ¤í„° ì‘ì§‘ë„: {models['openclip']['cluster_cohesion']:.2f}\n")
            f.write(f"  í•´ì„: {models['openclip']['interpretation']}\n\n")
        
        # DINO
        if models['dino']:
            f.write("ğŸ“Œ DINOv2 (ViT-S/14)\n")
            f.write(f"  ì—­í• : {models['dino']['purpose']}\n")
            f.write(f"  íŠ¹ì§• ì°¨ì›: {models['dino']['dimensions']}ì°¨ì›\n")
            f.write(f"  ê³µê°„ ì¼ê´€ì„±: {models['dino']['spatial_consistency']:.2f}\n")
            f.write(f"  í•´ì„: {models['dino']['interpretation']}\n\n")
        
        # MiDaS
        if models['midas']:
            f.write("ğŸ“Œ MiDaS (DPT-Hybrid)\n")
            f.write(f"  ì—­í• : {models['midas']['purpose']}\n")
            f.write(f"  í‰ê·  ê¹Šì´: {models['midas']['avg_depth']:.1f}\n")
            f.write(f"  ê¹Šì´ ë¶„ì‚°: {models['midas']['depth_variance']:.1f}\n")
            f.write(f"  ê³µê°„ ìœ í˜•: {models['midas']['space_type']}\n")
            f.write(f"  ë°°ê²½ ë³µì¡ë„: {models['midas']['background_complexity']}\n")
            f.write(f"  ê¹Šì´ ì¼ê´€ì„±: {models['midas']['depth_consistency']:.2f}\n")
            f.write(f"  í•´ì„: {models['midas']['interpretation']}\n\n")
        
        # ì‹œê°ì  ë¶„ì„
        f.write("="*70 + "\n")
        f.write("ğŸ¨ ì‹œê°ì  íŠ¹ì§• ë¶„ì„\n")
        f.write("="*70 + "\n\n")
        
        visual = analysis['visual_analyses']
        
        # ìƒ‰ê°
        if visual['color']:
            c = visual['color']
            f.write("ğŸ“Œ ìƒ‰ê° ë¶„ì„\n")
            f.write(f"  ìƒ‰ì˜¨ë„: {c['tone']}\n")
            f.write(f"  ë°ê¸°: {c['brightness']}\n")
            f.write(f"  ì±„ë„: {c['saturation']}\n")
            f.write(f"  ëŒ€ë¹„: {c['contrast']}\n")
            f.write(f"  ì—£ì§€ ë°€ë„: {c['edge_density']}\n")
            f.write(f"  \n")
            f.write(f"  ì„¸ë¶€ ìˆ˜ì¹˜:\n")
            f.write(f"    í‰ê·  ìƒ‰ìƒ(H): {c['avg_hue']:.1f}\n")
            f.write(f"    í‰ê·  ì±„ë„(S): {c['avg_sat']:.1f}\n")
            f.write(f"    í‰ê·  ë°ê¸°(V): {c['avg_val']:.1f}\n")
            f.write(f"    ìƒ‰ì˜¨ë„ ì§€ìˆ˜: {c['avg_temp']:.3f}\n\n")
        
        # í¬ì¦ˆ
        if visual['pose']:
            p = visual['pose']
            f.write("ğŸ“Œ í¬ì¦ˆ/êµ¬ë„ ë¶„ì„\n")
            f.write(f"  ì£¼ìš” í¬ì¦ˆ: {p['pose_type']}\n")
            f.write(f"  ìˆ˜ì§ ìœ„ì¹˜: {p['position_vertical']}\n")
            f.write(f"  ìˆ˜í‰ ìœ„ì¹˜: {p['position_horizontal']}\n")
            f.write(f"  í¬ì¦ˆ ë¶„í¬: {p['distribution']}\n\n")
        
        # ì¢…í•© í•´ì„
        f.write("="*70 + "\n")
        f.write("ğŸ’¡ ì¢…í•© í•´ì„\n")
        f.write("="*70 + "\n\n")
        
        f.write(generate_comprehensive_interpretation(analysis))
        
        # ëŒ€í‘œ ì´ë¯¸ì§€
        f.write("\n" + "="*70 + "\n")
        f.write("ğŸ–¼ï¸ ëŒ€í‘œ ì´ë¯¸ì§€\n")
        f.write("="*70 + "\n\n")
        for i, fname in enumerate(analysis['representative_images'], 1):
            f.write(f"  {i}. {fname}\n")
        
        f.write("\n" + "="*70 + "\n")

def generate_comprehensive_interpretation(analysis):  # â† í•¨ìˆ˜ëª… ë³€ê²½!
    """ì¢…í•© í•´ì„ ìƒì„±"""
    text = ""
    
    models = analysis['model_analyses']
    visual = analysis['visual_analyses']
    
    # MiDaS ê¸°ë°˜
    if models['midas']:
        text += f"ì´ í´ëŸ¬ìŠ¤í„°ëŠ” {models['midas']['space_type']}ì—ì„œ ì´¬ì˜ëœ ì´ë¯¸ì§€ë“¤ì…ë‹ˆë‹¤.\n"
        text += f"ë°°ê²½ ë³µì¡ë„ëŠ” {models['midas']['background_complexity']}ì…ë‹ˆë‹¤.\n\n"
    
    # í¬ì¦ˆ
    if visual['pose']:
        text += f"ì£¼ë¡œ {visual['pose']['pose_type']} í¬ì¦ˆë¡œ, "
        text += f"ì¸ë¬¼ì€ í™”ë©´ {visual['pose']['position_vertical']}ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.\n\n"
    
    # ìƒ‰ê°
    if visual['color']:
        text += f"ìƒ‰ê°ì€ {visual['color']['tone']}ì´ë©°, "
        text += f"{visual['color']['brightness']} ë°ê¸°ì™€ "
        text += f"{visual['color']['saturation']} ì±„ë„ë¥¼ ë³´ì…ë‹ˆë‹¤.\n\n"
    
    # DINO
    if models['dino']:
        if models['dino']['spatial_consistency'] > 15:
            text += "DINO ë¶„ì„ ê²°ê³¼, ì´ í´ëŸ¬ìŠ¤í„°ëŠ” ë§¤ìš° ì¼ê´€ëœ êµ¬ë„ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤.\n"
        else:
            text += "DINO ë¶„ì„ ê²°ê³¼, ë‹¤ì–‘í•œ êµ¬ë„ê°€ í˜¼ì¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n"
    
    # CLIP/OpenCLIP
    if models['clip'] and models['clip']['cluster_cohesion'] > 15:
        text += "CLIP ë¶„ì„ ê²°ê³¼, ê°ì„±ì ìœ¼ë¡œ ë§¤ìš° ìœ ì‚¬í•œ ì´ë¯¸ì§€ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n"
    
    return text

# ------------------------------------------------------
# [8] ë©”ì¸ ì‹¤í–‰
# ------------------------------------------------------
def main():
    print("\n" + "="*70)
    print("ğŸ§  TryAngle í´ëŸ¬ìŠ¤í„° ì‹¬ì¸µ ë¶„ì„")
    print("="*70)
    
    n_clusters = df["cluster"].n_unique()
    
    for c in range(n_clusters):
        # ë¶„ì„ ìˆ˜í–‰
        analysis = analyze_cluster_deep(c)
        
        # JSON ì €ì¥
        json_path = CLUSTER_DIR / f"cluster_{c}" / "analysis.json"
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2, default=str)
        
        # TXT ë¦¬í¬íŠ¸ ì €ì¥
        txt_path = CLUSTER_DIR / f"cluster_{c}" / "README.txt"
        generate_txt_report(analysis, txt_path)
        
        print(f"âœ… Cluster {c} ë¶„ì„ ì™„ë£Œ")
        print(f"   ğŸ“„ {txt_path}")
    
    print("\n" + "="*70)
    print("âœ… ì „ì²´ ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ ìœ„ì¹˜: {CLUSTER_DIR}")
    print("="*70)

if __name__ == "__main__":
    main()
