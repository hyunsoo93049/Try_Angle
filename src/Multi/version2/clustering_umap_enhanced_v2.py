# ======================================================
# ğŸ§  TryAngle Ultra-Advanced Clustering v2
# (PCA ì œê±° + UMAP ì°¨ì› ì¶•ì†Œ + KMeans)
#  - CLIP + OpenCLIP + DINO + MiDaS + Color/Texture
#  - UMAP 128D ì„ë² ë”© ì €ì¥
#  - KMeans ëª¨ë¸ + ì„¼íŠ¸ë¡œì´ë“œ + ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
# ======================================================

import os, gc, warnings
import numpy as np
import polars as pl
import cv2
from scipy.stats import skew, kurtosis
from skimage.feature import local_binary_pattern

from sklearn.preprocessing import RobustScaler, normalize
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

from umap import UMAP
import joblib

warnings.filterwarnings("ignore")

# ------------------------------------------------------
# [1] ê²½ë¡œ ì„¤ì •
# ------------------------------------------------------
PARQUET_PATH = r"C:\try_angle\features\fusion_final_with_openclip.parquet"
IMG_DIR      = r"C:\try_angle\data\train_images"
SAVE_DIR     = r"C:\try_angle\models_v2"

os.makedirs(SAVE_DIR, exist_ok=True)

# ------------------------------------------------------
# [2] ìƒ‰ìƒ/í…ìŠ¤ì²˜ íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜
# ------------------------------------------------------
def extract_color_texture_features(img_path: str):
    """
    ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨(HSV) + LAB í†µê³„ + LBP í…ìŠ¤ì²˜ + ì—£ì§€ ë°€ë„
    ì´ 119ì°¨ì› ì •ë„ì˜ hand-crafted feature
    """
    try:
        img = cv2.imread(img_path)
        if img is None:
            return None

        img = cv2.resize(img, (256, 256))
        img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        gray    = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        features = []

        # 1) HSV íˆìŠ¤í† ê·¸ë¨ (ê° ì±„ë„ 32bin)
        for channel in cv2.split(img_hsv):
            hist = cv2.calcHist([channel], [0], None, [32], [0, 256]).flatten()
            hist = hist / (hist.sum() + 1e-7)
            features.extend(hist)

        # 2) LAB í†µê³„ëŸ‰ (mean, std, skew, kurtosis)
        for channel in cv2.split(img_lab):
            flat = channel.flatten()
            features.extend([
                flat.mean(),
                flat.std(),
                skew(flat),
                kurtosis(flat)
            ])

        # 3) LBP í…ìŠ¤ì²˜ íˆìŠ¤í† ê·¸ë¨
        lbp = local_binary_pattern(gray, P=8, R=1, method="uniform")
        lbp_hist, _ = np.histogram(lbp.ravel(), bins=10, range=(0, 10))
        lbp_hist = lbp_hist / (lbp_hist.sum() + 1e-7)
        features.extend(lbp_hist)

        # 4) ì—£ì§€ ë°€ë„
        edges = cv2.Canny(gray, 50, 150)
        edge_density = edges.sum() / edges.size
        features.append(edge_density)

        return np.array(features, dtype=np.float32)

    except Exception:
        # ì´ë¯¸ì§€ ê¹¨ì¡Œê±°ë‚˜ ë¡œë“œ ì‹¤íŒ¨í•œ ê²½ìš°
        return None


# ------------------------------------------------------
# [3] ë°ì´í„° ë¡œë“œ
# ------------------------------------------------------
print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
df = pl.read_parquet(PARQUET_PATH)

clip_feats     = df.select([c for c in df.columns if c.startswith("clip_")]).to_numpy()
openclip_feats = df.select([c for c in df.columns if c.startswith("openclip_")]).to_numpy()
dino_feats     = df.select([c for c in df.columns if c.startswith("dino_")]).to_numpy()
midas_mean     = df.select("midas_mean").to_numpy().flatten()
midas_std      = df.select("midas_std").to_numpy().flatten()
filenames      = df["filename"].to_list()

print("âœ… ê¸°ì¡´ íŠ¹ì§• ë¡œë“œ ì™„ë£Œ")
print(f"   CLIP      : {clip_feats.shape}")
print(f"   OpenCLIP  : {openclip_feats.shape}")
print(f"   DINO      : {dino_feats.shape}")
print(f"   MiDaS     : mean/std â†’ ({midas_mean.shape[0]}, 2)")
print(f"   íŒŒì¼ ê°œìˆ˜ : {len(filenames)}")

# ------------------------------------------------------
# [4] ìƒ‰ìƒ/í…ìŠ¤ì²˜ íŠ¹ì§• ì¶”ì¶œ
# ------------------------------------------------------
print("\nğŸ¨ ìƒ‰ìƒ/í…ìŠ¤ì²˜ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
color_texture_list = []
for fname in filenames:
    fpath = os.path.join(IMG_DIR, os.path.basename(fname))
    feat = extract_color_texture_features(fpath)
    if feat is None:
        # ì‹¤íŒ¨ ì‹œ 0ë²¡í„° ëŒ€ì²´ (ì°¨ì› ë§ì¶”ê¸°ìš©)
        feat = np.zeros(119, dtype=np.float32)
    color_texture_list.append(feat)

color_texture_feats = np.array(color_texture_list)
print("âœ… ìƒ‰ìƒ/í…ìŠ¤ì²˜ íŠ¹ì§•:", color_texture_feats.shape)

# ------------------------------------------------------
# [5] ì •ê·œí™” + ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
# ------------------------------------------------------
print("\nğŸ”¹ íŠ¹ì§• ì •ê·œí™” ì¤‘...")

clip_scaler     = RobustScaler()
openclip_scaler = RobustScaler()
dino_scaler     = RobustScaler()
color_scaler    = RobustScaler()
midas_scaler    = RobustScaler()

clip_z     = clip_scaler.fit_transform(clip_feats)
open_z     = openclip_scaler.fit_transform(openclip_feats)
dino_z     = dino_scaler.fit_transform(dino_feats)
color_z    = color_scaler.fit_transform(color_texture_feats)

midas_feats = np.column_stack([midas_mean, midas_std])
midas_z     = midas_scaler.fit_transform(midas_feats)

# ğŸ’¾ ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
joblib.dump(clip_scaler,     os.path.join(SAVE_DIR, "scaler_clip.joblib"))
joblib.dump(openclip_scaler, os.path.join(SAVE_DIR, "scaler_openclip.joblib"))
joblib.dump(dino_scaler,     os.path.join(SAVE_DIR, "scaler_dino.joblib"))
joblib.dump(color_scaler,    os.path.join(SAVE_DIR, "scaler_color.joblib"))
joblib.dump(midas_scaler,    os.path.join(SAVE_DIR, "scaler_midas.joblib"))

print("ğŸ’¾ ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì™„ë£Œ:")
print(f"   {os.path.join(SAVE_DIR, 'scaler_*.joblib')}")

# ê°€ì¤‘ì¹˜
w_clip, w_op, w_dino, w_color, w_midas = 0.30, 0.30, 0.25, 0.12, 0.03

fusion_raw = np.concatenate(
    [
        clip_z * w_clip,
        open_z * w_op,
        dino_z * w_dino,
        color_z * w_color,
        midas_z * w_midas,
    ],
    axis=1,
)

print("âœ… ì›ë³¸ ìœµí•© íŠ¹ì§•:", fusion_raw.shape)

# ------------------------------------------------------
# [6] UMAP 128D í•™ìŠµ + ì €ì¥
# ------------------------------------------------------
print("\nğŸ”¹ UMAP ì°¨ì› ì¶•ì†Œ ì¤‘ (128D)...")
umap_high = UMAP(
    n_components=128,
    n_neighbors=30,
    min_dist=0.0,
    metric="cosine",
    random_state=42,
    verbose=True,
)
fusion_128 = umap_high.fit_transform(fusion_raw)
fusion_128 = normalize(fusion_128)

print("âœ… UMAP 128D ì™„ë£Œ:", fusion_128.shape)

# ğŸ’¾ UMAP + 128D ì„ë² ë”© ì €ì¥
joblib.dump(umap_high, os.path.join(SAVE_DIR, "umap_128d_model.joblib"))
np.save(os.path.join(SAVE_DIR, "fusion_128d.npy"), fusion_128)
print("ğŸ’¾ UMAP ëª¨ë¸ ë° ì„ë² ë”© ì €ì¥ ì™„ë£Œ")

# ------------------------------------------------------
# [7] KMeans í•™ìŠµ + ì €ì¥
# ------------------------------------------------------
print("\nğŸ”¹ KMeans í•™ìŠµ ì¤‘...")
k = 10
km = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=300)
labels_km = km.fit_predict(fusion_128)

joblib.dump(km, os.path.join(SAVE_DIR, "kmeans_model.pkl"))
np.save(os.path.join(SAVE_DIR, "kmeans_centroids.npy"), km.cluster_centers_)

print("ğŸ’¾ KMeans ëª¨ë¸/ì„¼íŠ¸ë¡œì´ë“œ ì €ì¥ ì™„ë£Œ")

# ------------------------------------------------------
# [8] ì„±ëŠ¥ í‰ê°€ + ê²°ê³¼ parquet ì €ì¥
# ------------------------------------------------------
sil = silhouette_score(fusion_128, labels_km, sample_size=min(5000, len(fusion_128)))
print(f"\nğŸ† Silhouette = {sil:.4f}")

df = df.with_columns(pl.Series("cluster", labels_km))
df.write_parquet(r"C:\try_angle\features\clustered_umap_v2_result.parquet")

print("\nğŸ‰ í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ!")
print("   â†’ clustered_umap_v2_result.parquet ì €ì¥ë¨")
print(f"   â†’ ëª¨ë¸ ë””ë ‰í† ë¦¬: {SAVE_DIR}")
