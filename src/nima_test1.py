import sys
import torch
from PIL import Image
import torchvision.transforms as transforms
import torchvision.models as models
import numpy as np

# ---------------------------------------------------
# 1ï¸âƒ£ ì™„ì „í•œ NIMA ëª¨ë¸ ì§ì ‘ êµ¬ì„±
# ---------------------------------------------------
class NIMAAesthetic(torch.nn.Module):
    def __init__(self):
        super().__init__()
        # MobileNetV2 featuresë§Œ ì‚¬ìš©
        mobilenet = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)
        self.features = mobilenet.features
        
        # NIMA classifier
        self.classifier = torch.nn.Sequential(
            torch.nn.AdaptiveAvgPool2d(1),
            torch.nn.Flatten(),
            torch.nn.Dropout(0.75),
            torch.nn.Linear(1280, 10),
            torch.nn.Softmax(dim=1)
        )
    
    def forward(self, x):
        x = self.features(x)      # (batch, 1280, 7, 7)
        x = self.classifier(x)    # (batch, 10)
        return x

# ëª¨ë¸ ìƒì„±
model = NIMAAesthetic()

# ---------------------------------------------------
# 2ï¸âƒ£ ê°€ì¤‘ì¹˜ ë¡œë“œ ë° ê²€ì¦
# ---------------------------------------------------
state_dict = torch.load(
    '/Users/hyunsoo/Try_Angle/Neural-IMage-Assessment/model/NIMA-spaq-46a7fcb7.pth',
    map_location='cpu',
    weights_only=False
)

# state_dict êµ¬ì¡° í™•ì¸
print("=" * 60)
print("ğŸ“¦ ì›ë³¸ State Dict í‚¤ ëª©ë¡:")
print("=" * 60)
if "params" in state_dict:
    state_dict = state_dict["params"]
    
for key in list(state_dict.keys())[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
    print(f"  - {key}: {state_dict[key].shape}")
print(f"  ... (ì´ {len(state_dict)} ê°œì˜ í‚¤)")
print()

# ê°€ì¤‘ì¹˜ í‚¤ ë§¤ì¹­
new_state_dict = {}
matched_keys = []
unmatched_keys = []

for key, value in state_dict.items():
    if key.startswith('base_model.'):
        new_key = key.replace('base_model.', '')
        new_state_dict[new_key] = value
        matched_keys.append(key)
    elif key.startswith('classifier.'):
        new_state_dict[key] = value
        matched_keys.append(key)
    else:
        unmatched_keys.append(key)

print("=" * 60)
print("ğŸ”„ ê°€ì¤‘ì¹˜ ë¡œë”© ê²°ê³¼:")
print("=" * 60)
print(f"âœ… ë§¤ì¹­ëœ í‚¤: {len(matched_keys)}ê°œ")
print(f"âŒ ë§¤ì¹­ë˜ì§€ ì•Šì€ í‚¤: {len(unmatched_keys)}ê°œ")
if unmatched_keys:
    print("\në§¤ì¹­ë˜ì§€ ì•Šì€ í‚¤ë“¤:")
    for key in unmatched_keys[:5]:
        print(f"  - {key}")
print()

# ê°€ì¤‘ì¹˜ ë¡œë“œ
missing_keys, unexpected_keys = model.load_state_dict(new_state_dict, strict=False)
print("=" * 60)
print("ğŸ” ëª¨ë¸ ë¡œë”© ìƒì„¸ ì •ë³´:")
print("=" * 60)
print(f"ëˆ„ë½ëœ í‚¤: {len(missing_keys)}ê°œ")
if missing_keys:
    for key in missing_keys[:5]:
        print(f"  - {key}")
print(f"\nì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {len(unexpected_keys)}ê°œ")
if unexpected_keys:
    for key in unexpected_keys[:5]:
        print(f"  - {key}")
print()

model.eval()

# ---------------------------------------------------
# 3ï¸âƒ£ ì—¬ëŸ¬ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ ê²€ì¦
# ---------------------------------------------------
test_images = [
    '/Users/hyunsoo/Try_Angle/data/sample_images/wow.jpg',
]

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

device = torch.device('cpu')
model.to(device)

print("=" * 60)
print("ğŸ“¸ ì´ë¯¸ì§€ë³„ ë¯¸í•™ ì ìˆ˜ ë¶„ì„:")
print("=" * 60)

for img_path in test_images:
    try:
        img = Image.open(img_path).convert('RGB')
        img_tensor = transform(img).unsqueeze(0).to(device)
        
        with torch.no_grad():
            output = model(img_tensor)
            probs = output[0].cpu().numpy()
            
            # í†µê³„ ê³„ì‚°
            mean_score = sum((i + 1) * p for i, p in enumerate(probs))
            std_score = np.sqrt(sum(((i + 1) - mean_score) ** 2 * p for i, p in enumerate(probs)))
            
            print(f"\nğŸ“ íŒŒì¼: {img_path.split('/')[-1]}")
            print(f"   í‰ê·  ì ìˆ˜: {mean_score:.3f}")
            print(f"   í‘œì¤€í¸ì°¨: {std_score:.3f}")
            print(f"   ë¶„í¬ (1~10ì ):")
            
            # ë§‰ëŒ€ ê·¸ë˜í”„ í˜•íƒœë¡œ ì¶œë ¥
            for i, p in enumerate(probs):
                bar = 'â–ˆ' * int(p * 50)  # 50ì ê¸°ì¤€
                print(f"      {i+1:2d}ì : {p:.4f} {bar}")
            
            # ê°€ì¥ ë†’ì€ í™•ë¥  3ê°œ
            top3_indices = np.argsort(probs)[-3:][::-1]
            print(f"   Top 3 ì ìˆ˜: ", end="")
            print(", ".join([f"{idx+1}ì ({probs[idx]:.3f})" for idx in top3_indices]))
            
    except FileNotFoundError:
        print(f"\nâŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")

print("\n" + "=" * 60)
print("ğŸ’¡ ë¶„ì„ í¬ì¸íŠ¸:")
print("=" * 60)
print("1. ëª¨ë“  ì ìˆ˜ê°€ ë¹„ìŠ·í•˜ê²Œ ë¶„ì‚°ë˜ì–´ ìˆë‹¤ë©´ â†’ ê°€ì¤‘ì¹˜ ë¡œë”© ì‹¤íŒ¨")
print("2. íŠ¹ì • ì ìˆ˜ì— ì§‘ì¤‘ë˜ì–´ ìˆë‹¤ë©´ â†’ ê°€ì¤‘ì¹˜ëŠ” ë¡œë“œë˜ì—ˆì§€ë§Œ í•™ìŠµ ë°ì´í„°ì…‹ê³¼ ë§ì§€ ì•ŠìŒ")
print("3. í‘œì¤€í¸ì°¨ê°€ ë§¤ìš° ì‘ë‹¤ë©´ â†’ ëª¨ë¸ì´ í™•ì‹  ì—†ì´ ì¤‘ê°„ê°’ ì¶œë ¥")
print("4. SPAQ ë°ì´í„°ì…‹ì€ ìŠ¤ë§ˆíŠ¸í° ì‚¬ì§„ í’ˆì§ˆ í‰ê°€ìš©ì…ë‹ˆë‹¤")
print("   - ë¸”ëŸ¬, ë…¸ì´ì¦ˆ, ë…¸ì¶œ ë“± ê¸°ìˆ ì  í’ˆì§ˆì— ë¯¼ê°")
print("   - êµ¬ë„, ê°ì„± ë“± ì˜ˆìˆ ì  ìš”ì†ŒëŠ” ëœ ë¯¼ê°í•  ìˆ˜ ìˆìŒ")