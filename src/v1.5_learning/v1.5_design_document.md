# TryAngle v1.5 ì™„ì „ ì„¤ê³„ ë¬¸ì„œ

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

### í•µì‹¬ ì»¨ì…‰
êµ¬ë„ì™€ í”„ë ˆì´ë°ì— ì§‘ì¤‘í•œ AI ì¹´ë©”ë¼ ê°€ì´ë“œ ì•±
- **í¬ì¦ˆ ì¤‘ì‹¬ (v1)** â†’ **êµ¬ë„/í”„ë ˆì´ë° ì¤‘ì‹¬ (v1.5)**
- 2,132ì¥+ ë ˆí¼ëŸ°ìŠ¤ ì‚¬ì§„ì˜ "ì¢‹ì€ êµ¬ë„" íŒ¨í„´ í•™ìŠµ
- ì‹¤ì‹œê°„ ì •ëŸ‰ì  í”¼ë“œë°± ì œê³µ

### í•µì‹¬ í˜ì‹ : ì••ì¶•ê° ê¸°ë°˜ ê±°ë¦¬ í”¼ë“œë°±
ê¸°ì¡´ ì•±ë“¤ê³¼ì˜ ì°¨ë³„ì :
- âŒ ê¸°ì¡´: "ì–¼êµ´ ì¤‘ì•™ì—", "ê·¸ë¦¬ë“œ ë¼ì¸"
- âœ… v1.5: **"1.2m ë’¤ë¡œ ë˜ëŠ” ì¤Œ ì¸"** (ê±°ë¦¬ + ì••ì¶•ê°)

---

## ğŸ—ï¸ ì „ì²´ ì•„í‚¤í…ì²˜

```
ì˜¤í”„ë¼ì¸ í•™ìŠµ (RTX 4070 Super - í•œ ë²ˆë§Œ)
    â†“
ë ˆí¼ëŸ°ìŠ¤ 2,132ì¥+ ì •ë°€ ë¶„ì„
    â†“
í…Œë§ˆë³„ íŒ¨í„´ DB (JSON 2-5MB)
    â†“
ì•±ì— ë‚´ì¥
    â†“
ì‹¤ì‹œê°„ ì´¬ì˜ (iPhone 15fps)
```

---

## ğŸš€ V1.5ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” ì‹¤ì§ˆì  ì´ì 

### ğŸ“¸ ì‚¬ìš©ì ê²½í—˜ ì¸¡ë©´

#### 1. **ì •ëŸ‰ì ì´ê³  êµ¬ì²´ì ì¸ í”¼ë“œë°±**
- ê¸°ì¡´: "ì¡°ê¸ˆ ë” ë’¤ë¡œ" â†’ V1.5: "1.2m ë’¤ë¡œ ê°€ê±°ë‚˜ 35mmë¡œ ì¡°ì •"
- ê¸°ì¡´: "êµ¬ë„ ì¡°ì •" â†’ V1.5: "ì¸ë¬¼ì„ ì™¼ìª½ 30cmë¡œ, ì¹´í˜ ì°½ë¬¸ê³¼ ê· í˜• ë§ì¶¤"
- ê¸°ì¡´: "ê°ë„ ë³€ê²½" â†’ V1.5: "ì¹´ë©”ë¼ 12ë„ ìœ„ë¡œ, í…Œì´ë¸” ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨"

#### 2. **ìƒí™©ë³„ ë§ì¶¤ ê°€ì´ë“œ**
ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ Theme Ã— Pose Type ì¸ì‹:
- "ì¹´í˜ ë°˜ì‹  ìƒ·" â†’ 2,000ì¥ì˜ ì„±ê³µ íŒ¨í„´ê³¼ ë¹„êµ
- "ê³µì› ì „ì‹  ìƒ·" â†’ ì•¼ì™¸ ì „ì‹  ìµœì  íŒ¨í„´ ì ìš©
- í…Œë§ˆë³„ íŠ¹í™” íŒ (ì¹´í˜ëŠ” ì°½ë¬¸ í™œìš©, ê³µì›ì€ ë‚˜ë¬´ í™œìš©)

#### 3. **ì „ë¬¸ê°€ ë…¸í•˜ìš° ë‚´ì¬í™”**
- ì¸ìŠ¤íƒ€ê·¸ë¨ ì¸í”Œë£¨ì–¸ì„œë“¤ì˜ êµ¬ë„ ë¹„ë²•
- ì „ë¬¸ ì‚¬ì§„ì‘ê°€ë“¤ì˜ ì••ì¶•ê° í™œìš©ë²•
- ì¥ì†Œë³„ ìµœì  ì•µê¸€ (ì°½ê°€ì„, ì½”ë„ˆì„ ë“±)

### ğŸ’° ë¹„ì¦ˆë‹ˆìŠ¤ ì¸¡ë©´

- **ëª…í™•í•œ ì°¨ë³„ì **: ì„¸ê³„ ìµœì´ˆ "ì••ì¶•ê° ê¸°ë°˜ ê±°ë¦¬ í”¼ë“œë°±"
- **íŠ¹í—ˆ ê°€ëŠ¥ì„±**: ê¸°ìˆ ì  í˜ì‹ ìœ¼ë¡œ ë³´í˜¸ ê°€ëŠ¥
- **í™•ì¥ì„±**: ìƒˆ íŠ¸ë Œë“œ ì¦‰ì‹œ ë°˜ì˜ (ì´ë¯¸ì§€ ì¶”ê°€ë§Œìœ¼ë¡œ)

---

## ğŸ”¬ ê°œì„ ëœ íŒŒì´í”„ë¼ì¸ (v1.2)

### ì™„ì „ ìë™í™” One-Pass Processing

ê¸°ì¡´ì˜ 2-pass (ë¶„ë¥˜ â†’ íŠ¹ì§•ì¶”ì¶œ) ëŒ€ì‹  1-passë¡œ íš¨ìœ¨í™”:

```python
class ImprovedV15Pipeline:
    def __init__(self):
        # ëª¨ë“  ëª¨ë¸ í•œ ë²ˆë§Œ ë¡œë“œ
        self.models = {
            'grounding_dino': load_grounding_dino(),
            'rtmpose': load_rtmpose(),
            'depth': load_depth_anything(),
        }

    def process_batch(self, images):
        # 1. ëª¨ë“  íŠ¹ì§• ë™ì‹œ ì¶”ì¶œ (GPU ë³‘ë ¬)
        features = {
            'objects': self.models['grounding_dino'](images),
            'poses': self.models['rtmpose'](images),
            'depths': self.models['depth'](images),
        }

        # 2. íŠ¹ì§• ê¸°ë°˜ ìë™ ë¶„ë¥˜
        for i, img in enumerate(images):
            theme = classify_theme(features['objects'][i])
            pose_type = classify_pose(features['poses'][i])

            # 3. ë¶„ë¥˜ì™€ íŠ¹ì§• ë™ì‹œ ì €ì¥
            save_with_metadata(img, theme, pose_type, features[i])

        return features
```

### ë‹¤ì¤‘ ì‹ í˜¸ ê¸°ë°˜ Robust Classification

ë‹¨ì¼ ëª¨ë¸ ì˜ì¡´ ëŒ€ì‹  ì—¬ëŸ¬ ì‹ í˜¸ë¥¼ ì¢…í•©:

```python
def robust_pose_classification(image, features):
    # 1. RTMPose ê¸°ë³¸ íŒì •
    pose_rtm = rtmpose_classify(features['pose'])

    # 2. Bbox ë¹„ìœ¨ë¡œ ë³´ì •
    bbox_ratio = features['bbox'].height / image.height
    if bbox_ratio > 0.8:
        pose_bbox = "full_body"
    elif bbox_ratio > 0.5:
        pose_bbox = "half_body"

    # 3. Depth ì •ë³´ í™œìš©
    visible_range = analyze_depth_range(features['depth'])
    pose_depth = depth_to_pose_type(visible_range)

    # 4. Votingìœ¼ë¡œ ìµœì¢… ê²°ì •
    return majority_vote([pose_rtm, pose_bbox, pose_depth])
```

### í…Œë§ˆ ë¶„ë¥˜ ê·œì¹™ (ìë™í™”)

```python
THEME_RULES = {
    'cafe_indoor': ['table', 'chair', 'coffee', 'window', 'cup'],
    'street_urban': ['building', 'car', 'road', 'sidewalk', 'sign'],
    'park_nature': ['tree', 'grass', 'bench', 'sky', 'flower'],
    'beach': ['ocean', 'sand', 'wave', 'umbrella'],
    'winter': ['snow', 'ice', 'coat', 'scarf']
}

def auto_classify_theme(detected_objects):
    scores = {}
    for theme, keywords in THEME_RULES.items():
        score = sum(1 for obj in detected_objects if obj in keywords)
        scores[theme] = score
    return max(scores, key=scores.get)
```

---

## ğŸ”¬ Phase 1: ì˜¤í”„ë¼ì¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸

### ì‚¬ìš© í™˜ê²½
- GPU: RTX 4070 Super
- ì´ë¯¸ì§€: 2,132ì¥ (MVP 300ì¥ë„ ê°€ëŠ¥)
- ì´ ì†Œìš” ì‹œê°„: 2-3ì‹œê°„ (2,132ì¥ ê¸°ì¤€)
- ê²°ê³¼ë¬¼: 2-5MB JSON íŒŒì¼

### Step 1: í…Œë§ˆ ìë™ ë¶„ë¥˜

**ëª©ì :** 2,132ì¥ì„ í…Œë§ˆë³„ë¡œ ê·¸ë£¹í™”

**ë°©ë²• 1 (ê¶Œì¥): Grounding DINO Rules-Based + DINOv2 Clustering**

```python
# Step 1-1: Grounding DINOë¡œ ë°°ê²½ ê°ì²´ ê²€ì¶œ
for image in 2132_photos:
    objects = grounding_dino(image,
        ["window", "beach", "tree", "street", "table", "snow"])

    # ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜
    if "window" in objects and "table" in objects:
        theme = "cafe_indoor"
    elif "beach" in objects:
        theme = "beach"
    elif "tree" in objects and not "street":
        theme = "park_nature"
    elif "snow" in objects:
        theme = "winter_outdoor"
    # ...

# Step 1-2: DINOv2ë¡œ ì• ë§¤í•œ ì¼€ì´ìŠ¤ clustering
ambiguous_images = [img for img in images if theme == "unknown"]
embeddings = dinov2_large(ambiguous_images)  # 384D vectors
clusters = kmeans(embeddings, n_clusters=5)
# ê° í´ëŸ¬ìŠ¤í„° ìˆ˜ë™ ë¼ë²¨ë§

# Step 1-3: ìˆ˜ë™ ê²€ì¦ (ì„ íƒì )
# ìƒ˜í”Œë§ìœ¼ë¡œ ì •í™•ë„ í™•ì¸ í›„ í•„ìš”ì‹œ ìˆ˜ì •
```

**ì •í™•ë„:**
- Grounding DINO Rules: 90-95%
- DINOv2 Clustering: 95-98% (ìˆ˜ë™ ë¼ë²¨ë§ í›„)

**ê²°ê³¼ ì˜ˆì‹œ:**
- cafe_indoor: 668ì¥
- park_nature: 908ì¥
- street_urban: 330ì¥
- winter_outdoor: 98ì¥
- highangle: 128ì¥

**ì†Œìš” ì‹œê°„:** ì•½ 30-40ë¶„ (2,132ì¥ ê¸°ì¤€)

---

### Step 2: ì •ë°€ ê°ì²´ ê²€ì¶œ

**ëª©ì :** ì¸ë¬¼ + ë°°ê²½ ê°ì²´ ì •í™•í•œ ìœ„ì¹˜ ì¶”ì¶œ

**ëª¨ë¸:** Grounding DINO-B (Base)

**ë°©ë²•:**
```python
for image in each_theme_group:
    # ì¸ë¬¼ ê²€ì¶œ
    person = grounding_dino(image, "person")

    # í…Œë§ˆë³„ ë°°ê²½ ê°ì²´
    if theme == "cafe":
        window = grounding_dino(image, "window")
        chair = grounding_dino(image, "chair")
        table = grounding_dino(image, "table")

    # ê³µê°„ ê´€ê³„ ê³„ì‚°
    person_to_window = calculate_distance(person, window)
    window_direction = get_direction(person, window)
```

**ì¶”ì¶œ ì •ë³´:**
```json
{
  "person_bbox": [250, 100, 300, 600],
  "background_objects": {
    "window": {
      "bbox": [720, 300, 300, 600],
      "direction_from_person": "right",
      "distance": 0.25
    }
  }
}
```

**ì†Œìš” ì‹œê°„:** ì•½ 1ì‹œê°„ (2,132ì¥ Ã— 1.5ì´ˆ)

---

### Step 2-1: Pose Type ìë™ ê²€ì¶œ (í•µì‹¬!)

**ëª©ì :** Shot Type ë¶„ë¥˜ (Samsung Display ê¸°ì¤€ ì°¸ê³ )

**ëª¨ë¸:** RTMPose (133 keypoints) via rtmlib (ONNX)

**ìƒˆë¡œìš´ 4-Type ë¶„ë¥˜ ì²´ê³„:**
| Shot Type | ì •ì˜ | íŒë‹¨ ê¸°ì¤€ |
|-----------|------|-----------|
| **closeup** | ì–¼êµ´~ì–´ê¹¨ | ì–´ê¹¨ë§Œ ë³´ì´ê±°ë‚˜ í”„ë ˆì„ í•˜ë‹¨ 70% ì´í•˜ |
| **medium_shot** | ê°€ìŠ´~í—ˆë¦¬ | íŒ”ê¿ˆì¹˜/ê³¨ë°˜ ë³´ì„ (bust+waist í†µí•©) |
| **knee_shot** | í—ˆë²…ì§€~ë¬´ë¦ | ë¬´ë¦ ë³´ì„ (í”„ë ˆì„ í•˜ë‹¨ 75% ì´í•˜) |
| **full_shot** | ì „ì‹  | ë°œëª© ë³´ì„ (í”„ë ˆì„ í•˜ë‹¨ 85% ì´í•˜) |

**ë°©ë²•:**
```python
for image in 2133_photos:
    # RTMPoseë¡œ keypoints ì¶”ì¶œ (rtmlib ONNX)
    keypoints, scores = wholebody(image)  # 133ê°œ (ì–¼êµ´+ëª¸+ì†)

    # 1. ì•‰ì€ ìì„¸ ê°ì§€ (í•µì‹¬!)
    def detect_sitting():
        torso_length = hip_y - shoulder_y
        hip_to_knee = knee_y - hip_y
        ratio = hip_to_knee / torso_length
        # ì„œ ìˆì„ ë•Œ: ratio â‰ˆ 1.0~1.5
        # ì•‰ì•„ ìˆì„ ë•Œ: ratio â‰ˆ 0.2~0.5
        return ratio < 0.6

    is_sitting = detect_sitting()

    # 2. Shot Type íŒì • (ì•‰ì€ ìì„¸ ê³ ë ¤)
    if ankle_visible and ankle_y > img_height * 0.85:
        pose_type = "full_shot"
    elif ankle_visible and is_sitting:
        pose_type = "knee_shot"  # ì•‰ì•„ìˆëŠ”ë° ë°œëª© ë³´ì„ â†’ knee_shot
    elif knee_visible and knee_y > img_height * 0.75:
        pose_type = "knee_shot"
    elif knee_visible and is_sitting:
        pose_type = "medium_shot"  # ì•‰ì•„ìˆëŠ”ë° ë¬´ë¦ ë³´ì„ â†’ medium_shot
    elif hip_visible or elbow_visible:
        pose_type = "medium_shot"
    elif shoulder_visible:
        pose_type = "closeup" if shoulder_y < img_height * 0.7 else "medium_shot"
    elif head_visible:
        pose_type = "closeup"
    else:
        pose_type = "unknown"
```

**Occlusion Handling (ì˜·/ê°€ë¦¼ ëŒ€ì‘):**
```python
# 1. Confidence threshold ë‚®ê²Œ ì„¤ì • (0.3)
# 2. ë³´ì´ëŠ” ê´€ì ˆë§Œìœ¼ë¡œ íŒë‹¨
# 3. Multi-frame averaging (ì‹¤ì‹œê°„ìš©)
# 4. Conservative classification
if uncertain:
    pose_type = "upper_body"  # ì•ˆì „í•˜ê²Œ ìƒë°˜ì‹ ìœ¼ë¡œ
```

**ê²°ê³¼ ì˜ˆì‹œ:**
```json
{
  "filename": "IMG_1234.jpg",
  "theme": "cafe_indoor",
  "pose_type": "medium_shot",
  "is_sitting": true,
  "sit_ratio": 0.35,
  "visible_keypoints": {
    "head": true,
    "shoulder": true,
    "elbow": true,
    "hip": true,
    "knee": true,
    "ankle": false
  }
}
```

**ì•‰ì€ ìì„¸ ê°ì§€ ì›ë¦¬:**
```
ì„œ ìˆì„ ë•Œ:           ì•‰ì•„ ìˆì„ ë•Œ:
   ğŸ‘¤ head               ğŸ‘¤ head
   â— shoulder            â— shoulder
   â— hip                 â— hip â†â”€â”€ ë¬´ë¦ê³¼ Y ê±°ë¦¬ ì§§ìŒ
   â— knee (ì•„ë˜)         â— knee (ê±°ì˜ ê°™ì€ ë†’ì´)
   â— ankle               â— ankle

ratio = (knee_y - hip_y) / (hip_y - shoulder_y)
ì„œ ìˆìŒ: 1.0~1.5 | ì•‰ì•„ ìˆìŒ: 0.2~0.5
```

**ì¤‘ìš”:** RTMPoseëŠ” 133ê°œ keypointë¥¼ ì œê³µí•˜ë¯€ë¡œ ì–¼êµ´ ëœë“œë§ˆí¬ê¹Œì§€ í™œìš© ê°€ëŠ¥!

**ì†Œìš” ì‹œê°„:** ì•½ 15ë¶„ (2,133ì¥ Ã— 0.5ì´ˆ, rtmlib ONNX ê¸°ì¤€)

---

### Step 3: ê¹Šì´ ë¶„ì„ (í•µì‹¬!)

**ëª©ì :** ì¹´ë©”ë¼ ê±°ë¦¬/ì••ì¶•ê° íŒë‹¨

**ëª¨ë¸:** Depth Anything V2 Large

**ë°©ë²•:**
```python
for image in 2132_photos:
    # Depth map ìƒì„±
    depth_map = depth_anything_v2_large(image)

    # í•µì‹¬ ì§€í‘œ ê³„ì‚°
    person_depth = mean(depth_map[person_mask])
    background_depth = mean(depth_map[0:h/3, :])
    foreground_depth = mean(depth_map[3*h/4:h, :])

    # Compression Index
    total_range = background_depth - foreground_depth
    compression_index = 1.0 - (total_range / 255.0)
    # 0 = ê´‘ê° (í° ë²”ìœ„)
    # 1 = ë§ì› (ì‘ì€ ë²”ìœ„, ì••ì¶•ë¨)
```

**ì£¼ì˜:** ì¹´ë©”ë¼ ê°ë„ëŠ” depth mapì´ ì•„ë‹Œ **iPhone Gyroscope**ë¡œ ê°ì§€!

**ì¶”ì¶œ ì •ë³´:**
```json
{
  "depth_analysis": {
    "person_depth": 165,
    "background_depth": 220,
    "foreground_depth": 80,
    "compression_index": 0.45,
    "camera_type": "normal_to_tele"
  }
}
```

**ì¹´ë©”ë¼ ê°ë„ ê°ì§€ (ì‹¤ì‹œê°„ë§Œ í•´ë‹¹):**
```swift
// iOS CMMotionManager ì‚¬ìš©
let motionManager = CMMotionManager()
if motionManager.isDeviceMotionAvailable {
    motionManager.startDeviceMotionUpdates(to: queue) { motion, error in
        let pitch = motion.attitude.pitch * 180 / .pi
        // pitch: -90 (í•˜í–¥) ~ 0 (ìˆ˜í‰) ~ 90 (ìƒí–¥)
        // ì¹´ë©”ë¼ ê°ë„: -pitch (ì¹´ë©”ë¼ëŠ” ë°˜ëŒ€ ë°©í–¥)
        let cameraAngle = -pitch
    }
}
// ì •í™•ë„: Â±2ë„ (95% ì‹ ë¢°ë„)
```

**ì†Œìš” ì‹œê°„:** ì•½ 40ë¶„

---

### Step 4: êµ¬ë„ íŠ¹ì§• ê³„ì‚°

**ê° ì‚¬ì§„ë§ˆë‹¤ ê³„ì‚°:**

1. **ìœ„ì¹˜ íŠ¹ì§•**
```python
person_center_x = (bbox.x + bbox.width/2) / image_width
person_center_y = (bbox.y + bbox.height/2) / image_height
â†’ (0.35, 0.42)
```

2. **í¬ê¸° íŠ¹ì§•**
```python
person_size_ratio = (bbox.width * bbox.height) / (img_w * img_h)
â†’ 0.32
```

3. **ì—¬ë°± íŠ¹ì§•**
```python
left_margin = bbox.x / image_width
right_margin = (image_width - bbox.x - bbox.width) / image_width
top_margin = bbox.y / image_height
bottom_margin = (image_height - bbox.y - bbox.height) / image_height
â†’ (0.22, 0.46, 0.18, 0.38)
```

4. **ì‚¼ë¶„í•  ì ìˆ˜**
```python
third_points = [(1/3, 1/3), (2/3, 1/3), (1/3, 2/3), (2/3, 2/3)]
min_distance = min(euclidean(person_center, point) for point in third_points)
rule_of_thirds_score = 1.0 - (min_distance / 0.5)
â†’ 0.92
```

**ì†Œìš” ì‹œê°„:** ì¦‰ì‹œ (ë‹¨ìˆœ ìˆ˜í•™)

---

### Step 5: Hierarchical Pattern í†µê³„ ê³„ì‚°

**í•µì‹¬:** Theme + Pose Type ì¡°í•©ìœ¼ë¡œ ì„¸ë¶„í™”!

**ì™œ?** ì•‰ì€ ìƒë°˜ì‹ ê³¼ ì„œìˆëŠ” ì „ì‹ ì„ ì„ìœ¼ë©´ í†µê³„ê°€ ë¬´ì˜ë¯¸í•´ì§

**ì˜ˆì‹œ: cafe_indoor (668ì¥) â†’ 4ê°œ sub-patternìœ¼ë¡œ ë¶„í• **

```python
cafe_indoor_images = filter_by_theme("cafe_indoor")  # 668ì¥

# Pose Typeë³„ ë¶„í• 
patterns = {
    "cafe_indoor_closeup": [],      # 50ì¥
    "cafe_indoor_upper_body": [],   # 200ì¥
    "cafe_indoor_half_body": [],    # 300ì¥ (ê°€ì¥ ë§ìŒ!)
    "cafe_indoor_full_body": []     # 118ì¥
}

for img in cafe_indoor_images:
    key = f"{img.theme}_{img.pose_type}"
    patterns[key].append(img)

# ê° sub-patternë³„ë¡œ í†µê³„ ê³„ì‚°
for pattern_name, images in patterns.items():
    if len(images) < 30:  # ìµœì†Œ ìƒ˜í”Œ ìˆ˜ ìƒí–¥
        continue

    stats = calculate_statistics(images)
    save_pattern(pattern_name, stats)
```

**ê²°ê³¼: cafe_indoor_half_body (300ì¥)**

```json
{
  "theme": "cafe_indoor",
  "pose_type": "half_body",
  "sample_count": 300,

  "position": {
    "mean": [0.35, 0.42],
    "std": [0.08, 0.10],
    "optimal_range": {
      "x": [0.25, 0.45],
      "y": [0.30, 0.55]
    }
  },

  "size": {
    "mean": 0.32,
    "std": 0.06,
    "optimal_range": [0.28, 0.38]
  },

  "margins": {
    "left": {"mean": 0.22, "std": 0.05},
    "right": {"mean": 0.46, "std": 0.08},
    "asymmetry": "right_heavy"
  },

  "camera": {
    "compression_index": {
      "mean": 0.45,
      "std": 0.12
    },
    "type": "normal_to_tele",
    "focal_length_estimate": "50-70mm",
    "angle": {
      "mean": 12,
      "std": 5,
      "range": [5, 20]
    }
  },

  "pose_requirements": {
    "sitting": true,
    "visible_joints": ["shoulders", "elbows", "hips", "knees"]
  },

  "background": {
    "window": {
      "presence_rate": 0.78,
      "typical_direction": "right",
      "distance_from_person": {"mean": 0.25}
    }
  }
}
```

**ì¤‘ìš”:** ì´ì œ "cafe ë°˜ì‹  ì•‰ì€ ì‚¬ì§„"ë§Œ ë¹„êµí•˜ë¯€ë¡œ í†µê³„ê°€ ì˜ë¯¸ìˆìŒ!

---

## ğŸ’¾ íŒ¨í„´ DB êµ¬ì¡° (JSON)

**Hierarchical Structure: theme â†’ pose_type â†’ sub-patterns**

```json
{
  "cafe_indoor": {
    "theme_description": "ì¹´í˜ ì‹¤ë‚´",
    "total_samples": 668,

    "sub_patterns": {
      "cafe_indoor_half_body": {
        "theme": "cafe_indoor",
        "pose_type": "half_body",
        "sample_count": 300,
        "description": "ì¹´í˜ ë°˜ì‹  (ê°€ì¥ ì¸ê¸°)",

        "composition": {
          "position": {
            "mean": [0.35, 0.42],
            "std": [0.08, 0.10],
            "acceptable_range": {
              "x": [0.25, 0.45],
              "y": [0.30, 0.55]
            }
          },
          "size": {
            "mean": 0.32,
            "optimal_range": [0.28, 0.38]
          },
          "margins": {
            "left": {"mean": 0.22, "std": 0.05},
            "right": {"mean": 0.46, "std": 0.08},
            "top": {"mean": 0.18, "std": 0.06},
            "bottom": {"mean": 0.38, "std": 0.10}
          }
        },

        "camera": {
          "angle": {
            "mean": 12,
            "std": 5,
            "range": [5, 20],
            "interpretation": "slight_high_angle"
          },
          "compression_index": {
            "mean": 0.45,
            "std": 0.12,
            "range": [0.30, 0.65]
          },
          "type": "normal_to_tele",
          "focal_length_estimate": "50-70mm"
        },

        "pose_requirements": {
          "sitting": true,
          "visible_joints": ["shoulders", "elbows", "hips", "knees"],
          "min_confidence": 0.3
        },

        "background": {
          "required_objects": ["window"],
          "common_objects": ["chair", "table", "plant"],
          "window": {
            "presence_rate": 0.78,
            "typical_direction": "right",
            "distance_from_person": {"mean": 0.25, "std": 0.08}
          }
        },

        "scoring_weights": {
          "position_match": 0.20,
          "size_match": 0.15,
          "margin_match": 0.15,
          "compression_match": 0.20,
          "angle_match": 0.15,
          "pose_match": 0.15
        },

        "exemplars": [
          {"filename": "IMG_1234.jpg", "score": 98},
          {"filename": "IMG_2345.jpg", "score": 96}
        ]
      },

      "cafe_indoor_upper_body": {
        "theme": "cafe_indoor",
        "pose_type": "upper_body",
        "sample_count": 200,
        "description": "ì¹´í˜ ìƒë°˜ì‹  í´ë¡œì¦ˆì—…",

        "composition": {
          "position": {
            "mean": [0.48, 0.38],
            "std": [0.06, 0.08]
          }
        }
      }
    }
  },

  "park_nature": {
    "theme_description": "ê³µì›/ìì—°",
    "total_samples": 908,

    "sub_patterns": {
      "park_full_body": {...},
      "park_half_body": {...}
    }
  }
}
```

**í•µì‹¬ ê°œì„ :**
- âœ… Theme + Pose Type ì¡°í•©ìœ¼ë¡œ ì •ë°€ ë¶„ë¥˜
- âœ… ì•‰ìŒ/ì„œìˆìŒ êµ¬ë¶„
- âœ… ì¹´ë©”ë¼ ê°ë„ í¬í•¨ (gyroscope ê¸°ë°˜)
- âœ… Pose requirements ëª…ì‹œ

---

## ğŸ“± Phase 2: ì‹¤ì‹œê°„ í”¼ë“œë°± ì‹œìŠ¤í…œ

### ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ (iPhone)

**ëª©í‘œ ì„±ëŠ¥:** 15fps (66ms/frame)

**ì£¼ì˜:** RTMPose = YOLOX (detector) + RTMPose (pose estimator)

```
í”„ë ˆì„ ìº¡ì²˜
  â†“
YOLOX person bbox (5ms)
  â†“
RTMPose keypoints (5ms)
  â†“
Pose Type íŒì • (1ms)
  â†“
Gyroscope ê°ë„ ì½ê¸° (ì¦‰ì‹œ, ë°±ê·¸ë¼ìš´ë“œ)
  â†“
MiDaS Small depth ì¶”ì • (50ms)
  â†“
êµ¬ë„ íŠ¹ì§• ê³„ì‚° (2ms)
  â†“
íŒ¨í„´ ë§¤ì¹­ (í˜„ì¬ pose_typeì— ë§ëŠ” íŒ¨í„´ê³¼ ë¹„êµ, 3ms)
  â†“
3ë‹¨ê³„ í”¼ë“œë°± ìƒì„± (1ms)
  â†“
UI ì—…ë°ì´íŠ¸

ì´: 67ms â†’ 15fps âœ…
```

**RTMPose ìƒì„¸:**
```swift
// RTMPoseRunner.swift ì´ë¯¸ êµ¬í˜„ë¨
let result = rtmPoseRunner.run(image)

// result.boundingBox: YOLOXê°€ ê²€ì¶œí•œ person bbox
// result.keypoints: RTMPoseê°€ ì¶”ì •í•œ 133ê°œ keypoints
// result.confidences: ê° keypoint ì‹ ë¢°ë„

// Pose Type íŒì •
let poseType = determinePoseType(
    keypoints: result.keypoints,
    confidences: result.confidences
)
// â†’ "half_body", "upper_body", "full_body", "closeup"
```

### 3ë‹¨ê³„ í”¼ë“œë°± ì‹œìŠ¤í…œ

#### Tier 1: ìœ„ì¹˜ í”¼ë“œë°± (ì¦‰ê°)
```
current.position.x < ideal.position.x - 0.05
â†’ "â† ì™¼ìª½ìœ¼ë¡œ"

current.position.x > ideal.position.x + 0.05
â†’ "â†’ ì˜¤ë¥¸ìª½ìœ¼ë¡œ"

else
â†’ "âœ“ ìœ„ì¹˜ ì™„ë²½"
```

#### Tier 2: ê±°ë¦¬ í”¼ë“œë°± (í•µì‹¬!)
```
compression_diff = current.compression - ideal.compression

if compression_diff > 0.15:  // ë„ˆë¬´ ë§ì›
    distance = estimate_distance(compression_diff)
    â†’ "ğŸ“ {distance}m ë” ê°€ê¹Œì´"
    â†’ "ë˜ëŠ” ì¤Œ ì•„ì›ƒ"

elif compression_diff < -0.15:  // ë„ˆë¬´ ê´‘ê°
    distance = estimate_distance(compression_diff)
    â†’ "ğŸ“ {distance}m ë’¤ë¡œ"
    â†’ "ë˜ëŠ” ì¤Œ ì¸"

else:
    â†’ "âœ“ ê±°ë¦¬ ì™„ë²½"
```

#### Tier 3: ì¢…í•© ì ìˆ˜
```
overall_score = weighted_average(
    position_match,
    size_match,
    margin_match,
    compression_match
)

if score >= 95:
    â†’ "ğŸ‰ ì™„ë²½! ì´¬ì˜í•˜ì„¸ìš”"
    + í–…í‹± í”¼ë“œë°±
    + ì´ˆë¡ìƒ‰ í…Œë‘ë¦¬

elif score >= 85:
    â†’ "ğŸ‘ í›Œë¥­í•©ë‹ˆë‹¤ ({score}/100)"

else:
    â†’ "ì¡°ì • í•„ìš” ({score}/100)"
```

---

## ğŸ¨ UI ë ˆì´ì•„ì›ƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                 â”‚
â”‚    [ì¹´ë©”ë¼ ë·°íŒŒì¸ë”]            â”‚
â”‚                                 â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚         â”‚   ğŸ‘¤    â”‚             â”‚ â† YOLO bbox ì˜¤ë²„ë ˆì´
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                 â”‚
â”‚    â”Œâ”€ â”€ â”€ â”€ â”€ â”€ â”€â”            â”‚ â† ì´ìƒì  ìœ„ì¹˜ (ì ì„ )
â”‚                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â† ì™¼ìª½ìœ¼ë¡œ                     â”‚ â† Tier 1
â”‚  ğŸ“ 1.2m ë’¤ë¡œ ë˜ëŠ” ì¤Œ ì¸        â”‚ â† Tier 2 (í•µì‹¬!)
â”‚  â­ êµ¬ë„ ì ìˆ˜: 87/100          â”‚ â† Tier 3
â”‚                                 â”‚
â”‚  [ì¹´í˜ ì°½ê°€ íŒ¨í„´]               â”‚
â”‚  [ëŒ€í‘œ ì˜ˆì‹œ ë³´ê¸°]               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ í•µì‹¬ ì°¨ë³„ì 

### ì••ì¶•ê° ê¸°ë°˜ ê±°ë¦¬ í”¼ë“œë°± (ì„¸ê³„ ìµœì´ˆ)

**ë¬¸ì œ:**
```
ì‚¬ì§„ A: ê°€ê¹Œì´ì„œ ê´‘ê° (24mm)
ì‚¬ì§„ B: ë©€ë¦¬ì„œ ë§ì› (85mm)

â†’ ë‘ ì‚¬ì§„ ëª¨ë‘ ì¸ë¬¼ í¬ê¸° ê°™ì„ ìˆ˜ ìˆìŒ
â†’ í•˜ì§€ë§Œ ì™„ì „íˆ ë‹¤ë¥¸ ëŠë‚Œ!
```

**í•´ê²°:**
```
Depth Mapìœ¼ë¡œ ì••ì¶•ê° ì¸¡ì •
â†’ "1.2m ë’¤ë¡œ" ì •ëŸ‰ì  í”¼ë“œë°±
â†’ "ì¸ìŠ¤íƒ€ ëŠë‚Œ"ì˜ í•µì‹¬ ì¬í˜„
```

### ê¸°ì¡´ ì•± vs TryAngle v1.5

| ê¸°ëŠ¥ | ê¸°ì¡´ ì•± | TryAngle v1.5 |
|------|---------|---------------|
| ìœ„ì¹˜ ê°€ì´ë“œ | "ê·¸ë¦¬ë“œ ë¼ì¸" | "ì™¼ìª½ìœ¼ë¡œ 10cm" |
| ê±°ë¦¬ ê°€ì´ë“œ | âŒ ì—†ìŒ | "1.2m ë’¤ë¡œ ë˜ëŠ” ì¤Œ ì¸" â­ |
| ì ìˆ˜ | âŒ ì—†ìŒ | "87/100, 3ì ë§Œ ë”" |
| í…Œë§ˆ | âŒ ì—†ìŒ | "ì¹´í˜ ì°½ê°€ íŒ¨í„´ 93% ì¼ì¹˜" |
| í”¼ë“œë°± | ì‹œê°ì ë§Œ | í–…í‹± + ìŒì„± + ì‹œê° |

---

## ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥

### ì˜¤í”„ë¼ì¸ í•™ìŠµ (RTX 4070 Super)
```
ì „ì²´ 2,132ì¥ ê¸°ì¤€:
- Grounding DINO ê°ì²´ ê²€ì¶œ: 1ì‹œê°„
- RTMPose Pose Type ë¶„ë¥˜: 30ë¶„
- Depth Anything V2 ê¹Šì´ ë¶„ì„: 40ë¶„
- í†µê³„ ê³„ì‚°: 10ë¶„

ì´: 2-3ì‹œê°„
ê²°ê³¼ë¬¼: 2-5MB JSON

MVP 300ì¥ ê¸°ì¤€:
- ì´ 30ë¶„
```

### ì‹¤ì‹œê°„ ì„±ëŠ¥ (iPhone 15 Pro)
```
- YOLO bbox: 10ms
- MiDaS Small: 50ms
- ê³„ì‚° + ë§¤ì¹­: 5ms
- í”¼ë“œë°±: 1ms

ì´: 66ms â†’ 15fps âœ…

ë°°í„°ë¦¬: ì¤‘ê°„ (MiDaS ì£¼ìš” ì†Œëª¨)
ë°œì—´: ë‚®ìŒ
```

---

## ğŸ¯ ì‹¤í–‰ ì „ëµ

### í˜„ì¬ ë°ì´í„° í™œìš© (2,132ì¥)

**Step 1: ìë™ ë¶„ë¥˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰**
```python
# auto_classify_all.py
for image in all_2132_images:
    theme = grounding_dino_classify_theme(image)
    pose_type = rtmpose_classify_pose(image)
    move_to(f"{theme}/{pose_type}/")
```

**Step 2: íŠ¹ì§• ì¶”ì¶œ**
```bash
python extract_features_full.py \
    --input_dir classified_full \
    --use_all_images True
```

**Step 3: íŒ¨í„´ ìƒì„±**
```bash
# ì¶œë ¥: patterns_full_v1.json (2-5MB)
```

### MVP í…ŒìŠ¤íŠ¸ (ë¹ ë¥¸ ê²€ì¦)

300ì¥ë§Œ ì„ ë³„í•˜ì—¬ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸:
```
cafe_indoor: 150ì¥
park_nature: 100ì¥
street_urban: 50ì¥

â†’ 30ë¶„ ë‚´ ì™„ë£Œ
â†’ ê¸°ëŠ¥ ê²€ì¦ í›„ ì „ì²´ í™•ì¥
```

---

## ğŸš€ ê°œë°œ ë¡œë“œë§µ

### Phase 0: ë°ì´í„° ì¤€ë¹„ (í˜„ì¬)
```
âœ… 2,132ì¥ ì´ë¯¸ì§€ í™•ë³´ (ì™„ë£Œ)
â¬œ ìë™ ë¶„ë¥˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
â¬œ Theme Ã— Pose Type í´ë” êµ¬ì„±
```

### Phase 1: íŠ¹ì§• ì¶”ì¶œ (1ì¼)
```
â¬œ RTX 4070S í™˜ê²½ ì„¸íŒ…
â¬œ Grounding DINO, RTMPose, Depth Anything V2 ì„¤ì¹˜
â¬œ extract_features_full.py ì‹¤í–‰
â¬œ patterns_full_v1.json ìƒì„±
```

### Phase 2: iOS ì•± í†µí•© (1ì£¼)
```
â¬œ JSON íŒŒì¼ ì•±ì— ë‚´ì¥
â¬œ íŒ¨í„´ ë§¤ì¹­ ë¡œì§ êµ¬í˜„
â¬œ ì‹¤ì‹œê°„ í”¼ë“œë°± UI
```

### Phase 3: í…ŒìŠ¤íŠ¸ ë° ê°œì„  (1ì£¼)
```
â¬œ ì‹¤ì œ ì´¬ì˜ í…ŒìŠ¤íŠ¸
â¬œ í”¼ë“œë°± ì •í™•ë„ ì¸¡ì •
â¬œ ì‚¬ìš©ì í…ŒìŠ¤íŠ¸
â¬œ íŒŒë¼ë¯¸í„° íŠœë‹
```

---

## ğŸ”‘ í•µì‹¬ ì¸ì‚¬ì´íŠ¸

### 1. Hierarchical Patternì˜ ì¤‘ìš”ì„±
```
âŒ ì˜ëª»ëœ ë°©ì‹:
   cafe_indoor ì „ì²´ í‰ê·  (ì•‰ì€ ë°˜ì‹  + ì„œìˆëŠ” ì „ì‹  ì„ì„)
   â†’ í†µê³„ê°€ ë¬´ì˜ë¯¸!

âœ… ì˜¬ë°”ë¥¸ ë°©ì‹:
   cafe_indoor_half_body (ì•‰ì€ ë°˜ì‹ ë§Œ)
   cafe_indoor_full_body (ì„œìˆëŠ” ì „ì‹ ë§Œ)
   â†’ ê°ê° ì˜ë¯¸ìˆëŠ” í†µê³„!

í•µì‹¬: Theme + Pose Type ì¡°í•©ì´ í•„ìˆ˜!
```

### 2. RTMPose vs YOLO
```
í˜„ì¬ ì•± êµ¬ì¡° (RTMPoseRunner.swift):
1. YOLOX â†’ Person bbox ê²€ì¶œ (ë¹ ë¦„)
2. RTMPose â†’ 133ê°œ keypoints (ì •ë°€)

ì™œ ë‘˜ ë‹¤ í•„ìš”?
- YOLOX: ë¹ ë¥¸ person detection
- RTMPose: ì–¼êµ´ ëœë“œë§ˆí¬ í¬í•¨ ì •ë°€ pose

v1.5ì—ì„œ:
- YOLOX bbox â†’ êµ¬ë„ ë¶„ì„ (ìœ„ì¹˜, í¬ê¸°, ì—¬ë°±)
- RTMPose keypoints â†’ Pose Type íŒì • (half/full/upper)
```

### 3. Occlusion Handling (ê°€ë¦¼ ëŒ€ì‘)
```
ë¬¸ì œ: ì˜·/í…Œì´ë¸”ë¡œ ê´€ì ˆ ê°€ë ¤ì§

í•´ê²° ì „ëµ:
1. Confidence threshold ë‚®ê²Œ (0.3)
2. ë³´ì´ëŠ” ê´€ì ˆë§Œìœ¼ë¡œ íŒë‹¨
3. Multi-frame averaging (ì‹¤ì‹œê°„)
4. Conservative classification
   ì˜ˆ: ë¶ˆí™•ì‹¤í•˜ë©´ "upper_body"

RTMPose ì¥ì :
- 133ê°œ keypoint â†’ ì–¼êµ´ ëœë“œë§ˆí¬ í™œìš© ê°€ëŠ¥
- Confidence per keypoint
- Robust to partial occlusion
```

### 4. Grounding DINOì˜ ì—­í• 
```
âœ… í•  ìˆ˜ ìˆëŠ” ê²ƒ:
   - ê°ê´€ì  ì¸¡ì • (ì–´ë””ì— ë­ê°€ ìˆëŠ”ì§€)
   - ì¸ë¬¼ + ë°°ê²½ ê°ì²´ ìœ„ì¹˜
   - í…Œë§ˆ ë¶„ë¥˜ (rules-based)

âŒ í•  ìˆ˜ ì—†ëŠ” ê²ƒ:
   - ì£¼ê´€ì  íŒë‹¨ (ì¢‹ì€ êµ¬ë„ì¸ì§€)
   - ì—¬ë°±ì´ ì ì ˆí•œì§€

â†’ ì˜¤í”„ë¼ì¸ í•™ìŠµì—ë§Œ ì‚¬ìš©!
```

### 5. ì—¬ë°± íŒë‹¨ì˜ ì›ë¦¬
```
Grounding DINO = ì¸¡ì • ë„êµ¬
í†µê³„ ë¶„ì„ = íŒ¨í„´ ë°œê²¬

"ì¢‹ì€ ì‚¬ì§„" 500ì¥ ì¸¡ì •
â†’ í‰ê·  ì—¬ë°± 22%-46%
â†’ ì´ê±¸ "ì´ìƒì  ì—¬ë°±"ìœ¼ë¡œ ì‚¬ìš©

â†’ ê·€ë‚©ì  ì¶”ë¡ !
```

### 6. ì••ì¶•ê° ì¸¡ì •
```
EXIF Focal Length: í¸ì§‘ëœ ì‚¬ì§„ì—” ì—†ìŒ âŒ
Depth Map: í•­ìƒ ê³„ì‚° ê°€ëŠ¥ âœ…

Compression Index:
- 0 = ê´‘ê° (í° depth ë²”ìœ„)
- 1 = ë§ì› (ì‘ì€ depth ë²”ìœ„)

â†’ "ê°€ê¹Œì´ vs ë©€ë¦¬+ì¤Œ" êµ¬ë¶„ ê°€ëŠ¥!
```

### 7. ì¹´ë©”ë¼ ê°ë„ ê°ì§€
```
âŒ Depth Map Gradient: ë¶€ì •í™•
âœ… iPhone Gyroscope: 95% ì •í™•ë„

CMMotionManager:
- pitch: ì¹´ë©”ë¼ ìƒí•˜ ê°ë„
- roll: ì¹´ë©”ë¼ ì¢Œìš° ê¸°ìš¸ê¸°
- ì‹¤ì‹œê°„, ë°°í„°ë¦¬ ì˜í–¥ ê±°ì˜ ì—†ìŒ

â†’ ë ˆí¼ëŸ°ìŠ¤ ì‚¬ì§„ì˜ angleê³¼ ë¹„êµ!
```

---

## ğŸ’¡ ì™œ ì´ ë°©ì‹ì´ ë˜‘ë˜‘í•œê°€?

### ì¥ì 

1. **Grounding DINO ê°•ì  í™œìš©**
   - ëŠë¦¬ì§€ë§Œ ì •ë°€ â†’ ì˜¤í”„ë¼ì¸ í•™ìŠµì—
   - ë°°ê²½ ê°ì²´ ì¸ì‹ â†’ í…Œë§ˆ ë¶„ë¥˜ì—

2. **ì‹¤ì‹œê°„ì€ ê²½ëŸ‰ ëª¨ë¸**
   - YOLO + MiDaS Small
   - ë¯¸ë¦¬ í•™ìŠµí•œ íŒ¨í„´ í™œìš©

3. **ì‚¬ìš©ìëŠ” ì°¨ì´ ëª» ëŠë‚Œ**
   - í”¼ë“œë°± ì¦‰ê°ì  (66ms)
   - ì •í™•ë„ 85-90%ë©´ ì¶©ë¶„
   - ë„¤íŠ¸ì›Œí¬ ë¶ˆí•„ìš”

4. **í™•ì¥ ê°€ëŠ¥**
   - ìƒˆ í…Œë§ˆ ì¶”ê°€ ì‰¬ì›€
   - ëª¨ë¸ ì—…ë°ì´íŠ¸ ë…ë¦½ì 
   - JSONë§Œ êµì²´

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

1. ìë™ ë¶„ë¥˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (auto_classify_all.py)
2. RTX 4070 Super í™˜ê²½ ì„¸íŒ…
3. Grounding DINO + Depth Anything V2 ì„¤ì¹˜
4. 2,132ì¥ íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
5. JSON DB ìƒì„±
6. iOS ì•± í†µí•©

---

**ìµœì´ˆ ì‘ì„±ì¼:** 2025-11-30
**ìµœì¢… ì—…ë°ì´íŠ¸:** 2025-11-30
**ë¸Œëœì¹˜:** v1.5_ios
**ë²„ì „:** 1.3

## ğŸ“ ë³€ê²½ ì´ë ¥

### v1.3 (2025-11-30)
- âœ… **ìƒˆë¡œìš´ 4-Type Shot ë¶„ë¥˜ ì²´ê³„ ë„ì…** (Samsung Display ê¸°ì¤€ ì°¸ê³ )
  - ê¸°ì¡´: closeup, upper_body, half_body, full_body
  - ì‹ ê·œ: **closeup, medium_shot, knee_shot, full_shot**
  - medium_shot = bust_shot + waist_shot í†µí•© (ì‹¤ìš©ì  ë¶„ë¥˜)
- âœ… **ì•‰ì€ ìì„¸ ê°ì§€ ë¡œì§ ì¶”ê°€**
  - ê³¨ë°˜-ë¬´ë¦ ê±°ë¦¬ / ìƒì²´ ê¸¸ì´ ë¹„ìœ¨ë¡œ íŒë‹¨
  - ratio < 0.6 â†’ ì•‰ì€ ìì„¸
  - ì•‰ì€ ìì„¸ì¼ ë•Œ Shot Type ë³´ì • ì ìš©
- âœ… **rtmlib (ONNX) ê¸°ë°˜ RTMPose êµ¬í˜„**
  - Mac M3ì—ì„œë„ ë™ì‘ ê°€ëŠ¥
  - ì†ë„: ~2 it/s (2,133ì¥ ì•½ 15ë¶„)
- âœ… ë¶„ë¥˜ ê¸°ì¤€ ëª…í™•í™” (í”„ë ˆì„ ë‚´ ìœ„ì¹˜ ê¸°ë°˜)

### v1.2 (2025-12-01)
- âœ… 2,132ì¥ ì „ì²´ í™œìš© ê³„íš ì¶”ê°€ (MVP ì œí•œ í•´ì œ)
- âœ… ì™„ì „ ìë™í™” One-Pass Processing ì¶”ê°€
- âœ… ë‹¤ì¤‘ ì‹ í˜¸ ê¸°ë°˜ Robust Classification
- âœ… ì‹¤ì§ˆì  ì´ì  ì„¹ì…˜ ì‹ ê·œ ì¶”ê°€
- âœ… ê°œì„ ëœ íŒŒì´í”„ë¼ì¸ ì„¹ì…˜ ì¶”ê°€
- âœ… ì‹¤í–‰ ì „ëµ êµ¬ì²´í™”

### v1.1 (2025-11-30)
- âœ… CLIP â†’ Grounding DINO rules-based + DINOv2 clusteringìœ¼ë¡œ ë³€ê²½
- âœ… Hierarchical Pattern êµ¬ì¡° ì¶”ê°€ (theme + pose_type)
- âœ… RTMPose 133 keypoints ê¸°ë°˜ Pose Type ìë™ ê²€ì¶œ ì¶”ê°€
- âœ… Occlusion Handling ì „ëµ ì¶”ê°€
- âœ… Gyroscope ê°ë„ ê°ì§€ (depth gradient ì œê±°)
- âœ… MVP Strategy ì¶”ê°€ (300ì¥ ìƒ˜í”Œ)
- âœ… ê°œë°œ ë¡œë“œë§µ MVP ê¸°ë°˜ìœ¼ë¡œ ì¬êµ¬ì„±
- âœ… RTMPose vs YOLO ëª…í™•í™”

### v1.0 (2025-11-30)
- ìµœì´ˆ ë¬¸ì„œ ì‘ì„±