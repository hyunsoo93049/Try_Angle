# clip_reference_comparator.py
# âœ… ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ 1ì¥ì„ CLIPìœ¼ë¡œ ì„ë² ë”©í•´ ì €ì¥í•˜ê³ ,
#    ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”„ë ˆì„ê³¼ ìŠ¤íƒ€ì¼/êµ¬ë„ ìœ ì‚¬ë„ë¥¼ ë¹„êµí•˜ëŠ” ì½”ë“œ

import cv2
import torch
import clip
import numpy as np
from PIL import Image
from torchvision import transforms
from sklearn.metrics.pairwise import cosine_similarity
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parent
while PROJECT_ROOT != PROJECT_ROOT.parent and not ((PROJECT_ROOT / "data").exists() and (PROJECT_ROOT / "src").exists()):
    PROJECT_ROOT = PROJECT_ROOT.parent

# ğŸ”¸ CLIP ëª¨ë¸ ë¡œë“œ (ViT-B/32 ì‚¬ìš©)
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# ğŸ”¸ ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ë¡œë”© ë° ì „ì²˜ë¦¬
REFERENCE_PATH = PROJECT_ROOT / "data" / "sample_images" / "test1.jpg"
ref_img_pil = Image.open(REFERENCE_PATH).convert("RGB")
ref_preprocessed = preprocess(ref_img_pil).unsqueeze(0).to(device)

# ğŸ”¸ ë ˆí¼ëŸ°ìŠ¤ ì„ë² ë”© ë²¡í„° ì¶”ì¶œ (í•œ ë²ˆë§Œ ìˆ˜í–‰)
with torch.no_grad():
    reference_embedding = model.encode_image(ref_preprocessed)
    reference_embedding /= reference_embedding.norm(dim=-1, keepdim=True)

print("âœ… ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ì„ë² ë”© ì™„ë£Œ. ì‹¤ì‹œê°„ ìœ ì‚¬ë„ ë¹„êµ ì‹œì‘.")

# ğŸ”¸ ì›¹ìº  ì‹¤í–‰
cap = cv2.VideoCapture(0)
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # ğŸ”¸ í˜„ì¬ í”„ë ˆì„ â†’ PIL â†’ CLIP ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    frame_pil = Image.fromarray(frame_rgb)
    frame_tensor = preprocess(frame_pil).unsqueeze(0).to(device)

    # ğŸ”¸ í˜„ì¬ í”„ë ˆì„ ì„ë² ë”© ê³„ì‚°
    with torch.no_grad():
        live_embedding = model.encode_image(frame_tensor)
        live_embedding /= live_embedding.norm(dim=-1, keepdim=True)

    # ğŸ”¸ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    similarity = (live_embedding @ reference_embedding.T).item()
    similarity_percent = int(similarity * 100)

    # ğŸ”¸ ìœ ì‚¬ë„ ì ìˆ˜ í‘œì‹œ
    cv2.putText(frame, f"CLIP Similarity: {similarity_percent}%", (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)

    # ğŸ”¸ í™”ë©´ ì¶œë ¥
    cv2.imshow("CLIP Style Similarity", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
